# Test04 - Î£55

---

# Questions
|n|Question|Answer|
|-|--------|------|
|1|You are planning to develop a mobile application named MobileApp1.<br/>MobileApp1 uses the OAuth 2 implicit grant type to acquire Azure AD access tokens.<br/>What information should you obtain to register MobileApp1 in Azure AD ?<br/><br/>a. a redirect URI<br/>b. a reply URL<br/>c. a key<br/>d. an application ID|<details><summary>Answer</summary>a. redirect URI<br/><br/>Register your application with your Azure Active Directory (Azure AD) tenant. This will give you an Application ID for your application, as well as enable it to receive tokens.<br/>At the time of registration, Provide the Redirect URI. For web applications, this is the base URL of your app where users can sign in. For example, http://localhost:12345. For public client (mobile & desktop), Azure AD uses it to return token responses. Enter a value specific to your application. For example, http://MyFirstAADApp<br/>https://docs.microsoft.com/en-us/azure/active-directory/azuread-dev/v1-protocols-oauth-code#register-your-application-with-your-ad-tenant</details>|
|2|You are developing an application that uses Azure storage account.<br/>You need to recommend a solution to recover blob data that is deleted accidentally from the storage account for 14 days after the deletion occurred.<br/><br/>What should you recommend ?<br/><br/>a. Enable Resource Lock<br/>b. Configure access tiers for blob data<br/>c. Enable Soft Delete with retain period as 14 days|<details><summary>Answer</summary>c. Enable Soft Delete with retain period as 14 days<br/><br/>Soft delete protects blob data from being accidentally or erroneously modified or deleted. When soft delete is enabled for a storage account, blobs, blob versions (preview), and snapshots in that storage account may be recovered after they are deleted, within a retention period that you specify<br/>https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-overview</details>|
|3|You have deployed an application in Azure and configured below rules in auto scaling<br/>If CPU < 30%, scale-in by 1<br/>If Memory < 50%, scale-in by 1<br/>If CPU > 75%, scale-out by 1<br/>If Memory > 75%, scale-out by 1<br/>Then the follow occurs:<br/>If CPU is 50% and Memory is 76%<br/><br/>What happens to instance count ?<br/><br/>a. Scale out by 1<br/>b. Scale out by 2<br/>c. Scale in by 1|<details><summary>Answer</summary>a. Scale out by 1</details>|
|4|You have deployed a web application into an Azure App Service that uses the D1 pricing tier.<br/>You need to configure that all connections to web application use HTTPS and custom domain.<br/>What should you do first ?<br/><br/>a. Scale up App service plan<br/>b. Modify the connection strings<br/>c. Disable anonymous access<br/>d. Configure Scale out in App service|<details><summary>Answer</summary>a. Scale Up App service plan<br/><br/>Secure Sockets Layer (SSL) Certificates for custom domains is available on Basic, Standard and Premium service plans. SSL Certificates enables secure connections (https://) to your custom domain website.<br/>The D1 (Shared) pricing tier does not support HTTPS on custom domains.<br/>https://azure.microsoft.com/en-au/pricing/details/app-service/windows/</details>|
|5|You are developing a social networking application using Azure Cosmos DB. Your need to record/save the likes and replies for the posts in the social networking application.<br/>The order of replies and likes are not a priority.<br/>Which consistency level is most appropriate ?<br/><br/>a. Strong<br/>b. Bounded Staleness<br/>c. Session<br/>d. Consisten Prefix<br/>e. Eventual|<details><summary>Answer</summary>e. Eventual<br/><br/>Eventual: There's no ordering guarantee for reads. In the absence of any further writes, the replicas eventually converge.<br/>Eventual consistency is the weakest form of consistency because a client may read the values that are older than the ones it had read before. Eventual consistency is ideal where the application does not require any ordering guarantees. Examples include count of Retweets, Likes, or non-threaded comments. The following graphic illustrates the eventual consistency with musical notes.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels</details>|
|6|You have developed an application using Azure Cosmos DB. The application is used by users across the globe. Some of the users have raised a concern on latency issues.<br/>You have reviewed the logs and enabled Multi-write feature in Azure Cosmos DB to fix latency issues.<br/>What changes should you make in your application code ?<br/><br/>a. Set UseMultipleWriteLocations to True<br/>b. SetCurrentLocation to name of the region where application deployed<br/>c. Rewrite data layer access module to handle multi write|<details><summary>Answer</summary>a. Set UseMultipleWriteLocations to True<br/>b. SetCurrentLocation to name of the region where application deployed<br/><br/>Once an account has been created with multiple write regions enabled, you must make two changes in your application to the ConnectionPolicy for the DocumentClient to enable the multi-master and multi-homing capabilities in Azure Cosmos DB. Within the ConnectionPolicy, set UseMultipleWriteLocations to true and pass the name of the region where the application is deployed to SetCurrentLocation. This will populate the PreferredLocations property based on the geo-proximity from location passed in. If a new region is later added to the account, the application does not have to be updated or redeployed, it will automatically detect the closer region and will auto-home on to it should a regional event occur.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/how-to-multi-master?tabs=api-async</details>|
|7|You plan to develop a web application using Azure App Service and Azure Cosmos DB. The web application will send data to the database daily. You need to send an email notification when data is received.<br/>What solution should you recommend keeping compute costs minimal ?<br/><br/>a. Create an Azure logic app that has the Azure Cosmos DB connector configured to use a SendGrid action<br/>b. Create a function app using Consumption plan, Cosmos DB trigger & a SendGrid binding<br/>c. Create an Azure Logic app that has a SendGrid connector configured to use an Azure Cosmos DB action<br/>d. Create a function app that is configured to use the Consumption plan & an Azure Event Hubs binding|<details><summary>Answer</summary>b. Create a function app using Consumption plan, Cosmos DB trigger & a sendGrid binding<br/><br/>The Azure Cosmos DB change feed enables efficient processing of large datasets with a high volume of writes. Change feed also offers an alternative to querying an entire dataset to identify what has changed.<br/>Azure Cosmos DB is well-suited for IoT, gaming, retail, and operational logging applications. A common design pattern in these applications is to use changes to the data to trigger additional actions. Examples of additional actions include:<br/>* Triggering a notification or a call to an API, when an item is inserted or updated.<br/>* Real-time stream processing for IoT or real-time analytics processing on operational data.<br/>Data movement such as synchronizing with a cache, a search engine, a data warehouse, or cold storage.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed-design-patterns<br/><br/><ins>chatGPT</ins><br/>Azure Functions, when configured with the Consumption plan, are billed based on per-execution, so you're not paying for any idle compute time. A Cosmos DB trigger can be used to execute the function when new data is received, and the SendGrid binding can be used to send an email notification when the function is triggered. This setup would only run when new data is received in Cosmos DB, making it a cost-effective solution.</details>|
|8|You have an application that uses Azure Front Door Service.<br/>You expect that inbound files to be compressed by using Brotli compression.<br/>You discover that inbound XML files are not compressed. The files are 10 megabytes (MB) in size.<br/>You need to find the root cause for the issue.<br/><br/>Select the option as Yes if the option helps you to find root cause, otherwise select No.<br/>1. The file MIME type is supported by the service<br/>2. Edge nodes must be purged of all cache assets<br/>3. The compression type is supported<br/><br/>a. yes,yes,yes<br/>b. yes,no,yes<br/>c. No,no,yes<br/>d. no,no,no|<details><summary>Answer</summary>c. No,No,Yes<br/><br/>1. The file MIME type is supported by the service. So, this option does not help you to determine the root cause.<br/>2. Edge nodes are not required to be purged. So, this option does not help you to determine the root cause.<br/>The compression type is not supported due to size limits. This options provides root cause for not compression.<br/><br/>1. The file MIME type is supported by the service. So, this option does not help you to determine the root cause<br/>2. Edge nodes are not required to be purged. So, this option does not help you to determine the root cause.<br/>3. The compression type is not supported due to size limits. This options provides root cause for not compression<br/>https://docs.microsoft.com/en-us/azure/frontdoor/front-door-caching#file-compression</details>|
|9|You have an ASP.NET Core web app that runs in Docker. The app is mapped to the www. WebApplication.com domain. You are migrating this application to Azure.<br/>You plan to create Azure resources. The application will use an App Service Web App to host the docker image. You need to map a custom domain to the App Service web app.<br/><br/>A resource group named RG1 has been created in the WestUS region.<br/>RG1 contains an App Service Plan named ASP1.<br/>Select the order in which should you use the below CLI commands to create the Azure resources ?<br/><br/>1. az webapp config container set<br/>--docker-custom-image-name<br/>$dockerHubContainerPath<br/>--name $appName<br/>--resource-group RG1<br/><br/>2. az webapp config hostname add<br/>--webapp-name $appName<br/>--resource-group RG1 \ <br/>--hostname $fqdn<br/><br/>3. az webapp create<br/>--name $appName<br/>--plan ASP1<br/>--resource-group RG1<br/><br/>4. #/bin/bash<br/>appName = âWebApplication$randomâ<br/>location= âWestUSâ<br/>dockerHubContainerPath = âWebApplication/publicweb.v1â<br/>fqdn = âwww.WebApplication.comâ<br/><br/>a. 1,2,3,4<br/>b. 4,3,2,1<br/>c. 4,3,1,2|<details><summary>Answer</summary>c. 4,3,1,2<br/><br/>The order in which commands must be executed are<br/>1. Prepare data or declare variables.<br/>2. Create the web app<br/>3. Set the container<br/>4. Configure custom domain<br/>https://docs.microsoft.com/en-us/azure/app-service/tutorial-custom-container?pivots=container-linux#push-the-image-to-azure-container-registry<br/>https://docs.microsoft.com/en-us/azure/app-service/scripts/cli-configure-custom-domain</details>|
|10|You are developing a server less application on Azure. You created a key vault named KV1 to store and read secrets from an Azure Function.<br/><br/>You need to reference KV1 without making any changes to the application source code.<br/>The identity used to connect to KV1 must be deleted if the Azure function is deleted.<br/>The Azure Function must scale based on the number of incoming requests.<br/>Avoid any cold starts.<br/>Azure Function must be able to connect to a virtual network.<br/><br/>You need to implement the Azure Functions application access to the Azure Key Vault.<br/><br/>Which three actions should you perform in sequence ?<br/><br/>a. Create the Azure Functions app with a consumption plan type<br/>Crea a user-managed identity for the application.<br/>Crea an access policy in Azure Key Vault for the application identity<br/><br/>b. Create the Azure Functions app with a premium plan type<br/>Crea a user-managed identity for the application.<br/>bCreate an access policy in Azure Key Vault for the application idenity<br/><br/>c. Create the Azure Functions app with a premium plan type<br/>Create a system-managed idenity for the application.<br/>Create an access policy in Azure Key Vault for the application identity<br/><br/>d. Create the Azure Functions app with app service plan type<br/>Create a system-managed idenity for the application.<br/>Create an access policy in Azure Key Vault for the application identity|<details><summary>Answer</summary>c. Create the Azure Functions app with a premium plan type<br/>Create a system-managed identity for the application<br/>Create an access policy in Azure Key Vault for the application identity<br/><br/>The Azure Functions Premium plan (sometimes referred to as Elastic Premium plan) is a hosting option for function apps. The Premium plan provides features like VNet connectivity, no cold start, and premium hardware<br/>A managed identity from Azure Active Directory (Azure AD) allows your app to easily access other Azure AD-protected resources such as Azure Key Vault. The identity is managed by the Azure platform and does not require you to provision or rotate any secrets.<br/>Your application can be granted two types of identities:<br/>A system-assigned identity is tied to your application and is deleted if your app is deleted. An app can only have one system-assigned identity.<br/>A user-assigned identity is a standalone Azure resource that can be assigned to your app. An app can have multiple user-assigned identities.<br/>https://docs.microsoft.com/en-us/azure/app-service/overview-managed-identity?tabs=dotne<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-premium-plan</details>|
|11|You are developing a web app that will use an App Service on Linux.<br/>You create and push a Docker image that contains the web app to Azure Container Registry.<br/>You should be able to access the console logs in real-time generated from inside the container.<br/>Which Azure CLI commands should you use ?<br/><br/>a. az webapp log config --name webapp --resource-group RG1 --docker-container-logging filesystem<br/>az webapp log tail --name webapp --resource-group RG1<br/><br/>b. az webapp log config --name webapp --resource-group RG1 --application-logging filesystem<br/>az webapp log tail --name webapp --resource-group RG1<br/><br/>c. az webapp log config --name webapp --resource-group RG1 --docker-container-logging filesystem<br/>az webapp log download --name webapp --resource-group RG1<br/><br/>d. az webapp log config --name webapp --resource-group RG1 --docker-container-logging filesystem<br/>az webapp log show --name webapp --resource-group RG1|<details><summary>Answer</summary>a. az webapp log config --name webapp --resource-group RG1 --docker-container-logging filesystem<br/>az webapp log tail --name webapp --resource-group RG1<br/><br/>To access the console logs generated from inside the container, first, turn on container logging by running the following command:<br/>az webapp log config --name <app-name> --resource-group <resource-group-name> --docker-container-logging filesystem<br/>Once container logging is turned on, run the following command to see the log stream:<br/>az webapp log tail --name <app-name> --resource-group <resource-group-name><br/>https://docs.microsoft.com/en-us/azure/app-service/configure-custom-container?pivots=container-linux#access-diagnostic-logs-1</details>|
|12|You plan to use Azure messaging solution in an application. The messaging solution must meet the below requirements:<br/>It must provide transactional support.<br/>It must provide duplicate detection.<br/>Able to store the messages for an unlimited period of time.<br/><br/>Select the two solutions that will meet these requirements.<br/><br/>a. Azure Service Bus Topic<br/>b. Azure Service Bus Queue<br/>c. Azure Storage Queue<br/>d. Azure Event Hub|<details><summary>Answer</summary>a. Azure Service Bus Topic<br/>b. Azure Service Bus Queue<br/><br/>Azure event hub does not support duplicate detection and Azure storage queue does not provide transactional support.<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted</details>|
|13|You are developing a website that will store the scanned copies of patient health records. If the health records are downloaded from storage by a third party, the contents of the forms must not be compromised.<br/><br/>To achieve the requirement, you plan to store the health records in an Azure Key Vault as secrets.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. No<br/><br/>Instead, encrypt the forms and Store the encrypted from in Azure Storage Blob storage.</details>|
|14|You are developing a website that will store the scanned copies of patient health records. If the health records are downloaded from storage by a third party, the contents of the forms must not be compromised.<br/><br/>To achieve the requirement, you plan to create an Azure Cosmos DB database with Storage service encryption enabled and store the health records in the database.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. No<br/><br/>This approach will encrypt the data at rest. However, once data is read by a 3d party, it is not guaranteed that forms are not compromised.</details>|
|15|You are developing a website that will store the scanned copies of patient health records. If the health records are downloaded from storage by a third party, the contents of the forms must not be compromised.<br/><br/>To achieve the requirement, you plan to create an Azure Key Vault key, use the key to encrypt the health records and store the encrypted health records in an Azure Blob storage.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>a. yes<br/><br/>Since health records are encrypted with a key, 3rd party cannot modify the forms.</details>|
|16|You develop an Azure Function app that uses HTTP trigger. The Azure Function app process data stored in an Azure blob storage. The Azure Function app is triggered using an output binding on the blob.<br/>The Function app continues to time out after four minutes. The Function app must process the blob data.<br/>You need to implement a solution so that the Function app does not time out and processes the blob data.<br/><br/>You plan to use the Durable Function async pattern to process the blob data.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>a. yes<br/><br/>The maximum amount of time that an HTTP triggered function can take to respond to a request is 230 seconds. This is because of the default idle timeout of Azure Load Balancer. For longer processing times, consider using the Durable Functions async pattern. <br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale#timeout</details>|
|17|You develop an Azure Function app that uses HTTP trigger. The Azure Function app process data stored in an Azure blob storage. The Azure Function app is triggered using an output binding on the blob.<br/>The Function app continues to time out after four minutes. The Function app must process the blob data.<br/>You need to implement a solution so that the Function app does not time out and processes the blob data.<br/><br/>You plan to pass the HTTP trigger payload into an Azure Service Bus queue to be processed by a queue trigger function and return an immediate HTTP success response.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>a. yes<br/><br/>Large, long-running functions can cause unexpected timeout issues. Whenever possible, refactor large functions into smaller function sets that work together and return responses fast. For example, a webhook or HTTP trigger function might require an acknowledgment response within a certain time limit; it's common for webhooks to require an immediate response. You can pass the HTTP trigger payload into a queue to be processed by a queue trigger function. This approach lets you defer the actual work and return an immediate response.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-best-practices</details>|
|18|You develop an Azure Function app that uses HTTP trigger. The Azure Function app process data stored in an Azure blob storage. The Azure Function app is triggered using an output binding on the blob.<br/>The Function app continues to time out after four minutes. The Function app must process the blob data.<br/>You need to implement a solution so that the Function app does not time out and processes the blob data.<br/><br/>You plan to the app to use an App Service hosting plan and enable the Always On setting.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. No<br/><br/>Instead use Durable functions or use a queue/ event hub to pass the payload and trigger function from queue.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-best-practices</details>|
|19|You plan to deploy an application named Application1 in an Azure App Service.<br/>You need to eliminate file conflicts between deployments and improve cold-start performance.<br/><br/>Which setting should you configure in the Azure App Service ?<br/><br/>a. Set WEBSITE_RUN_FROM_PACKAGE = 0<br/>b. Set WEBSITE_RUN_FROM_PACKAGE = 1<br/>c. Set Always On to Off<br/>d. Set Always On to On|<details><summary>Answer</summary>b. Set WEBSITE_RUN_FROM_PACKAGE = 1<br/><br/>There are several benefits to running directly from a package:<br/>Eliminates file lock conflicts between deployment and runtime<br/>Ensures only full-deployed apps are running at any time.<br/>Can be deployed to a production app (with restart)<br/>Improves the performance of Azure Resource Manager deployments<br/>May reduce cold-start times, particularly for JavaScript functions with large npm package trees<br/>https://docs.microsoft.com/en-us/azure/app-service/deploy-run-package</details>|
|20|You are developing and deploying several ASP.NET web applications to Azure App Service. You plan to use sessions to store user information. You have configure auto-scaling in the Azure App Service.<br/>You need to ensure that session information is not lost when application scales out.<br/>What should you implement ?<br/><br/>a. Set ARR affinity to Off<br/>b. Set ARR affinity to On<br/>c. Set WEBSITE_RUN_FROM_PACKAGE = 0<br/>d. Set WEBSITE_RUN_FROM_PACKAGE = 1|<details><summary>Answer</summary>b. Set ARR affinity to On<br/><br/>ARR affinity: In a multi-instance deployment, ensure that the client is routed to the same instance for the life of the session. You can set this option to Off for stateless applications. If client is routed to different instances, then session data will be los<br/>https://docs.microsoft.com/en-us/azure/app-service/configure-common#configure-connection-strings</details>|
|21|You plan to deploy an application into an Azure virtual machine.<br/>Just in time (JIT) access has been enabled on the virtual machine.<br/>What should be your first step to connect to the virtual machine using remote desktop ?<br/><br/>a. From AAD Privileged Identity Management (PIM), activate the Security administator user role.<br/>b. From AAD PIM, activate the Owner role for the VM<br/>c. From the Azure portal, select the virtual machine VM1, select Connect, & then select Request access|<details><summary>Answer</summary>c. From the Azure portal, select the virtual machine VM1, select Connect, & then select Request access<br/><br/>You can request access to a JIT-enabled VM from the Azure portal (in Security Center or Azure Virtual machines) or programmatically. When a VM has a JIT enabled, you have to request access to connect to it. You can request access in any of the supported ways, regardless of how you enabled JIT.<br/>https://docs.microsoft.com/en-us/azure/security-center/security-center-just-in-time?tabs=jit-config-asc%2Cjit-request-avm#request-access-to-a-jit-enabled-v</details>
|22|Which of the following are valid sections in an Azure Resource Manager (ARM) template ?<br/><br/>a. Parameters<br/>b. Inputs<br/>c. Outputs<br/>d. Variables<br/>e. Comment<br/>f. User defined functions<br/>g. Resources<br/>h. Version|<details><summary>Answer</summary>a. Parameters<br/>c. Outputs<br/>d. Variables<br/>f. User defined function<br/>g. Resources<br/><br/>https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview#template-design</details>
|23|Which Azure RBAC roles allows you to download images from an Azure Container Registry ?<br/><br/>a. AcrPush<br/>b. AcrPull<br/>c. AcrImageSigner<br/>d. contributor|<details><summary>Answer</summary>a. AcrPush<br/>b. AcrPull<br/>d. Contributor<br/><br/>The Azure Container Registry service supports a set of built-in Azure roles that provide different levels of permissions to an Azure container registry. Use Azure role-based access control (Azure RBAC) to assign specific permissions to users, service principals, or other identities that need to interact with a registry<br/>https://docs.microsoft.com/bs-latn-ba/azure/container-registry/container-registry-roles</details>
|24|You create a container image named Image1.<br/>The Image1 processes long running tasks.<br/>Which restart policy should you consider for Image1 ?<br/><br/>a. Always<br/>b. Never<br/>c. OnFailure|<details><summary>Answer</summary>a. Always<br/><br/>The restart policy Always will ensure needed processes continue to be available even if a restart is required<br/>https://docs.microsoft.com/en-us/azure/container-instances/container-instances-restart-policy</details>
|25|You have an Azure Container Registry named Registry1. You need to publish an image named Image1 to Finance namespace.<br/><br/>Select the command should you use.<br/><br/>a. docker push finance.azurecr.io/registry1/image1<br/>b. docker push registry1.azurecr/finance/image1<br/>c. docker push registry.azurecr.io/finance/image1<br/>d. docker push finance.azurecr/registry1/image1|<details><summary>Answer</summary>c. docker push registry1.azurecr.io/finance/image1<br/><br/>docker push is the command to push an image to Azure Container registry. The correct format is docker push <registryname>.azureacr.io/<namespace>/<imagename><br/>https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-docker-cli</details>|
|26|You plan to deploy a web application in an Azure App Service.<br/>The application logs must be captured and retained for long-term.<br/>Which three actions should you perform in sequence ?<br/><br/>a. Navigate to Azure App Service<br/>Select App Service Logs<br/>Turn on Application logging File System<br/><br/>b. Navigate to Azure App Service<br/>Select App Service Logs<br/>Turn on Application logging Blob<br/><br/>c. Navigate to Azure App Service<br/>Select App Service Logs<br/>Turn on Web server logging Storage<br/><br/>d. Navigate to Azure App Service<br/>Select App Service Logs<br/>Turn on Web server logging File system|<details><summary>Answer</summary>b. Navigate to Azure App Service<br/>Select App Service Logs<br/>Turn on Application logging Blob<br/><br/>To enable application logging for Windows apps in the Azure portal, navigate to your app and select App Service logs<br/>Select On for either Application Logging (Filesystem) or Application Logging (Blob), or both.<br/>The Filesystem option is for temporary debugging purposes, and turns itself off in 12 hours. The Blob option is for long-term logging, and needs a blob storage container to write logs to.<br/>https://docs.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs</details>
|27|You are developing an application that uploads videos to an Azure storage container named Container1.<br/>The upload method uses Storage REST APIs.<br/><br/>You need to copy specific blobs from Container1 to Container2 in real time when specific business requirements are met. The copies must exclude backup blobs.<br/><br/>What should you do ?<br/><br/>a. Download the videos to a VM from Container1 & then upload the blob to Container2<br/>b. Execute the Azure PowerShell command Start-AzureStorageBlobCopy<br/>c. Copy blobs to Container2 by using the Put Blob operation of the Blob Service REST API.<br/>d. Use AzCopy with the Snapshot switch blobs to Container2|<details><summary>Answer</summary>b. Execute the Azure PowerShell command Start-AzureStorageBlobCopy<br/><br/>The Start-AzureStorageBlobCopy cmdlet starts to copy a blob<br/>https://docs.microsoft.com/en-us/powershell/module/azure.storage/start-azurestorageblobcopy?view=azurermps-6.13.0<br/>The Put Blob operation creates a new block, page, or append blob, or updates the content of an existing block blob. So in the given options, onlyStart-AzureStorageBlobCopy cmdlet copies the blob</details>
|28|You plan to develop an application that will be deployed to an Azure virtual machine.<br/>The application connects to external services that are authenticated using a secret key.<br/>You plan to store secret keys in an Azure Key Vault.<br/>Select the authentication method you must consider to read secrets from Key Vault.<br/><br/>a. Service principal & certificate<br/>b. Managed Identity<br/>c. Service principal & secret|<details><summary>Answer</summary>b. Managed Identity<br/><br/>Managed identities for Azure resources: When you deploy an app on a virtual machine in Azure, you can assign an identity to your virtual machine that has access to Key Vault. You can also assign identities to other Azure resources. The benefit of this approach is that the app or service isn't managing the rotation of the first secret. Azure automatically rotates the identity. We recommend this approach as a best practice.<br/>https://docs.microsoft.com/en-us/azure/key-vault/general/basic-concepts#authentication</details>
|29|You are developing a web application that will be accessible using application1.azurewebsites.net. The traffic to the web application must be secured with SSL and routed through an Azure Application Gateway.<br/>The Azure application gateway instance is used by multiple applications.<br/><br/>Select the two actions should you perform to configure Azure Application Gateway.<br/><br/>a. Enable the Use for App service setting in the Azure Application Gateway's HTTP settings<br/>b. Convert the web app to run in an Azure App service environment (ASE)<br/>c. Ad authentication certificate to the Azure Application gateway<br/>d. Set the value of the Override backed path option to application1.azurewebsites.net in the Azure Application Gateway's HTTP settings|<details><summary>Answer</summary>a. Enable the Use for App service setting in the Azure Application Gateway's HTTP settings<br/><br/>d. Set the value of the Override backend path option to application1.azurewebsites.net in the Azure Application Gateway's HTTP settings<br/><br/>In multi-tenant architectural designs in web servers, multiple websites are running on the same web server instance. Hostnames are used to differentiate between the different applications which are hosted. Application gateway provides a capability which allows users to override the HTTP host header in the request based on the host name of the back-end. This capability enables support for multi-tenant back ends such as Azure App service web apps and API management<br/>The ability to specify a host override is defined in the HTTP settings and can be applied to any back-end pool during rule creation. The following two ways of overriding host header and SNI extension for multi-tenant back ends is supported: <br/>The ability to set the host name to a fixed value explicitly entered in the HTTP settings. This capability ensures that the host header is overridden to this value for all traffic to the back-end pool where the particular HTTP settings are applied. When using end to end TLS, this overridden host name is used in the SNI extension. This capability enables scenarios where a back-end pool farm expects a host header that is different from the incoming customer host header.<br/>The ability to derive the host name from the IP or FQDN of the back-end pool members. HTTP settings also provide an option to dynamically pick the host name from a back-end pool member's FQDN if configured with the option to derive host name from an individual back-end pool member. When using end to end TLS, this host name is derived from the FQDN and is used in the SNI extension. This capability enables scenarios where a back-end pool can have two or more multi-tenant PaaS services like Azure web apps and the request's host header to each member contains the host name derived from its FQDN. For implementing this scenario, we use a switch in the HTTP Settings called Pick hostname from backend address which will dynamically override the host header in the original request to the one mentioned in the backend pool.<br/>[img src="https://i.imgur.com/tOIkJtk.png">](https://i.imgur.com/tOIkJtk.png)<br/>https://docs.microsoft.com/en-us/azure/application-gateway/application-gateway-web-app-overview#tls-termination-and-end-to-end-tls-with-multi-tenant-services</details>
|30|You are developing an Azure App Service web app to deliver video on-demand streaming media. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node.<br/>You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint.<br/>Customer videos are downloaded from the web app by using the following example URL.: http://www.webapplication.com/content.mp4?quality=1<br/><br/>All videos must expire from the cache after one hour.<br/>You need to configure Azure CDN caching rules.<br/>Which option should you use for caching behavior ?<br/><br/>a. Bypass Cache<br/>b. Override<br/>c. Set if missing|<details><summary>Answer</summary>True</details>|
|31|You are developing an Azure App Service web app to deliver video on-demand streaming media. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node.<br/>You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint.<br/><br/>Customer videos are downloaded from the web app by using the following example URL.: http://www.webapplication.com/content.mp4?quality=1<br/><br/>All videos must expire from the cache after one hour.<br/>You need to configure Azure CDN caching rules.<br/>Which option should you use for cache expiration duration ?<br/><br/>a. 1 Second<br/>b. 1 Minute<br/>c. 1 Month<br/>d. 1 Hour|<details><summary>Answer</summary>True</details>|
|32|You are developing an Azure App Service web app to deliver video on-demand streaming media. Customer videos with varying quality must be delivered to the closest regional point of presence (POP) node.<br/>You enable an Azure Content Delivery Network (CDN) Standard for the web endpoint.<br/><br/>Customer videos are downloaded from the web app by using the following example URL.: http://www.webapplication.com/content.mp4?quality=1<br/><br/>All videos must expire from the cache after one hour.<br/>You need to configure Azure CDN caching rules.<br/>Which option should you configure for query string caching behavior ?<br/><br/>a. Ignore Query Strings<br/>b. Bypass caching for query strings<br/>c. Cache every unique URL|<details><summary>Answer</summary>True</details>|
|33|You are developing a HTTP-based API to support a web app.<br/>The primary functionality of the API is to allow customers to check the status of their orders.<br/>You need to use Azure Functions to implement the API.<br/>The API must not allow write operations. However, it must provide pubic read only operations.<br/>You need to recommend a configuration option for authorization level.<br/>What should you recommend ?<br/><br/>a. Anonymous<br/>b. Function<br/>c. Admin|<details><summary>Answer</summary>True</details>|
|34|You plan to publish an API for your customers by using Azure API Management. The API uses JWT token for user authorization.<br/><br/>You need to implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID.<br/><br/>You need to add a set-variable policy to store the detected user identity to the policies file.<br/><br/>To which section of the policy should you add ?<br/><br/>a. Inbound<br/>b. Outbound|<details><summary>Answer</summary>True</details>|
|35|You plan to publish an API for your customers by using Azure API Management. The API uses JWT token for user authorization.<br/>You need to implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID.<br/>You need to add a cache-lookup-value policy to the policies file.<br/>To which section of the policy should you add ?<br/><br/>a. Inbound<br/>b. Outbound|<details><summary>Answer</summary>True</details>|
|36|You plan to publish an API for your customers by using Azure API Management. The API uses JWT token for user authorization.<br/>You need to implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID.<br/>You need to add a cache-store-value policy to the policies file.<br/>To which section of the policy should you add ?<br/><br/>a. Inbound<br/>b. Outbound|<details><summary>Answer</summary>True</details>|
|37|You plan to publish an API for your customers by using Azure API Management. The API uses JWT token for user authorization.<br/>You need to implement response caching for the APIM gateway. The caching mechanism must detect the user ID of the client that accesses data for a given location and cache the response for that user ID.<br/>You need to add a find-and-replace policy to the policies file to update the response body with the user profile information.<br/>To which section of the policy should you add ?<br/><br/>a. Inbound<br/>b. Outbound|<details><summary>Answer</summary>True</details>|
|38|You have developed several web APIs. The web APIs are published by using Azure API Management.<br/>You are developing several web apps that will use the Web APIs.<br/>Both web apps and web APIs are registered with your Azure Active Directory (Azure AD) tenant.<br/>You need to implement a solution to block unauthorized requests originating from the web apps from reaching the web APIs.<br/>The solution must use Azure AD generated claims and minimize the configuration effort.<br/>What should you implement ?<br/><br/>a. AAD<br/>b. API Management API Restriction Policy<br/>c. API Management Cross domain policy|<details><summary>Answer</summary>True</details>|
|39|You plan to create a virtual machine in your Azure subscription using PowerShell.<br/>Which two parameters should you add to complete below command ?<br/><br/>New-AzVm -Name "myVM" -Location "East US" -SubnetName "mySubnet" -SecurityGroupName "myNetworkSecurityGroup" -PublicIpAddressName "myPublicIpAddress" -OpenPorts 80,3389<br/><br/>a. -ResourceGroupname "myResourceGroup"<br/>b. -DiskSize 50 000<br/>c. -VirtualNetworkname "myVnet"<br/>d. -OperatingSystem "win2016datacenter"|<details><summary>Answer</summary>True</details>|
|40|You have a Resource Group named RG1 in an Azure subscription named Subscription1.<br/>You have created an Azure virtual machine in RG1 using Azure Portal.<br/>You need to download the Azure Resource Manager (ARM) template of the newly created VM to re-use in your next deployments.<br/>Select the steps should you follow in sequence.<br/><br/>a. Login to Azure Portal<br/>Select the VM created using Azure Portal<br/>Select Export template & download<br/><br/>b. Login to Azure Portal<br/>Select the VM created using Azure Portal<br/>Select activity log & download<br/><br/>c. Login to Azure Portal<br/>Select the VM created using Azure Portal<br/>Select logs & download<br/><br/>d. Login to Azure Portal<br/>Select the VM created using Azure Portal<br/>Select the VM created using Azure Portal<br/>Select continuous delivery & download scripts|<details><summary>Answer</summary>True</details>|
|41|You need to view container startup events.<br/>Which troubleshooting command should you use ?<br/>a. az container logs<br/>b. az container attach<br/>c. az container exec|<details><summary>Answer</summary>True</details>|
|42|You plan to develop an application using Azure App Service and Azure Cosmos DB.<br/>You need to collect detailed resource logs for monitoring health and availability of Azure resources.<br/>Which of the following actions you should perform to send logs to Log Analytics workspace ?<br/><br/>a. Create a Log Analytics Workspace<br/>Enable Diagnostic settings<br/>Select log categories<br/>Select Send to Log Analytics<br/><br/>b. Create a Storage account<br/>Enable Diagnostic settings<br/>Select log categories<br/>Select Send to Storage account<br/>Configure Log Analytics to connect to Storage account<br/><br/>c. Create a Log Analytics Workspace<br/>Enable Diagnostic settings<br/>Select log categories<br/>Select Send to Log Analytics & Storage accounts|<details><summary>Answer</summary>True</details>|
|43|You plan to develop an application using Azure Functions.<br/>You need to use the Azure Function triggers that have built-in retry support.<br/>Which triggers should you use ?<br/><br/>a. Azure Blob storage<br/>b. Azure Queue storage<br/>c. Azure Service Bus (queue/topic)<br/>d. Azure Table Storage<br/>e. Azure Cosmos DB<br/>f. Event Hubs|<details><summary>Answer</summary>True</details>|
|44|You are developing an application that must execute a sequence of activities in a specific order.<br/>You plan to deploy the application in a serverless compute environment.<br/>Which of the below service should you create to deploy the application ?<br/><br/>a. Azure Functions<br/>b. Durable Functions<br/>c. Azure App Service|<details><summary>Answer</summary>True</details>|
|45|You have an Azure Cosmos DB. You need to configure consistency level that consumes the least amount of request units per operation.<br/>Which consistency level should you configure ?<br/><br/>a. Strong<br/>b. Bounded Staleness<br/>c. Session<br/>d. Consistent Prefix<br/>e. Eventual|<details><summary>Answer</summary>True</details>|
|46|You are developing an application that uses Azure Cosmos DB for a hospital.<br/>You have configured the default consistency level for the database to Strong and Indexing mode to Consistent.<br/>If multiple users in different locations have updated a patient record, the application must return latest patient status details.<br/>You need to override the default consistency level at the query level.<br/>Which consistency level should you implement to return patient status ?<br/><br/>a. Strong<br/>b. Consistent Prefix<br/>c. Bounded Staleness<br/>d. Eventual|<details><summary>Answer</summary>True</details>|
|47|You are developing an application that uses Azure Cosmos DB for a hospital.<br/>You have configured the default consistency level for the database to Strong and Indexing mode to Consistent.<br/>The application must return the health monitoring data of a patent in the current version or the prior version.<br/>You need to override the default consistency level at the query level.<br/>Which consistency level should you implement to return health monitoring data ?<br/><br/>a. Strong<br/>b. Consistent Prefix<br/>c. Bounded Staleness<br/>d. Eventual|<details><summary>Answer</summary>True</details>|
|48|You are developing an application that uses Azure Cosmos DB for a hospital.<br/>You have configured the default consistency level for the database to Strong and Indexing mode to Consistent.<br/>The patient billing record contains the final charges once a patient is discharged and all charges have been assessed.<br/>You need to override the default consistency level at the query level.<br/>Which consistency level should you implement to retrieve the correct billing data with the final changes ?<br/><br/>a. Strong<br/>b. Consistent Prefix<br/>c. Bounded Staleness<br/>d. Eventual|<details><summary>Answer</summary>True</details>|
|49|You are developing an application that stores customer information in an Azure Cosmos DB.<br/>The customer details is partitioned by last name.<br/>You need to implement a query that returns all customers with the last name Smith.<br/>Which code segment should you use ?<br/><br/>a. TableQuery.GenerateFilterCondition("PartitionKey",Equals,"Smith")<br/>b. TableQuery.GenerateFilterCondition("LastName",Equals,"Smith")<br/>c. TableQuery.GenerateFilterCondition("PartitionKey",QueryConparisons.Equal,"smith")<br/>d. TableQuery.GenrateFilterCondition("LastName",QueryComparisons.Equal,"smith")|<details><summary>Answer</summary>True</details>|
|50|You have an Azure Storage account that contains several blobs. The files are set to use the archive access tier.<br/>You need to ensure a file named File1 is accessible within in two hours once a retrieval request is initiated.<br/>Select rehydration priority should you use.<br/><br/>a. General Priority<br/>b. Standard Priority<br/>c. High Priority|<details><summary>Answer</summary>True</details>|
|51|**Overview -**<br/>You are a developer for Adam, Ltd.<br/>The company has a social networking website that is developed as a Single Page Application (SPA).<br/>The social networking website loads user uploaded content from an Azure blob storage. You are developing a solution to monitor the user uploaded data for inappropriate content.<br/><br/>The following process occurs when users upload content by using the social networking website:<br/>Messages are sent to ContentUploadService.<br/>Content is processed by ContentAnalysisService.<br/>After processing is complete, the content is either posted to the social network or a rejection message is posted in its place.<br/><br/>The ContentAnalysisService is deployed with Azure Container Instances from a private Azure Container Registry named AdamImages.<br/>The solution will use eight CPU cores.<br/><br/>**Azure Active Directory -**<br/>Azure Active Directory (Azure AD) is used for both internal and guest accounts.<br/><br/>**Requirements -**<br/><br/>ContentAnalysisService -<br/>The Companyâs data science group built ContentAnalysisService which accepts user generated content as a string and returns a probable value for inappropriate content.<br/>Any values over a specific threshold must be reviewed by an employee of Adam, Ltd.<br/>You must create an Azure Function named CheckUserContent to perform the content checks.<br/><br/>**Costs -**<br/>The solution must minimize costs for all Azure services.<br/><br/>**Manual review -**<br/>To review content, the user must authenticate to the website portion of the ContentAnalysisService using their Azure AD credentials.<br/>The website is built using React and all pages and API endpoints require authentication.<br/>In order to review content a user must be part of a ContentReviewer role.<br/>All completed reviews must include the reviewer's email address for auditing purposes.<br/><br/>**High availability -**<br/>The region failures must not impact overall application availability.<br/><br/>**Monitoring -**<br/>An alert must be raised if the ContentUploadService uses more than 80 percent of available CPU-cores.<br/><br/>**Security Requirements-**<br/>Any web service accessible over the Internet must be protected from cross site scripting attacks.<br/>All websites and services must use SSL from a valid root certificate authority.<br/>Azure Storage access keys must only be stored in memory and must be available only to the service.<br/>All Internal services must only be accessible from Internal Virtual Networks (VNets)<br/>All parts of the system must support inbound and outbound traffic restrictions.<br/>All service calls must be authenticated by using Azure AD.<br/><br/>**User agreements -**<br/>Users must agree to a user agreement before submitting content.<br/>The agreement allows employees of Adam.Ltd to review content, store cookies on user devices and track user's IP addresses.<br/>Information regarding agreements is used by multiple divisions within Adam, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime.<br/>The volume of agreements is expected to be in the millions per hour.<br/><br/>**Validation testing -**<br/>When a new version of the ContentAnalysisService is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version.<br/><br/>**Issues -**<br/>Users of the ContentUploadService report that they occasionally see HTTP 502 responses on specific pages.<br/><br/>ContentUploadService code is as below. Line number are for reference only.<br/>[<img src="https://i.imgur.com/fTNHZA6.png">](https://i.imgur.com/fTNHZA6.png)<br/>ApplicationManifest code is as below<br/>[<img src="https://i.imgur.com/J0R5Nen.png">](https://i.imgur.com/J0R5Nen.png)<br/>**Question**<br/>You need to add code at line AM09 to ensure that users can review content using contentAnalysisService.<br/>How should you complete the code ?<br/><br/>a. "oauth2AllowImplicitFlow":true<br/>"preAuthorizedApplications":["SPA"]<br/><br/>b. "oauth2AllowImplicitFlow":true<br/>"oautth2AllowIdTokenImplicitFlow":true<br/><br/>c. "allowPublicClient":true<br/>"oauth2AllowIdTokenImplicitFlow":true<br/><br/>d. "oauth2Permissions":["login"]<br/>"oauth2AllowIdTokenImplicitFlow":true|<details><summary>Answer</summary>True</details>|
|52|**Overview -**<br/>You are a developer for Adam, Ltd.<br/>The company has a social networking website that is developed as a Single Page Application (SPA).<br/>The social networking website loads user uploaded content from an Azure blob storage. You are developing a solution to monitor the user uploaded data for inappropriate content.<br/><br/>The following process occurs when users upload content by using the social networking website:<br/>Messages are sent to ContentUploadService.<br/>Content is processed by ContentAnalysisService.<br/>After processing is complete, the content is either posted to the social network or a rejection message is posted in its place.<br/><br/>The ContentAnalysisService is deployed with Azure Container Instances from a private Azure Container Registry named AdamImages.<br/>The solution will use eight CPU cores.<br/><br/>**Azure Active Directory -**<br/>Azure Active Directory (Azure AD) is used for both internal and guest accounts.<br/><br/>**Requirements -**<br/><br/>ContentAnalysisService -<br/>The Companyâs data science group built ContentAnalysisService which accepts user generated content as a string and returns a probable value for inappropriate content.<br/>Any values over a specific threshold must be reviewed by an employee of Adam, Ltd. You must create an Azure Function named CheckUserContent to perform the content checks.<br/><br/>**Costs -**<br/>The solution must minimize costs for all Azure services.<br/><br/>**Manual review -**<br/>To review content, the user must authenticate to the website portion of the ContentAnalysisService using their Azure AD credentials.<br/>The website is built using React and all pages and API endpoints require authentication.<br/>In order to review content a user must be part of a ContentReviewer role.<br/>All completed reviews must include the reviewer's email address for auditing purposes.<br/><br/>**High availability -**<br/>The region failures must not impact overall application availability.<br/><br/>**Monitoring -**<br/>An alert must be raised if the ContentUploadService uses more than 80 percent of available CPU-cores.<br/><br/>**Security Requirements-**<br/>Any web service accessible over the Internet must be protected from cross site scripting attacks.<br/>All websites and services must use SSL from a valid root certificate authority.<br/>Azure Storage access keys must only be stored in memory and must be available only to the service.<br/>All Internal services must only be accessible from Internal Virtual Networks (VNets)<br/>All parts of the system must support inbound and outbound traffic restrictions.<br/>All service calls must be authenticated by using Azure AD.<br/><br/>**User agreements -**<br/>Users must agree to a user agreement before submitting content.<br/>The agreement allows employees of Adam.Ltd to review content, store cookies on user devices and track user's IP addresses.<br/>Information regarding agreements is used by multiple divisions within Adam, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime.<br/>The volume of agreements is expected to be in the millions per hour.<br/><br/>**Validation testing -**<br/>When a new version of the ContentAnalysisService is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version.<br/><br/>**Issues -**<br/>Users of the ContentUploadService report that they occasionally see HTTP 502 responses on specific pages.<br/><br/>ContentUploadService code is as below. Line number are for reference only.<br/>[<img src="https://i.imgur.com/fTNHZA6.png">](https://i.imgur.com/fTNHZA6.png)<br/>ApplicationManifest code is as below<br/>[<img src="https://i.imgur.com/J0R5Nen.png">](https://i.imgur.com/J0R5Nen.png)<br/>**Question**<br/>You need to ensure that network security policies are met. How should you configure network security ?<br/><br/>a. SSL Certificate : Valid root certificate<br/>Proxy Type : ngnix<br/><br/>b. SSL Certificate : Self-signed certificate<br/>Proxy Type : ngninx<br/>c. SSL Certificate : Self-signed certificate<br/>Proxy Type : Azure Application Gateway<br/><br/>d. SSL Certificate : Valide root certificate<br/>Proxy Type : Azure Application Gateway|<details><summary>Answer</summary>True</details>|
|53|**Overview -**<br/>You are a developer for Adam, Ltd.<br/>The company has a social networking website that is developed as a Single Page Application (SPA).<br/>The social networking website loads user uploaded content from an Azure blob storage. You are developing a solution to monitor the user uploaded data for inappropriate content.<br/><br/>The following process occurs when users upload content by using the social networking website:<br/>Messages are sent to ContentUploadService.<br/>Content is processed by ContentAnalysisService.<br/>After processing is complete, the content is either posted to the social network or a rejection message is posted in its place.<br/><br/>The ContentAnalysisService is deployed with Azure Container Instances from a private Azure Container Registry named AdamImages.<br/>The solution will use eight CPU cores.<br/><br/>**Azure Active Directory -**<br/>Azure Active Directory (Azure AD) is used for both internal and guest accounts.<br/><br/>**Requirements -**<br/><br/>ContentAnalysisService -<br/>The Companyâs data science group built ContentAnalysisService which accepts user generated content as a string and returns a probable value for inappropriate content.<br/>Any values over a specific threshold must be reviewed by an employee of Adam, Ltd. You must create an Azure Function named CheckUserContent to perform the content checks.<br/><br/>**Costs -**<br/>The solution must minimize costs for all Azure services.<br/><br/>**Manual review -**<br/>To review content, the user must authenticate to the website portion of the ContentAnalysisService using their Azure AD credentials.<br/>The website is built using React and all pages and API endpoints require authentication.<br/>In order to review content a user must be part of a ContentReviewer role.<br/>All completed reviews must include the reviewer's email address for auditing purposes.<br/><br/>**High availability -**<br/>The region failures must not impact overall application availability.<br/><br/>**Monitoring -**<br/>An alert must be raised if the ContentUploadService uses more than 80 percent of available CPU-cores.<br/><br/>**Security Requirements-**<br/>Any web service accessible over the Internet must be protected from cross site scripting attacks.<br/>All websites and services must use SSL from a valid root certificate authority.<br/>Azure Storage access keys must only be stored in memory and must be available only to the service.<br/>All Internal services must only be accessible from Internal Virtual Networks (VNets)<br/>All parts of the system must support inbound and outbound traffic restrictions.<br/>All service calls must be authenticated by using Azure AD.<br/><br/>**User agreements -**<br/>Users must agree to a user agreement before submitting content.<br/>The agreement allows employees of Adam.Ltd to review content, store cookies on user devices and track user's IP addresses.<br/>Information regarding agreements is used by multiple divisions within Adam, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime.<br/>The volume of agreements is expected to be in the millions per hour.<br/><br/>**Validation testing -**<br/>When a new version of the ContentAnalysisService is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version.<br/><br/>**Issues -**<br/>Users of the ContentUploadService report that they occasionally see HTTP 502 responses on specific pages.<br/><br/>ContentUploadService code is as below. Line number are for reference only.<br/>[<img src="https://i.imgur.com/fTNHZA6.png">](https://i.imgur.com/fTNHZA6.png)<br/>ApplicationManifest code is as below<br/>[<img src="https://i.imgur.com/J0R5Nen.png">](https://i.imgur.com/J0R5Nen.png)<br/>**Question**<br/>You need to configure the ContentUploadService deployment. Which two actions should you perform ?<br/><br/>a. Add the following markup to line number 34:types:Private<br/>b. Add the following markup to line number 34:types:Public<br/>c. Add the following markup to line number 35:osType:Windows<br/>d. Add the following markup to line number 35:osType:Linux|<details><summary>Answer</summary>True</details>|
|54|**Overview -**<br/>You are a developer for Adam, Ltd.<br/>The company has a social networking website that is developed as a Single Page Application (SPA).<br/>The social networking website loads user uploaded content from an Azure blob storage. You are developing a solution to monitor the user uploaded data for inappropriate content.<br/><br/>The following process occurs when users upload content by using the social networking website:<br/>Messages are sent to ContentUploadService.<br/>Content is processed by ContentAnalysisService.<br/>After processing is complete, the content is either posted to the social network or a rejection message is posted in its place.<br/><br/>The ContentAnalysisService is deployed with Azure Container Instances from a private Azure Container Registry named AdamImages.<br/>The solution will use eight CPU cores.<br/><br/>**Azure Active Directory -**<br/>Azure Active Directory (Azure AD) is used for both internal and guest accounts.<br/><br/>**Requirements -**<br/><br/>ContentAnalysisService -<br/>The Companyâs data science group built ContentAnalysisService which accepts user generated content as a string and returns a probable value for inappropriate content.<br/>Any values over a specific threshold must be reviewed by an employee of Adam, Ltd. You must create an Azure Function named CheckUserContent to perform the content checks.<br/><br/>**Costs -**<br/>The solution must minimize costs for all Azure services.<br/><br/>**Manual review -**<br/>To review content, the user must authenticate to the website portion of the ContentAnalysisService using their Azure AD credentials.<br/>The website is built using React and all pages and API endpoints require authentication.<br/>In order to review content a user must be part of a ContentReviewer role.<br/>All completed reviews must include the reviewer's email address for auditing purposes.<br/><br/>**High availability -**<br/>The region failures must not impact overall application availability.<br/><br/>**Monitoring -**<br/>An alert must be raised if the ContentUploadService uses more than 80 percent of available CPU-cores.<br/><br/>**Security Requirements-**<br/>Any web service accessible over the Internet must be protected from cross site scripting attacks.<br/>All websites and services must use SSL from a valid root certificate authority.<br/>Azure Storage access keys must only be stored in memory and must be available only to the service.<br/>All Internal services must only be accessible from Internal Virtual Networks (VNets)<br/>All parts of the system must support inbound and outbound traffic restrictions.<br/>All service calls must be authenticated by using Azure AD.<br/><br/>**User agreements -**<br/>Users must agree to a user agreement before submitting content.<br/>The agreement allows employees of Adam.Ltd to review content, store cookies on user devices and track user's IP addresses.<br/>Information regarding agreements is used by multiple divisions within Adam, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime.<br/>The volume of agreements is expected to be in the millions per hour.<br/><br/>**Validation testing -**<br/>When a new version of the ContentAnalysisService is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version.<br/><br/>**Issues -**<br/>Users of the ContentUploadService report that they occasionally see HTTP 502 responses on specific pages.<br/><br/>ContentUploadService code is as below. Line number are for reference only.<br/>[<img src="https://i.imgur.com/fTNHZA6.png">](https://i.imgur.com/fTNHZA6.png)<br/>ApplicationManifest code is as below<br/>[<img src="https://i.imgur.com/J0R5Nen.png">](https://i.imgur.com/J0R5Nen.png)<br/>**Question**<br/>You need to add markup at line AM04 to implement the ContentReview role.<br/>How should you complete the markup ?<br/><br/>a. ""appRoles":[<br/>{<br/>"allowedMemberType":[<br/>"user"<br/>],<br/>"displayName":"ContenReviewer",<br/>"id":"e1c2ade8-98f8-45fd-aa4a-6d24b512c22a",<br/>"isEnabled":true,<br/>"role":"ContentReviewer"<br/>}<br/>],<br/><br/>b. "appRoles""[<br/>{<br/>"allowdMemberTypes":[<br/>"User"<br/>],<br/>"displayName":"ContentReviewer",<br/>"id":"e1c2ade8-98f8-45fd-aa4a-6d24b512c22a",<br/>"isEnabled":true,<br/>"value":"ContentReviewer"<br/>}<br/>],<br/><br/>c. "appRoles":[<br/>{"allowdAccountTypes":[<br/>"User"<br/>],<br/>"displayName":"ContentReviewer",<br/>"id":"e1c2ade8-98f8-45fd-aa4a-6d24b512c22a",<br/>"isEnabled":true,<br/>"value":"ContentReviewer"<br/>}<br/>],<br/><br/>d. "appRoles":[<br/>{<br/>"allowedAccountTypes":[<br/>"User"<br/>],<br/>"displayName":"ContentReviewer",<br/>"id":"e1c2ade8-98f8-45fd-aa4a-6d24b512c22a",<br/>"isEnabled":true,<br/>"role":"ContentReviewer"<br/>}<br/>],|<details><summary>Answer</summary>True</details>|
|55|**Overview -**<br/>You are a developer for Adam, Ltd.<br/>The company has a social networking website that is developed as a Single Page Application (SPA).<br/>The social networking website loads user uploaded content from an Azure blob storage. You are developing a solution to monitor the user uploaded data for inappropriate content.<br/><br/>The following process occurs when users upload content by using the social networking website:<br/>Messages are sent to ContentUploadService.<br/>Content is processed by ContentAnalysisService.<br/>After processing is complete, the content is either posted to the social network or a rejection message is posted in its place.<br/><br/>The ContentAnalysisService is deployed with Azure Container Instances from a private Azure Container Registry named AdamImages.<br/>The solution will use eight CPU cores.<br/><br/>**Azure Active Directory -**<br/>Azure Active Directory (Azure AD) is used for both internal and guest accounts.<br/><br/>**Requirements -**<br/><br/>ContentAnalysisService -<br/>The Companyâs data science group built ContentAnalysisService which accepts user generated content as a string and returns a probable value for inappropriate content.<br/>Any values over a specific threshold must be reviewed by an employee of Adam, Ltd. You must create an Azure Function named CheckUserContent to perform the content checks.<br/><br/>**Costs -**<br/>The solution must minimize costs for all Azure services.<br/><br/>**Manual review -**<br/>To review content, the user must authenticate to the website portion of the ContentAnalysisService using their Azure AD credentials.<br/>The website is built using React and all pages and API endpoints require authentication.<br/>In order to review content a user must be part of a ContentReviewer role.<br/>All completed reviews must include the reviewer's email address for auditing purposes.<br/><br/>**High availability -**<br/>The region failures must not impact overall application availability.<br/><br/>**Monitoring -**<br/>An alert must be raised if the ContentUploadService uses more than 80 percent of available CPU-cores.<br/><br/>**Security Requirements-**<br/>Any web service accessible over the Internet must be protected from cross site scripting attacks.<br/>All websites and services must use SSL from a valid root certificate authority.<br/>Azure Storage access keys must only be stored in memory and must be available only to the service.<br/>All Internal services must only be accessible from Internal Virtual Networks (VNets)<br/>All parts of the system must support inbound and outbound traffic restrictions.<br/>All service calls must be authenticated by using Azure AD.<br/><br/>**User agreements -**<br/>Users must agree to a user agreement before submitting content.<br/>The agreement allows employees of Adam.Ltd to review content, store cookies on user devices and track user's IP addresses.<br/>Information regarding agreements is used by multiple divisions within Adam, Ltd. User responses must not be lost and must be available to all parties regardless of individual service uptime.<br/>The volume of agreements is expected to be in the millions per hour.<br/><br/>**Validation testing -**<br/>When a new version of the ContentAnalysisService is available the previous seven days of content must be processed with the new version to verify that the new version does not significantly deviate from the old version.<br/><br/>**Issues -**<br/>Users of the ContentUploadService report that they occasionally see HTTP 502 responses on specific pages.<br/><br/>ContentUploadService code is as below. Line number are for reference only.<br/>[<img src="https://i.imgur.com/fTNHZA6.png">](https://i.imgur.com/fTNHZA6.png)<br/>ApplicationManifest code is as below<br/>[<img src="https://i.imgur.com/J0R5Nen.png">](https://i.imgur.com/J0R5Nen.png)<br/>**Question**<br/>You need to investigate the http server log output to resolve the issue with the ContentUploadService. Which command should you use first ?<br/><br/>a. az webapp log<br/>b. az ams live-output<br/>c. az monitor activity-log<br/>d. az container attach|<details><summary>Answer</summary>True</details>|

---

## Results
|n|Date|Note|Revision|
|-|----|----|--------|
|1|18-07-2023 PM|29/55 = 52%|<details><summary>Revision</summary>True</details>|
