# Test07 - Î£45

---

## Questions
|n|Question|Answer|
|-|--------|------|
|1|You are developing an order processing system.<br/>A point of sale application publishes orders to topics in an Azure Service Bus queue.<br/>The Label property for the topic includes the following data:<br/><table><tbody><tr><td>**Property**</td><td>**Description**</td></tr><tr><td>ShipLocation</td><td>the country/region where th order will be shipped</td></tr><tr><td>CorrelationId</td><td>a priority value for the order</td></tr><tr><td>Quantity</td><td>a user-defined field that stores the quantity of items in an order</td></tr><tr><td>AuditedAt</td><td>a user-defined field that records the date an order is audited</td></tr></tbody></table><br/>The system has the following requirements for subscriptions:<br/><table><tbody><tr><td>**Subscription type**</td><td>**Comments**</td></tr><tr><td>FutureOrders</td><td>This subscription is reserved for future use & must not receive any orders</td></tr><tr><td>HighPriorityOrders</td><td>Handle all high priority orders & international orders</td></tr><tr><td>InternationalOrders</td><td>Handle orders where the country/region is not United States</td></tr><tr><td>HighQuantityOrders</td><td>Handle only orders with quantities greater than 100 units</td></tr><tr><td>AllOrders</td><td>This subscription is used for auditing purposes.<br/>This subscription must receive every single order.<br/>AllOrders has an Action defined that updates the<br/>AuditedAt property to include the date & time it was reveived by the subscription</td></tr></tbody></table><br/>You need to implement filtering and maximize throughput while evaluating filters.<br/>Which filter types should you implement ?<br/><br/>a. FutureOrders:SQLFilter<br/>b. FutureOrders:CorrelationFilter<br/>c. FutureOrders:No Filter<br/>d. InternationalOrders:SQLFilter<br/>e. InternationalOrders:CorrelationFilter<br/>f. AllOrders:SQLFilter<br/>g. AllOrders:CorrelationsFilter<br/>h. AllOrders:No Filter<br/>i. HighPriorityOrders:SQLFilter<br/>j. HighPriorityOrders:CorrelationFilter<br/>k. HighQuantityOrders:CorrelationFilter<br/>l. HighQuantityOrders:SQLFilter|<details><summary>Answer</summary>b. FutureOrders:CorrelationFilter<br/>d. InternationalOrders:SQLFilter<br/>h. AllOrders:No Filter<br/>i. HighPriorityOrders:SQLFilter<br/>l. HightQuantityOrders:SQLFilter<br/><br/>Subscribers can define which messages they want to receive from a topic. These messages are specified in the form of one or more named subscription rules. Each rule consists of a condition that selects particular messages and an action that annotates the selected message. For each matching rule condition, the subscription produces a copy of the message, which may be differently annotated for each matching rule.<br/><br/>Each newly created topic subscription has an initial default subscription rule. If you don't explicitly specify a filter condition for the rule, the applied filter is the true filter that enables all messages to be selected into the subscription.<br/><br/>FutureOrders: CorrelationFilter - Create a filter on a impossible condition like CorrelationId = -10000 So, that no present orders will arrive.<br/>HighPriorityOrders: SQLFilter - Create a filter on boolean AND condition with country NOT IN USA. This type of filtering is possible only with SQLFilter.<br/>InternationalOrders: SQLFilter - NOT IN condition based on country, This type of filtering is possible only with SQLFilter.<br/>HighQunatityOrders: SQLFilter - Greater than condition based on quantity. This type of filtering is possible only with SQLFilter.<br/>AllOrders : No need to define a filter since, by default, true filter that enables all messages to be selected into the subscription.<br/><br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/topic-filters</details>|
|2|You are building a container image for a Node.js application.<br/>The dockerfile contains the commands as shown below<br/>1. FROM node:8.9.3-alpine<br/>2. RUN mkdir -p /usr/src/app<br/>WORKDIR /usr/src/app<br/>4.<br/>5. RUN npm install<br/>CMD node /usr/src/app/index.js<br/><br/>You need to complete line number 4.<br/><br/>Which of the below commands should you use?<br/><br/>a. COPY ./usr/src/app/ pp/<br/>b. COPY ./app/ /usr//app/<br/>c. COPY ./app/ /user/src/app/|<details><summary>Answer</summary>c. COPY ./app/ /usr/src/app/<br/><br/>https://docs.microsoft.com/en-us/azure/container-instances/container-instances-tutorial-prepare-app</details>|
|3|You are developing an application managed photos. Users upload photos to an API which then stores the photos in an Azure blob storage of type General-purpose V2.<br/>You need to implement a module that processes photos and produce a thumbnail version of the photo. The process must start in less than one minute when photos were uploaded.<br/>To achieve requirement, you convert the Azure Storage account to a BlockBlobStorage storage account.<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. No<br/><br/>Instead you can use an Azure Function to create thumbnails<br/><br/>The Blob storage trigger starts a function when a new or updated blob is detected. The blob contents are provided as input to the function.<br/>The Azure Blob storage trigger requires a general-purpose storage account. Storage V2 accounts with hierarchal namespaces are also supported.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp</details>|
|4|You are developing an application managed photos. Users upload photos to an API which then stores the photos in an Azure blob storage of type General-purpose V2<br/>You need to implement a module that processes photos and produce a thumbnail version of the photo. The process must start in less than one minute when photos were uploaded.<br/>To achieve requirement, you create photo processing login in an Azure Function triggered from the blob upload.<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>a. yes<br/><br/>The Blob storage trigger starts a function when a new or updated blob is detected. The blob contents are provided as input to the function<br/>The Azure Blob storage trigger requires a general-purpose storage account. Storage V2 accounts with hierarchal namespaces are also supported.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp</details>|
|5|You are developing an application managed photos. Users upload photos to an API which then stores the photos in an Azure blob storage of type General-purpose V2.<br/>You need to implement a module that processes photos and produce a thumbnail version of the photo. The process must start in less than one minute when photos were uploaded.<br/>To achieve requirement, you trigger the photo processing from Blob storage events<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>a. yes<br/><br/>Azure Storage events allow applications to react to events, such as the creation and deletion of blobs. It does so without the need for complicated code or expensive and inefficient polling services. The best part is you only pay for what you use.<br/><br/>Blob storage events are pushed using Azure Event Grid to subscribers such as Azure Functions, Azure Logic Apps, or even to your own http listener. Event Grid provides reliable event delivery to your applications through rich retry policies and dead-lettering.<br/><br/>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-event-overview</details>|
|6|You plan to develop an application that processes queue data.<br/>You need to ensure that queue size must not grow larger than 80 gigabytes (GB).<br/>The messages must process in first-in-first-out (FIFO) ordering.<br/>Costs must be minimized.<br/>You need to implement the messaging solution.<br/>To achieve the requirement, you use the .Net API to add a message to an Azure Service Bus Queue. Create an Azure Windows VM that is triggered from Azure Service Bus Queue.<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. no<br/><br/>Azure Service bus queue provides FIFO and max limit is 80GB. However, instead of a VM to process messages, consider using Azure Function to minimize azure costs.<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted#foundational-capabilities</details>|
|7|You plan to develop an application that processes queue data.<br/>You need to ensure that queue size must not grow larger than 80 gigabytes (GB).<br/>The messages must process in first-in-first-out (FIFO) ordering.<br/>Costs must be minimized.<br/>You need to implement the messaging solution.<br/>To achieve the requirement, you use the .Net API to add a message to an Azure Service Bus Queue. Create an Azure Function App that uses an Azure Service Bus Queue trigger.<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>a. yes<br/><br/>Yes, this is the optimal solution. Azure Service bus queue provides FIFO and max limit is 80GB. Azure Function provides cost effective way of processing messages.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-storage-queue-triggered-function</details>|
|8|You plan to develop an application that processes queue data.<br/>You need to ensure that queue size must not grow larger than 80 gigabytes (GB).<br/>The messages must process in first-in-first-out (FIFO) ordering.<br/>Costs must be minimized.<br/>You need to implement the messaging solution.<br/>To achieve the requirement, you use the .Net API to add a message to an Azure Storage Queue. Create an Azure VM that is triggered from Azure Storage Queue events.<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. no<br/><br/>Azure Storage queue does not guarantee FIFO and size can grow more than 80 GB. Azure Service bus queue is the right choice.<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted#foundational-capabilities</details>|
|9|You plan to develop an application that processes queue data.<br/>You need to ensure that queue size must not grow larger than 80 gigabytes (GB).<br/>The messages must process in first-in-first-out (FIFO) ordering.<br/>Costs must be minimized.<br/>You need to implement the messaging solution.<br/>To achieve the requirement, you use the .Net API to add a message to an Azure Storage Queue. Create an Azure Function App that uses an Azure Storage Queue trigger.<br/>Does the solution meet the goal?<br/><br/>a. yes<br/>b. no|<details><summary>Answer</summary>b. no<br/><br/>Azure Storage queue does not guarantee FIFO and size can grow more than 80 GB. Azure Service bus queue is the right choice.<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted#foundational-capabilities</details>|
|10|You have the source code for an application in GitHub repository under master branch.<br/>You need to create an Azure Function and configure it to deploy code from a GitHub repository.<br/>Which of the below Azure CLI command should you use?<br/><br/>a. az functionapp create --name $functionAppName \ <br/>--storage-account $storageName \ <br/>--consumption-plan-location $region \ <br/> --resource-group myResourceGroup \ <br/> --deployment-source-url $gitrepo \ <br/> --deployment-source-branch root \ <br/>--functions-version 2<br/><br/><br/>b. az functionapp create --name $functionAppName \ <br/>--storage-account $storagename \ <br/>--consumption-plan-location $region \ <br/> --resource-group myResourceGroup \ <br/>--deployment-source-url $gitrepo \ <br/>--deployment-source-branch master \ <br/>--functions-version 2<br/><br/>c. az functionapp create --name $functionAppName \ <br/>--storage-account $storageName \ <br/>--consumption-plan-location $region \ <br/>--resource-group myResourceGroup \ <br/>--deployment-source $gitrepo \ <br/>--deployment-source-branch master \ <br/>--functions-version 2|<details><summary>Answer</summary>b. az functionapp create --name $functionAppName \ <br/>--storage-account $storageName \ <br/>--consumption-plan-location $region \ <br/>--resource-group myResourceGroup \ <br/>--deployment-source-url $gitrepo \ <br/>--deployment-source-branch master \ <br/>--functions-version2<br/><br/>https://docs.microsoft.com/en-us/azure/azure-functions/scripts/functions-cli-create-function-app-github-continuous</details>|
|11|You store customer information in an Azure Cosmos DB. The following data already exists in the database:<br/><table><tbody><tr><td>**PartitionKey**</td><td>**RowKey**</td><td>**Email**</td></tr><tr><td>Harp</td><td>Walter</td><td>wharp@videogames.com</td></tr><tr><td>Smith</td><td>Steve</td><td>ssmith@videogames.com</td></tr><tr><td>Smith</td><td>Jeff</td><td>jsmith@videogames.com</td></tr></tbody></table><br/>You develop the following code.<br/>`CloudTableClient tableClient = account.CreateCloudTableClient();`<br/>`CloudTable table = tableClient.GetTableReference("people");`<br/>`TableQuery<CustomerEntity> query = new TableQuery<CustomerEntity>().Where(TableQuery.CombineFilters(`<br/>`TableQuery.GenerateFilterCondition(PartitionKey, QueryComparisons.Equal, "Smith"),`<br/>`TableOperatioon.And, TableQuery.GenerateFilterCondtion(Email, QueryComparisons.Equal, "ssmith@videogames.com")));`<br/>`await table.ExecuteQuerySegmentedAsync<CustomerEntity>(query, null);`<br/>Select Yes if the below statement is true. Otherwise, select No.<br/>1. The code returns every record where the surname equals Smith<br/>2. The table endpoint https://<tableendpoint>/people(PartitionKey='Smith',RowKey='Steve') returns the same results as the code.<br/><br/>a. no, no<br/>b. yes, yes<br/>c. yes, no<br/>d. no, yes|<details><summary>Answer</summary>d. no, yes<br/><br/>1. Only the second row is returned due to filter condition on email as well.<br/>2. The code segment and table endpoint returns only second row</details>|
|12|You have an application that is deployed to an Azure Web apps and Azure Functions.<br/>Application secrets including connection strings and certificates are stored in Azure Key Vault.<br/>You need to design the approach to loading application secrets.<br/>Secrets must not be stored in the application or application runtime environment.<br/>Changes to Azure Active Directory (Azure AD) must be minimized.<br/>What should you do?<br/><br/>a. Create a single user-assigned Managed Identity with permission to access Key Vault & configure each App Service to use that Managed Identity<br/>b. Create a single AAD Service Principal with permission to access Key Vault & use a client secret from within the App Services to access Key Vault<br/>c. Create a system assigned Managed Identity in each App Service with permission to access Key Vault<br/>d. Create an AAD Service Principal with Permissioons to access Key Vault for each App Service & use a certificate from within the App Services to access key Vault|<details><summary>Answer</summary>c. Create a system assigned Managed Identity in each App Service with persmission to access Key Vault<br/><br/>Use Key Vault references for App Service and Azure Functions.<br/>Key Vault references support system-assigned managed identities.<br/>System managed identity is like an extension or part of your application. It gets recycled along with application resource life cycle<br/>https://docs.microsoft.com/en-us/azure/app-service/app-service-key-vault-references</details>|
|13|You are debugging an application that is running on Azure Kubernetes cluster.<br/>The cluster uses Azure Monitor for containers to monitor the cluster.<br/>The application has sticky sessions enabled on the ingress controller.<br/>You have noticed that there is a large number of errors in the application over the last 24 hours.<br/>You need to determine on which virtual machines (VMs) the errors are occurring.<br/>How should you complete the Azure Monitor query?<br/>`let startTimestamp = <<Code Block1>>`<br/>`let ContainerIDs = kubeProdInventory`<br/>`\| where ClusterName == 'Cluster1'`<br/>`\| <<Code Block2>>`<br/>`ContainerLog`<br/>`\| <<Code Block3>>`<br/>`\| where TimeGenerated > startTimestamp`<br/>`\| where LogEntrySource == 'stderr'`<br/>`\| <<Code Block4>>`<br/><br/>a. Code Blcok1:date(now()-1d);<br/>b. Code Block1:ago(1d);<br/>c. Code Block2:distinct ContainerID;<br/>d. Code Block2:union ContainerID;<br/>e. Code Block3:restrict ContainerID in (ContainerIDs)<br/>f. Code Block3:where ContainerID in (ContainerIDs)<br/>g. Code Block4:summarize count() by Computer<br/>h. Code Block4:summarize by computer|<details><summary>Answer</summary>b. Code Block1:ago(1d);<br/>c. Code Block2:distinct ContainerID;<br/>f. Code Block3:where ContainerID in (ContainerIDs)<br/>g. Code Block4:summarize count() by Computer<br/><br/>The question asks for errors in last 24 hours, so startTimestap should be ago (1d).<br/>We need to distinct the logs for each container from set of containers. So, distinct based on ContainerID and where condition on container Ids. We need to determine the VM. So, summarize the output by computer.<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/get-started-queries<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/log-query/query-optimization</details>|
|14|You are developing an API using Azure Functions app for your customers.<br/>Azure API Management instance with consumption plan is used to provide access to the API.<br/>All API calls are authenticated by using OAuth.<br/>API calls must be cached.<br/>Customers must not be able to view cached data for other customers.<br/>You need to configure API Management policies for caching.<br/>How should you complete the below policy statement?<br/>`<policies>`<br/>`<inbound>`<br/>`<base/>`<br/>`<cache-lookup caching-type="<<Code Block1>>" downstream-caching-type = "<<Code Block2"`<br/>`    <vary-by-header>`<br/>`        <<Code Block3>>`<br/>`    <vary-by-header/>`<br/>`    </cache-lookup>`<br/>`    </inbound>`<br/>`</policies>`<br/><br/>a. Code Block1:internal<br/>b. Code Block1:external<br/>c. Code Block2:public<br/>d. Code Block2:private<br/>e. Code Block3:Authorization<br/>f. Code Block3:Authentication|<details><summary>Answer</summary>b. Code Block1:external<br/>d. Code Block2:private<br/>e. Code Block3:Authorization<br/><br/>Caching type must be external since consumption plan does not support internal caching.<br/>Downstream caching type must be private as it is not shared.<br/>Vary by header must be authorization as it is cached per customer.<br/>https://docs.microsoft.com/en-us/azure/api-management/api-management-caching-policies</details>|
|15|You are developing a website that uses an Azure Active Directory (Azure AD) for authentication<br/>Azure AD users must be able to login to the website. Active Directory group memberships are used to personalize the website based on logged on user.<br/>How should you configure the application's manifest to meet the authentication requirements?<br/>To answer, select the code snippets that will replace the appropriate app manifest file segments<br/>`{`<br/>`âappIdâ: âd61126e3-089b-4adb-b721-d5023213df7dâ,`<br/>`âdisplayNameâ: âinternalâ,`<br/>`â<<Code Block1>>â: âAllâ,`<br/>`â<<Code Block2>>â: true`<br/>`}`<br/><br/>a. CodeSnippet1:optionalClaims<br/>b. Code Block1:groupMembershipClaims<br/>c. Code Block2:oauth2Permissions<br/>d. Code Block2:requiredResourceAccess<br/>e. Code Block2:oauth2AllowImplicitFlow|<details><summary>Answer</summary>b. Code Block1:groupMembershipClaims<br/>e. Code Block2:oauth2AllowImplicitFlow<br/><br/>Caching type must be external since consumption plan does not support internal caching.<br/>groupMembershipClaims will get the all of the security groups, distribution groups, and Azure AD directory roles that the signed-in user is a member of. As website personalization is based on user group memberships, this must be configured.<br/>oauth2AllowImplicitFlow flag is used for browser-based apps, like JavaScript single-page apps. Specifies whether this web app can request OAuth2.0 implicit flow access tokens<br/>https://docs.microsoft.com/en-us/azure/active-directory/develop/reference-app-manifest#configure-the-app-manifest</details>|
|16|You are developing a series of video games. All games use a single leaderboard service.<br/>You must implement following requirements:<br/>Code must be scalable and allow for growth.<br/>Each record must consist of a playerId, gameId, score, and time played.<br/><br/>When users reach a new high score, the system will save the new score using the SaveScore function below.<br/>Each game is assigned an Id based on the series title.<br/>You plan to store customer information in Azure Cosmos DB. The following data already exists in the database:<br/><table><tbody><tr><td>**PartionKey**</td><td>**RowKey**</td><td>**Email**</td></tr><tr><td>Harry</td><td>David</td><td>harry@videogames.com</td></tr><tr><td>Steve</td><td>Smith</td><td>ssteve@videogames.com</td></tr><tr><td>Steve</td><td>White</td><td>swhite@videogames.com</td></tr></tbody></table><br/>You develop the following code to save scores in the data store.<br/>`public void SaveScore(string gameId, string playerId, int score, long timePlayed)`<br/>`{`<br/>`    CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionstring);`<br/>`    CloudTableClient tableClient = storageAccount.CreateCloudTableClinet();`<br/>`    CloudTable table = tableClient.GetTableReference("scoreTable");`<br/>`    table.CreateIfNotExists();`<br/>`    var scoreRecord = new PlayerScore(gameId, playerId, score, timePlayed);`<br/>`    TableOperation insertOperation = TableOperation.Insert(scoreRecord);`<br/>`    table.Execute(insertOperation);`<br/>`}`<br/>`public class PlayerScore : TableEntity`<br/>`{`<br/>`    public PlayerScore(string gameId, string playerId, int score, long timePlayed)`<br/>`    {`<br/>`        this.PartitionKey = gameId;`<br/>`        this.RowKey = playerId;`<br/>`    Score = score;`<br/>`    TimePlayed = timePlayed;`<br/>`    }`<br/>`    public int Score { get; set; }`<br/>`    public long TimePlayed { get; set; }`<br/>`}`<br/>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br/><br/>1. SaveScore will work with Cosmos DB.<br/>2. SaveScore will update and replace a record if one already exists with the same playerId and gameId.<br/>3. Leader board data for the game will be automatically partitioned using gameId<br/>4. SaveScore will store the values for the gameId and playerId parameters in the database<br/><br/>a. yes, no, no, yes<br/>b. yes, yes, yes, yes<br/>c. yes, no, yes, yes<br/>d. no, no, yes, yes, yes|<details><summary>Answer</summary>c. yes, no, yes, yes<br/><br/>1. A CloudTableClient object lets you get reference objects for tables and entities. The SaveScore method uses correct libraries to save data.<br/>2. SaveScore will insert the data. It will not replace if exists or updates a record<br/>3. gameId is the partition key<br/>4. gameId and playerId values will get stored in the database.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/tutorial-develop-table-dotnet</details>|
|17|Your company is developing a Java web app.<br/>The web app code is hosted in a GitHub repository located at https://github.com/yourcompanyname/webapp.<br/>The web app must be evaluated before it is moved to production. You must deploy the initial code release to a deployment slot named staging.<br/>You need to create the web app and deploy the code.<br/>How should you complete the below commands?<br/><br/>gitrepo=https://github.com/ yourcompanyname /webapp<br/>webappname=businesswebapp<br/>resourcegroupname=businessappresourcegroup<br/><br/>a. az group create --location centralus --name $resourcegroupname<br/>az appserviceplan create --name $webappname --resource-group $resourcegroupname --sku S3<br/>az webapp create --name $webappname --resource-group $resourcegroupname --plan $webappname<br/>az webapp deployment slot create --name $webappname --resource-group $resourcegroupname --slot staging<br/>az webapp deployment source config --name $webappname --resource-group $resourcegroupname \ <br/>--slot staging --repo-url $gitrepo --branch master --manual-integration<br/><br/>b. az group create --location centralus --name $resourcegroupname<br/>az webapp create --name $webappname --resource-group $resourcegroupname --sku S3<br/>az appserviceplan create --name $webappname --resource-group $resourcegroupname --plan $webappname<br/>az webapp deployment slot create --name $webappname --resource-group $resourcegroupname --slot staging<br/>az webapp deployment source config --name $webappname --resource-group $resourcegroupname \ <br/>--slot staing --repo-url $gitrepo --branch master --manual-integration<br/><br/>c. az group create --location centralus --name $resourcegroupname<br/>az appserviceplan create --name $webappname --resource-group $resourcegroupname --sku S3<br/>az webapp create --name $webappname --resource-group $resourcegroupname --plan $webappname<br/>az webapp deployment slot create --name $webappname --resource-group $resourcegroupname --slot staging<br/>az webapp deployment source config --name $webappname --resource-group $resourcegroupname \ <br/>--slot prod --repo-url $gitrepo --branch master --manual-integration|<details><summary>Answer</summary>a. az group create --location centralus --name $resourcegroupname<br/>az appserviceplan create --name $webappname --resource-group $resourcegroupname --sku S3<br/>az webapp create --name $webappname --resource-group $resourcegroupname --plan $webappname<br/>az webapp deployment slot create --name $webappname --resource-group $resourcegroupname --slot staging<br/>az webapp deployment source config --name $webappname --resource-group $resourcegroupname \ <br/>--slot staging --repo-url $gitrepo --branch master --manual-integration<br/><br/>The correct sequence of activities are<br/>1. Create a resource group<br/>2. Create an App Service plan<br/>3. Create a web app<br/>4. Create a deployment slot with the name "staging"<br/>5. Deploy sample code to "staging" slot from GitHub<br/>https://docs.microsoft.com/en-us/azure/app-service/scripts/cli-deploy-staging-environment</details>|
|18|You are developing a new page for a website that uses Azure Cosmos DB for data storage. The feature uses documents that have the following format:<br/>`{`<br/>`ânameâ : âJohnâ,`<br/>`âcityâ: âSeattleâ`<br/>`}`<br/>You must display data for the new page in a specific order. You create the following query for the page:<br/>SELECT*<br/>FROM PEOPLE p<br/>ORDER BY p.name, p.city DESC<br/><br/>You need to configure a Cosmos DB policy to the support the query.<br/>How should you configure the policy?<br/>`{`<br/>`    "automatic": true,`<br/>`    "ngMode": "Consistent",`<br/>`    "includedPaths":[`<br/>`        {`<br/>`            "path": "/*"`<br/>`        }`<br/>`    ], "excludedPaths": [],`<br/>`    "<<Code Block1>>" :[`<br/>`        [`<br/>`            {`<br/>`                "path": "/name", "order": "descending"`<br/>`            },`<br/>`            {`<br/>`                "path": "/city", "order": "<<Code Block2>>"`<br/>`            }`<br/>`        ]`<br/>`    ]`<br/>`}`<br/><br/>a. Code Block1:compositeIndexes<br/>b. Code Block1:sortOrder<br/>c. Code Block2:ascending<br/>d. Code Block2: descending|<details><summary>Answer</summary>a. Code Block1:compositeIndexes<br/>c. Code Block2:ascending<br/><br/>Queries that have an ORDER BY clause with two or more properties require a composite index. You can also define a composite index to improve the performance of many equality and range queries. By default, no composite indexes are defined so you should add composite indexes as needed.<br/>The following considerations are used when using composite indexes for queries with an ORDER BY clause with two or more properties:<br/>If the composite index paths do not match the sequence of the properties in the ORDER BY clause, then the composite index can't support the query.<br/>The order of composite index paths (ascending or descending) should also match the order in the ORDER BY clause.<br/>The composite index also supports an ORDER BY clause with the opposite order on all paths.<br/>So, you must add compositeIndexes and order must be ascending since the query is in desc order. The composite Index supports Order by clause with the opposite order on all paths.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/index-policy#composite-indexes<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/how-to-manage-indexing-policy?tabs=dotnetv2%2Cpythonv3#composite-index-defined-for-name-asc-age-desc</details>|
|19|You are developing an Azure Function which process the messages in a queue. The outcome of the process must be stored in an Azure Cosmos DB<br/><br/>Select the following code snippet that will suffice the requirement.<br/><br/>a. [FunctionName("QueueToDocDB")]<br/>public static void Run(<br/>[CosmosDBTrigger("myqueue-items",Connection="AzureWebJobsStorage")] string<br/>myQueueItem,<br/>[Queue("ToDoList","Items",Id = "id",ConnectionStringSetting = "myCosmosDB")] out<br/>dynamic document)<br/>{<br/>...<br/>}<br/>b. [FunctionName("QueueToDocDB")]<br/>public static void Run(<br/>[QueueTrigger("myqueue-items",Connection = "AzureWebJobStorage")] string<br/>myQueueItem,<br/>[CosmosDB("ToDoList","Items",Id = "id",ConnectionStringSetting = "myCosmosDB")] in<br/>dynamic document)<br/>{<br/>...<br/>}c. [FunctionName("QueueToDocDB")]<br/>public static void Run([QueueTrigger("myqueue-items",Connection = "AzureWebJobsStroage")] string<br/>myQueueItem,<br/>[CosmosDB("ToDocList","Items",Id = "id",ConnectionStringSetting = "myCosmosDB")] out<br/>dynamic document)<br/>{<br/>...<br/>}|<details><summary>Answer</summary>c. [FunctionName("QueueToDocDB")]<br/>public static void Run(<br/>[QueueTrigger("myqueue-items",Connection = "AzureWebJobsStorage")]string my QueueItem,<br/>[CosmosDb("ToDoList","Items",Id = "id",<br/>ConnectionStringSetting = "myCosmosDB")] out dynamic document)<br/>{<br/>...<br/>}<br/><br/>The QueueTrigger lets you trigger the Function when a message arrives in the queue.<br/>The Azure Cosmos DB output binding lets you write a new document to an Azure Cosmos DB database using the SQL API.<br/>The direction must be set to out.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-cosmosdb-v2-output?tabs=csharp#attributes-and-annotations</details>|
|20|You develop blog content delivery app for Windows devices.<br/>You need to send a notification to user's device when there is a new article available for them to view.<br/>You need to implement push notifications.<br/><br/>string notificationHubName = "hubname";<br/>string notificationHubConnection = "connectionstring";<br/>**< CodeBlock1>** hub = **< CodeBlock1>**.< CodeBlock2>(notificationHubConnection,notificationHubName);<br/>//create payload<br/>...<br/>...<br/>...<br/><br/>var result = await hub.< CodeBlock3>(payload)<br/><br/>How should you complete the CodeBlock1?<br/><br/>a. NotificationHubJob<br/>b. NotificationHubClient<br/>c. NotificationHub<br/>d. NotificationDetails|<details><summary>Answer</summary>b. NotificationHubClient<br/><br/>https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-aspnet-backend-windows-dotnet-wns-notification#send-notifications-from-the-webapi-backend</details>|
|21|You develop blog content delivery app for Windows devices.<br/>You need to send a notification to user's device when there is a new article available for them to view.<br/>You need to implement push notifications.<br/><br/>string notificationHubName = "hubname";<br/>string notificationHubConnection = "connectionstring";<br/>< CodeBlock1> hub = < CodeBlock1>.**< CodeBlock2>**(notificationHubConnection,notificationHubName);<br/>//create payload<br/>...<br/>...<br/>...<br/>var result = await hub.< CodeBlock3>(payload)<br/><br/>How should you complete the CodeBlock2?<br/><br/>a. CreateClient<br/>b. CreateClientFromConnectionString<br/>c. CreatorUpdateClient|<details><summary>Answer</summary>b. CreateClientFromConnectionString<br/><br/>https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-aspnet-backend-windows-dotnet-wns-notification#send-notifications-from-the-webapi-backend</details>|
|22|You develop blog content delivery app for Windows devices.<br/>You need to send a notification to user's device when there is a new article available for them to view.<br/>You need to implement push notifications.<br/><br/>string notificationHubName = "hubname";<br/>string notificationHubConnection = "connectionstring";<br/>< CodeBlock1> hub = < CodeBlock1>.< CodeBlock2>(notificationHubConnection,notificationHubName);<br/>//create payload<br/>...<br/>...<br/>...<br/><br/>var result = await hub.**< CodeBlock3>**(payload)<br/><br/>How should you complete the CodeBlock3?<br/><br/>a. SubmitNotificationHubJobAsync<br/>b. SendWindowsNativeNotificationAsync<br/>c. ScheduleWindowsNativeNotificationAsync|<details><summary>Answer</summary>b. SendWindowsNativeNotificationAsync<br/><br/>https://docs.microsoft.com/en-us/azure/notification-hubs/notification-hubs-aspnet-backend-windows-dotnet-wns-notification#send-notifications-from-the-webapi-backend</details>|
|23|You are creating a Virtual Machine Scale Set (VMSS) environment for your development team. The environment includes several storage accounts, and networking components<br/><br/>Storage accounts must be created first and an associated load balancer and virtual network must be configured before creating VMSS.<br/><br/>Complete the below Azure Resource Manager template to setup development environment.<br/>`{`<br/>`    ...`<br/>`    "resources": [`<br/>`    {`<br/>`        "apiVersion": "2016-01-01",`<br/>`        "type": "Microsoft.Storage/storageAccounts",`<br/>`        "name": "[concat(**<<CodeBlock1>>**(),'storage',uniqueString(resourceGroup().id))]",`<br/>`        "location": "[resourceGroup().location]",`<br/>`        ...`<br/>`        "sku": {`<br/>`            "name": "Standard_LRS"`<br/>`        },`<br/>`        "kind": "storage",`<br/>`        "properties": {},`<br/>`        "<<CodeBlock2>>": {`<br/>`            "name": "storagesetup",`<br/>`            "count": 3`<br/>`        }`<br/>`    },`<br/>`    {`<br/>`        "apiVersion": "2015-06-15",`<br/>`        "type": "Microsoft.Compute/virtualMachines",`<br/>`        "name": "[concat('VM', uniqueString(resourceGroup().id))]",`<br/>`        "<<CodeBlock3>>": [`<br/>`        "[variables('loadBalancerName')]",`<br/>`        "[variables('virtualNetworkName')]",`<br/>`        "storage",`<br/>`        ],`<br/>`        ...`<br/>`    }`<br/>`    ],`<br/>`    "outputs": {}`<br/>`}`<br/><br/>a. CodeBlock1:copy<br/>b. CodeBlock1:copyIndex<br/>c. CodeBlock1:dependsOn<br/>d. CodeBlock2:copy<br/>e. CodeBlock2:copyIndex<br/>f. CodeBlock2:dependsOn<br/>g. CodeBlock3:copy<br/>h. CodeBlock3:copyIndex<br/>i. CodeBlock3:dependsOn|<details><summary>Answer</summary>b. CodeBlock1:copyIndex<br/>d. CodeBlock2:copy<br/>i. CodeBlock3:dependsOn<br/><br/>The copyIndex() function returns the current iteration in the loop. You use the index as the name prefix. copyIndex() is zero-based.<br/>In the copy element, you specify the number of iterations and a variable for this loop. The count value must be a positive integer and can't exceed 800<br/>The dependsOn element enables you to define one resource as a dependent on one or more resources<br/>https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/define-resource-dependency</details>|
|24|You are developing an application that needs access to an Azure virtual machine (VM).<br/><br/>The access lifecycle for the application must be associated with the VM service instance.<br/><br/>You need to enable managed identity for the VM. How should you complete the PowerShell segment?<br/><br/>$vm = Get-AzVM âResourceGroupName âRG1â âName âVirtualMachine1â<br/>Update-AzVM âResourceGroupName âRG1â âVM $vm <CodeBlock1> < CodeBlock2><br/><br/>a. CodeBlock1:-AssignIdentity:<br/>b. CodeBlock1:-IdentityType:<br/>c. CodeBlock2:$SystemAssigned<br/.d. CodeBlock2:$UserAssigned|<details><summary>Answer</summary>b. CodeBlock1:-IdentityType:<br/>c. CodeBlock2:$SystemAssigned<br/><br/>IdentityType - The type of identity used for the virtual machine. Valid values are SystemAssigned, UserAssigned, SystemAssignedUserAssigned, and None<br/>SystemAssigned - This parameter enables the VM with the system-assigned identity<br/>https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/qs-configure-powershell-windows-vm#system-assigned-managed-identity</details>|
|25|You are developing a web application that will be deployed on Azure virtual machines. The application uses an Azure Storage.<br/>The application should not use secret key-based authentication mechanisms for accessing an Azure Storage account.<br/>You configure all virtual machines to use managed identities.<br/>You must use only Azure Instance Metadata Service endpoints.<br/><br/>You need to complete below code to retrieve an access token to access Azure Storage.<br/>`var url = "<CodeBlock1>";`<br/>`var queryString = "...";`<br/>`var clinet = new HttpClient();`<br/>`var response = await client.GetAsync(url + queryString);`<br/>`var payload = await response.Content.ReadAsStringAsync();`<br/><br/>`return <CodeBlock2>`<br/><br/>a. CodeBlock1: http://169.254.169.254:50432/oauth2/token<br/>b. CodeBlock1: http://169.254.169.254/metadata/identity/oauth2/token<br/>c. CodeBlock1: https://localhost:50432/oauth2/token<br/>d. CodeBlock2:XDocument.Parse(payload);<br/>e. CodeBlock2:new MultipartContent(payload);<br/>f. CodeBlock2:JsonConvert.DeserializeObject<Dictionary<string,string>>(payload);|<details><summary>Answer</summary>b. CodeBlock1: http://169.254.169.254/metadata/identity/oauth2/token<br/>g. CodeBlock2:JsonConvert.DeserializeObject<Dictionary<string, string>>(payload);<br/><br/>Here is the sample code.<br/>using System;<br/>using System.Collections.Generic;<br/>using System.IO;<br/>using System.Net;<br/>using System.Web.Script.Serialization;<br/><br/>// Build request to acquire managed identities for Azure resources token<br/>HttpWebRequest request = (HttpWebRequest)WebRequest.Create("http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com/");<br/>request.Headers["Metadata"] = "true";<br/>request.Method = "GET";<br/><br/>try<br/>{<br/>// Call /token endpoint<br/>HttpWebResponse response = (HttpWebResponse)request.GetResponse();<br/><br/>// Pipe response Stream to a StreamReader, and extract access token<br/>StreamReader streamResponse = new StreamReader(response.GetResponseStream());<br/>string stringResponse = streamResponse.ReadToEnd();<br/>JavaScriptSerializer j = new JavaScriptSerializer();<br/>Dictionary<string, string> list = (Dictionary<string, string>) j.Deserialize(stringResponse, typeof(Dictionary<string, string>));<br/>string accessToken = list["access_token"];<br/>}<br/>catch (Exception e)<br/>}<br/>string errorText = String.Format("{0} \n\n{1}", e.Message, e.InnerException != null ?<br/>e.InnerException.Message : "Acquire token failed");<br/>}<br/>https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/how-to-use-vm-token#get-a-token-using-c</details>|
|26|You are preparing to deploy a Python website to an Azure Web App using a container.<br/>Below is the Dockerfile that builds the container<br/><br/>FROM python:3<br/>ADD website.py<br/>CMD [âpythonâ, â./website.pyâ]<br/><br/>The solution will use multiple containers in the same container group.<br/>The Azure Container Registry instance named images is a private registry. You build a container by using the following command<br/><br/>docker build ât images.azurecr.io/website:v1.0.0<br/><br/>The user name and password for the registry is admin.<br/>The Web App must always run the same version of the website regardless of future builds.<br/>You need to create an Azure Web App to run the website.<br/>How should you complete the commands?<br/><br/>az configure --defaults web=website<br/>az configure --defaults group=website<br/>az appservice plan create --name websitePlan **<codeBlock1>**<br/>az webapp create --plan websitePlan **<CodeBlock2>**<br/>az webapp config **<CodeBlock3>**<br/><br/>a. CodeBlock1:--sku B1-is-linux<br/>b. CodeBlock1:--sku B1-hyper-v<br/>c. CodeBlock2:--deployment-container-image-name images.azurecr.io/website:v1.0.0<br/>d. CodeBlock2:--deployment-container-image-name images.azurecr.io/website:latest<br/>e. CodeBlock3:container set-docker-registry-server-url https://images.azurecr.io -u admin -p admin<br/>f. CodeBlock3:container set-docker-registry-server-url https://images.azurecr.io/website -u admin -p admin|<details><summary>Answer</summary>a. CodeBlock1:--sku B1 --is-linux<br/>c. codeBlock2:--deployment-container-image-name images.azurecr.io/website:v1.0.0<br/>e. CodeBlock3:container set -docker-registry-server-url https://images.azurecr.io -u admin -p admin<br/><br/>1. Multi-container groups currently support only Linux containers. For Windows containers, Azure Container Instances only supports deployment of a single container instance<br/>https://docs.microsoft.com/en-us/azure/container-instances/container-instances-container-groups<br/>2. Sample command is below<br/># Create a web app.<br/>az webapp create --name <app_name> --plan AppServiceLinuxDockerPlan --resource-group myResourceGroup --deployment-container-image-name <acr_registry_name>.azurecr.io/<container_name:version><br/>https://docs.microsoft.com/en-us/azure/app-service/scripts/cli-linux-acr-aspnetcore<br/>3. Sample command is below<br/># Configure web app with a custom Docker Container from Azure Container Registry<br/>az webapp config container set --resource-group myResourceGroup --name <app_name> --docker-registry-server-url http://<acr_registry_name>.azurecr.io --docker-registry-server-user <registry_user> --docker-registry-server-password <registry_password><br/>https://docs.microsoft.com/en-us/azure/app-service/scripts/cli-linux-acr-aspnetcore</details>|
|27|You are building a website that uses Azure CDN to improve performance.<br/>You build and deploy a mobile app for Apple iPhones.<br/>The user must be redirected to the app store if a user access the website from an iPhone.<br/>You need to implement an Azure CDN rule.<br/>How should you complete the Azure Resource Manager template?<br/>`"conditions": [ {`<br/>`    "name": "IsDevice",`<br/>`    "parameters": {`<br/>`        "@odata.type": "#Microsoft.Azure.Cdn.Models.<CodeBlock1>",`<br/>`        "operator": "Equal"`<br/>`        "matchValues": ["<CodeBlock2>"]`<br/>`    } },`<br/>`    {`<br/>`        "name": "RequestHeader",`<br/>`        "parameters": {`<br/>`            "@odata.type": "#Microsoft.Azure.Cdn.Models.<CodeBlock3>",`<br/>`            "operator": "Contains",`<br/>`            "selector": "<CodeBlock4>",`<br/>`            "matchValues": [ "<CodeBlock5>" ]`<br/>`        } }`<br/>`]`<br/><br/>a. CodeBlock1:DeleveryRulesIsDeviceConditionParameters<br/>b. CodeBlock1:DeliveryRuleRequestHeaderConditionParameters<br/>c. CodeBlock2:Mobile<br/>d. CodeBlock2:Desktop<br/>e. CodeBlock3:DeliveryRulesIsDeviceConditionParameters<br/>f. CodeBlock3:DeliveryRuleRequestHeaderConditionParameters<br/>g. CodeBlock4:X-POWERED-BY<br/>h. CodeBlock4:HTTP_USER_AGENT<br/>i. CodeBlock5:iOS<br/>j. CodeBlock5:iPhone|<details><summary>Answer</summary>a. CodeBlock1:DeliveryRulesIsDeviceConditionParameters<br/>c. CodeBlock2:Mobile<br/>f. CodeBlock3:DeliveryRuleRequestHeaderConditionParameters<br/>h. CodeBlock4:HTTP_USER_AGENT<br/><br/>https://github.com/Azure/azure-quickstart-templates/blob/master/201-cdn-with-ruleseengine-rewriteandredirect/azuredeploy.json<br/>https://docs.microsoft.com/en-us/python/api/azure-mgmt-cdn/azure.mgmt.cdn.models.requestheadermatchconditionparameters?view=azure-python#constructor</details>|
|28|You are developing a web service that will be accessed by using an Azure API Management instance.<br/>The web service does not correctly handle conflicts.<br/>the web service is returning a HTTP status code of 500 instead of status code 409<br/>The body of the status message contains only the word conflict.<br/>You need to ensure that conflicts produce the correct response.<br/>How should you complete the policy?<br/>`<CodeBlock1>`<br/>`	<base/>`<br/>`	<choose>`<br/>`		<when condition = "@<CodeBlock2>.Response.StatusCode == 500 && <CodeBlock3>.LastError.Message.Contains ("conflict = "))")">`<br/>`			<return-reponse>`<br/>`				<<CodeBlock4>>`<br/>`			</return-reponse>`<br/>`		</when>`<br/>`		<otherwise/>`<br/>`	</choose>`<br/>`<<CodeBlock5>>`<br/><br/>a. CodeBlock1:when-error<br/>b. CodeBlock1:on-error<br/>c. CodeBlock2:server<br/>d. CodeBlock2:context<br/>e. CodeBlock3:server<br/>f. CodeBlock3:context<br/>h. CodeBlock4:set-status<br/>i. CodeBlock4:override-status,br/>j. CodeBlock5:when-error<br/>k. CodeBlock5:on-error|<details><summary>Answer</summary>b. CodeBlock1:on-error<br/>d. CodeBlock2:context<br/>f. CodeBlock3:context<br/>g. CodeBlock4:set-status<br/>j. CodeBlock5:on-error<br/><br/>On-error - Policies in Azure API Management are divided into inbound, backend, outbound, and on-error. The statements to be applied if there is an error condition go on-error section.<br/>Context is used to get the request context.<br/>set-status - The set-status policy sets the HTTP status code to the specified value<br/>https://docs.microsoft.com/en-us/azure/api-management/api-management-error-handling-policies</details>|
|29|You are developing an ASP.NET Core app that includes feature flags which are managed by Azure App Configuration.<br/><br/>You create an Azure App Configuration store named FeatureFlagStore that contains a feature flag named Flag1.<br/><br/>You need to update the app to meet the following requirements:<br/>Use the Flag1 feature in the app without requiring a restart of the app.<br/>Validate users before users are allowed access to secure resources.<br/>Permit users to access secure resources.<br/><br/>How should you complete the code segment?<br/>`public void Configure(IApplicationBuilder app, IWebHostEnvironment env)`<br/>`{`<br/>`if (env.IsDevelopment())`<br/>`{`<br/>`   app.UseDeveloperExceptionPage();`<br/>`}`<br/>`else`<br/>`{`<br/>`	app.UseExceptionHandler("/Error");`<br/>`}`<br/>`app.<CodeBlock1>();`<br/>`app.<CodeBlock2>();`<br/>`app.<CodeBlock3>();`<br/>`app.UseEndpoint(endpoints =>`<br/>`{`<br/>`	endpoints.MapRazorPages();`<br/>`});`<br/>`}`<br/><br/>a. CodeBlock1:UseAuthentication<br/>b. CodeBlock1:UseSession<br/>c. CodeBlock1:UseCookiePolicy<br/>d. CodeBlock2:UseAuthorization<br/>e. CodeBlock2:UseHTTPsRedirection<br/>f. CodeBlock2:useSession<br/>g. CodeBlock3:UseAzureAppConfiguration<br/>h. CodeBlock3:UseStaticFiles<br/>i. CodeBlock3:UseRequestLocalization|<details><summary>Answer</summary>a. CodeBlock1:UseAuthentication<br/>d. CodeBlock2:UseAuthorization<br/>g. CodeBlock3:UseAzureAppConfiguration<br/><br/>UseAuthentication â Adds the AuthenticationMiddleware to the specified IApplicationBuilder, which enables authentication capabilities.<br/>UseAuthorization â Adds the AuthorizationMiddleware to the specified IApplicationBuilder, which enables authorization capabilities.<br/>UseAzureAppConfiguration - It enables your application to use the App Configuration middleware to handle the configuration updates for you automatically<br/>https://docs.microsoft.com/en-us/azure/azure-app-configuration/enable-dynamic-configuration-aspnet-core?tabs=core5x<br/>https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.builder.iapplicationbuilder?view=aspnetcore-5.0</details>|
|30|You plan to develop an Azure Function app to write the functions by using the Rust language.<br/>Which Azure Function app features should you use?<br/><br/>a. Runtime<br/>b. Hosting Plan<br/>c. Extension bundle<br/>d. Custom handler<br/>e. Trigger|<details><summary>Answer</summary>d. Custom handler<br/><br/>Custom handlers are lightweight web servers that receive events from the Functions host. Any language that supports HTTP primitives can implement a custom handler.<br/>Custom handlers are best suited for situations where you want to:<br/>* Implement a function app in a language that's not currently offered out-of-the box, such as Go or Rust<br/>* Implement a function app in a runtime that's not currently featured by default, such as Deno.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-custom-handlers</details>|
|31|You plan to develop an Azure Function app that declaratively connect to an Azure Blob Storage account.<br/>Which Azure Function app features should you use?<br/><br/>a. Runtime<br/>b. Hosting Plan<br/>c. Extension bundle<br/>d. Custom handler<br/>e. Trigger|<details><summary>Answer</summary>c. Extension bundle<br/><br/>Extension bundles is a way to add a compatible set of binding extensions to your function app. You enable extension bundles in the app's host.json file. Standard triggers along with input and output bindings are available by referencing extension bundles in your host.json file.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-register</details>|
|32|You develop an Azure solution that uses Cosmos DB.<br/>The Cosmos DB container must be replicated and must use a partition key that is optimized for queries.<br/>You need to implement a change feed processor solution to store the data from which the change feed is generated.<br/>Which change feed processor should you use?<br/><br/>a. Host<br/>b. Delegate<br/>c. Lease container<br/>d. Monitored container|<details><summary>Answer</summary>d. Monitored container<br/><br/>There are four main components of implementing the change feed processor:<br/>1. The **monitored container**: The monitored container has the data from which the change feed is generated. Any inserts and updates to the monitored container are reflected in the change feed of the container.<br/>2. **The lease container:**he lease container acts as a state storage and coordinates processing the change feed across multiple workers. The lease container can be stored in the same account as the monitored container or in a separate account.<br/>3. **The host**A host is an application instance that uses the change feed processor to listen for changes. Multiple instances with the same lease configuration can run in parallel, but each instance should have a different instance name<br/>4. **The delegate**The delegate is the code that defines what you, the developer, want to do with each batch of changes that the change feed processor reads<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor</details>|
|33|You develop an Azure solution that uses Cosmos DB.<br/>The Cosmos DB container must be replicated and must use a partition key that is optimized for queries.<br/>You need to implement a change feed processor solution to coordinate processing of the change feed across multiple workers<br/>Which change feed processor should you use?<br/><br/>a. Host<br/>b. Delegate<br/>c. Lease container<br/>d. Monitored container|<details><summary>Answer</summary>c. Lease container<br/><br/>There are four main components of implementing the change feed processor:<br/>1. **The monitored container:**The monitored container has the data from which the change feed is generated. Any inserts and updates to the monitored container are reflected in the change feed of the container.<br/>2. **The leaser container**he lease container acts as a state storage and coordinates processing the change feed across multiple workers. The lease container can be stored in the same account as the monitored container or in a separate account.<br/>3. **The host**A host is an application instance that uses the change feed processor to listen for changes. Multiple instances with the same lease configuration can run in parallel, but each instance should have a different **instance name**<br/>4. **The delegate**The delegate is the code that defines what you, the developer, want to do with each batch of changes that the change feed processor reads<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor</details>|
|34|You develop an Azure solution that uses Cosmos DB.<br/>The Cosmos DB container must be replicated and must use a partition key that is optimized for queries.<br/>You need to implement a change feed processor solution for using the change feed processor to listen for changes.<br/>Which change feed processor should you use?<br/><br/>a. Host<br/>b. Delegate<br/>c. Lease container<br/>d. Monitored container|<details><summary>Answer</summary>a. host<br/><br/>There are four main components of implementing the change feed processor:<br/>1. **The monitored container**he monitored container has the data from which the change feed is generated. Any inserts and updates to the monitored container are reflected in the change feed of the container<br/>2. **The lease container**The lease container acts as a state storage and coordinates processing the change feed across multiple workers. The lease container can be stored in the same account as the monitored container or in a separate account.<br/>3. **The host**A host is an application instance that uses the change feed processor to listen for changes. Multiple instances with the same lease configuration can run in parallel, but each instance should have a different **instance name**<br/>4. **The delegate**The delegate is the code that defines what you, the developer, want to do with each batch of changes that the change feed processor reads.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor</details>|
|35|**Background -**<br/>You develop an Azure solution that uses Cosmos DB.<br/>The Cosmos DB container must be replicated and must use a partition key that is optimized for queries.<br/>You need to implement a change feed processor solution to handle each batch of changes.<br/>Which change feed processor should you use?<br/><br/>a. Host<br/>b. Delegate<br/>c. Lease container<br/>d. Monitored container|<details><summary>Answer</summary>b. Delegate<br/><br/>The "delegate" refers to the code that you, as the developer, write to define what actions should be taken with each batch of changes read from the change feed. It's the logic that processes the actual data changes. In the context of the change feed processor, the delegate is crucial as it determines how you want to process the changes and update your application or system accordingly.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/sql/change-feed-processor</details>|
|36|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to ensure that authentication events are triggered and processed according to the authentication events policy<br/>What should you do?<br/><br/>a. Ensure that signout events have a subject prefix.Create an Azure Event Grid subscription that uses the subjectBginsWith filter<br/>b. Create a new Azure Event Grid topic & add a subscription for the events<br/>c. Create a new Azure Event Grid subscription for all authentication htat delivers messages to an Azure Event Hub.Use the subscription to prcess signout events<br/>d. Create separate Azure Event Grid topics & subscriptions for sign-in & sing-out events|<details><summary>Answer</summary>d. Create separete Azure Event Grid topics & subscriptions for sign-in & sign-out events<br/><br/>Scenario: Authentication events are used to monitor users signing in and signing out. All authentication events must be processed by Policy service. Sign outs must be processed as quickly as possible.<br/>We need to monitor both sign-in and signout events.</details>|
|37|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to meet the scaling requirements for Policy Service.<br/>Which information should you cache?<br/><br/>a. TempData<br/>b. Session state<br/>c. ViewState<br/>d. HttpContext.Items|<details><summary>Answer</summary>b. Session state<br/><br/>Scenario: Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing<br/>When you auto scale app service, you need to cache session information.<br/>Azure Cache for Redis provides a session state provider that you can use to store your session state in-memory with Azure Cache for Redis instead of a SQL<br/>https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-aspnet-session-state-provider</details>|
|38|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to resolve a notification latency issue.<br/>Which two actions should you perform?<br/><br/>a. Set Always On to false<br/>b. Set Always On to true<br/>c. Ensure that the Azure Function is set to use a consumption plan<br/>d. Ensure that the Azure Function is using an App Service plan|<details><summary>Answer</summary>b. Set Always On to true<br/>d. Ensure that the Azure Function is using an App Service plan<br/><br/>Scenario: Notification latency: Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>Anomaly detection service: You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service.<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/><br/>If you run on an App Service plan, you should enable the Always on setting so that your function app runs correctly. On an App Service plan, the functions runtime goes idle after a few minutes of inactivity, so only HTTP triggers will "wake up" your functions. Always on is available only on an App Service plan. On a Consumption plan, the platform activates function apps automatically.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale#always-on</details>|
|39|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to insert code at line LE03 of LoginEvent.cs to ensure that all authentication events are processed correctly<br/>How should you complete the code?<br/><br/>a. public string id { get; set; }<br/>public string dataVersion { get; set; }<br/><br/>b. public string id { get; set; }<br/>public string eventType { get; set; }<br/><br/>c. public string dataVersion { get; set; }<br/>public string metadataVersion { get; set; }|<details><summary>Answer</summary>b. public string id { get; set; }<br/>public string eventType { get; set; }<br/><br/>id - Unique identifier for the event and it is mandatory<br/>eventType - One of the registered event types for this event source and it is mandatory.<br/>[<img src="https://i.imgur.com/hmmltfm.png">](https://i.imgur.com/hmmltfm.png)<br/>https://docs.microsoft.com/en-us/azure/event-grid/event-schema#event-properties</details>|
|40|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to add code at line EG15 in EventGridController.cs to ensure that the Log policy applies to all services.<br/>How should you complete the code?<br/><br/>a. if {<br/>@event["data"]["topic"].ToString() == "eventType" && @event["data"]<br/>["operationName"].ToString() == "Microsoft.Web/sites/write"<br/>}<br/><br/>b. if {<br/>@event["data"]["status"].ToString() == "Succeeded" && @event["data"]<br/>["operationName"].ToString() == 'Microsoft.Web/sites/write"<br/>}<br/>c. if {<br/>@event["data"]["status"].ToString() == "eventType" && @event["data"]<br/>["resourceProvider"].ToString() == "Microsoft.Web/sites/write"<br/>}<br/><br/>d. if {<br/>@event["data"]["status"].ToString() == "Succeeded" && @event["data"]<br/>["resourceProvider"].ToString() == "Microsoft.Web/sites/write"<br/>}|<details><summary>Answer</summary>b. if {<br/>@event["data"]["status"].ToString() == "Succeeded" &&<br/>@event["data"]["operationName"].ToString() == "Microsoft.Web/sites/write"<br/>}<br/><br/>Log policy: All Azure App Service Web Apps must write logs to Azure Blob storage.</details>|
|41|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to ensure that the solution can meet the scaling requirements for Policy Service.<br/>Which Azure Application Insights data model should you use?<br/><br/>a. an Application Insights metric<br/>b. an Application Insights trace<br/>c. an Application Insights dependency<br/>d. an Application Insights event|<details><summary>Answer</summary>a. an Application Insights metric<br/><br/>Scenario:<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/>Metric - used to report periodic scalar measurements.<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/data-model</details>|
|42|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to implement the Log policy.<br/>How should you complete the Azure Event Grid subscription?<br/>`{`<br/>`	"name": "newlogs",`<br/>`	"properties": {`<br/>`		"topic": "/subscriptions/.../providers/Microsoft.EventGrid/topics/...",`<br/>`		"destination": {`<br/>`			"endpointType": "<Code Snippert1>"	},`<br/>`			"filter": {`<br/>`				"<Code Snippert2>": "/blobServices/default/containers/logdrop/",`<br/>`				"includedEventTypes": [" <Code Snippert3> "] },`<br/>`	},`<br/>`	"labels": [],`<br/>`	"eventDeliverySchema": "EventGridSchema"`<br/>`}`<br/><br/>a. Code Snppert1:Webhook<br/>b. Code Snippet1:All<br/>c. Code Snippet1:Microsoft.Storage<br/>d. Code Snippet2:Microsoft.Storage<br/>e. Code Snippet2:subjectBegingsWith<br/>f. Code Snippet2:subjectEndWith<br/>g. Code Snippet3:Microsoft.Storage<br/>h. Code Snippet3:Microsoft.Storage.BlobCreated<br/>i. Code Snippet3:All|<details><summary>Answer</summary>a. Code Snippet1:Wbhook<br/>e. Code Snippet2:subjectBeginsWith<br/>h. Code Snippet3:Microsoft.Storage.BlobCreated<br/><br/>All Azure App Service Web Apps must write logs to Azure Blob storage. All log files should be saved to a container named logdrop. You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service. If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>endpointType - The type of endpoint for the subscription (webhook/HTTP, Event Hub, or queue). In this scenario, it is an Azure Function. So, it can be a webhook.<br/>subjectBeginsWith - A prefix-match filter to the subject field in the event message. In this scenario, logs are dropped to a container name logdrop.<br/>includedEventTypes - Match when the event type in the event message is an exact match to one of these event type names. In this scenario, when a log file is dropped. It means when a blob is created.<br/>https://docs.microsoft.com/en-us/azure/event-grid/subscription-creation-schema</details>|
|43|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to implement telemetry for non-user actions.<br/>How should you complete the Filter class?<br/>`public class Filter: <Code Snippet>`<br/>`{`<br/>`	private readonly <Code Snippet2> _next;`<br/>`	public (Filter <Code Snippet3> next)`<br/>`	{`<br/>`		_next = next;`<br/>`	}`<br/>`	public void Process(ITelemetry item)`<br/>`	{`<br/>`		var x = item as <Code Snippet4>;`<br/>`		if (x?.Url.AbsolutePath == "<Code Snippet5>")`<br/>`		{`<br/>`			return;`<br/>`		}`<br/>`		_next.Process(item);`<br/>`	}`<br/>`}`<br/><br/>a. Code Snippet1:ITelmetryProcessor<br/>b. Code Snippet1:ITelemetryInitializer<br/>c. Code Snippet2:ItelmetryProcessor<br/>d. Code Snippet2:ITelemetryInitializer<br/>e. Code Snippet3:ITelmetryProcessor<br/>f. Code Snippet3:ITelemetryInitializer<br/>g. Code Snippet4:RequestTelemetry<br/>h. Code Snippet4:PageViewTelemetry<br/>i. Code Snippet5:/health<br/>j. Code Snippet5:/status|<details><summary>Answer</summary>a. Code Snippet1:ITelmetryProcessor<br/>c. Code Snippet2:ItelmetryProcessor<br/>e. Code Snippet3:ItelmetryProcessor<br/>g. Code Snippet4:REquestTelemetry<br/>i. Code Snippet5:/health<br/><br/>Scenario: Exclude non-user actions from Application Insights telemetry.<br/>o create a filter, implement ITelemetryProcessor. Below is the sample code.<br/>`using Microsoft.ApplicationInsights.Channel;`<br/>`using Microsoft.ApplicationInsights.Extensibility;`<br/>`using Microsoft.ApplicationInsights.DataContracts;`<br/>` `<br/>`public class SuccessfulDependencyFilter : ITelemetryProcessor`<br/>`{`<br/>`	private ITelemetryProcessor Next { get; set; }`<br/>` `<br/>`	// next will point to the next TelemetryProcessor in the chain`<br/>`	public SuccessfulDependencyFilter(ITelemetryProcessor next)`<br/>`	{`<br/>`		this.Next = next;`<br/>`	}`<br/>` `<br/>`	public void Process(Itelemetry item)`<br/>`	{`<br/>`		// To filter out an item, return without calling the next processor`<br/>`		if (!OKtosend(item)) { return; }`<br/>` `<br/>`		this.Next.Process(item);`<br/>`	}`<br/>` `<br/>`	// eg: replace with your own criteria`<br/>`	private bool OKtosend (ITelemetry item)`<br/>`	{`<br/>`		var dependency = item as DependencyTelemetry;`<br/>`		if (dependency == null) return true;`<br/>` `<br/>`		return dependency.Success != true;`<br/>`	}`<br/>`}`<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/api-filtering-sampling</details>|
|44|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to ensure that PolicyLib requirements are met.<br/>How should you complete the code segment?<br/>`public class IncludedEventId : <Code Snippet1>`<br/>`{`<br/>`	public void <Code Snippet2> (ITelemetry telemetry)`<br/>`	{`<br/>`		<Code Snippet3>.Properties["EventId"] = <Code Snippet4>;`<br/>`	}`<br/>`}`<br/><br/>a. Code Snippet1:ItelemetryProcessor<br/>b. Code Snippet1:ItelemetryInitializer<br/>c. Code Snippet2:Process<br/>d. Code Snippet2:Initialize<br/>e. Code Snippet3:telemetry.Sequence<br/>f. Code Snippet3:telemetry.Context<br/>g. Code Snippet4:EventGridController.EventId.Value<br/>h. Code Snippet4:((EventTelemetry)telemetry).Properties["EventId"]|<details><summary>Answer</summary>b. Code Snippet1:ITelemetryInitializer<br/>d. Code Snippet2:Initialize<br/>f. Code Snippet3:telemetry.Context<br/>g. Code Snippet4:EventGridController.EventId.Value<br/><br/>Scenario: The application reacts to events from Azure Event Grid and performs policy actions based on those events. The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>You can add properties to telemetry by implementing ITelemetryInitializer which defines the Initialize method.<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/api-custom-events-metrics#sampling-filtering-and-processing-telemetry</details>|
|45|**Background -**<br/>You are a developer for Adam, Inc. You are developing an application that applies a set of governance policies for Adamâs internal services, external services, and applications.<br/>The application will also provide a shared library for common functionality.<br/>**Requirements -**<br/><br/>**Policy service -**<br/>You develop and deploy a stateful ASP.NET Core web application named Policy service to an Azure App Service Web App.<br/>The application reacts to events from Azure Event Grid and performs policy actions based on those events.<br/>The application must include the Event Grid Event ID field in all Application Insights telemetry.<br/>Policy service must use Application Insights to automatically scale with the number of policy actions that it is performing.<br/><br/>**Log policy -**<br/>All Azure App Service Web Apps must write logs to Azure Blob storage.<br/>All log files should be saved to a container named logdrop.<br/>Logs must remain in the container for 15 days.<br/><br/>**Authentication events -**<br/>Authentication events are used to monitor users signing in and signing out.<br/>All authentication events must be processed by Policy service<br/>Sign outs must be processed as quickly as possible.<br/>**PolicyLib -**<br/>You have a shared library named PolicyLib that contains functionality common to all ASP.NET Core web services and applications.<br/>The PolicyLib library must:<br/>Exclude non-user actions from Application Insights telemetry.<br/>Provide methods that allow a web service to scale itself.<br/>Ensure that scaling actions do not disrupt application usage.<br/>**Other -**<br/>**Anomaly detection service -**<br/>You have an anomaly detection service that analyzes log information for anomalies. It is implemented as an Azure Machine Learning model. The model is deployed as a web service<br/>If an anomaly is detected, an Azure Function that emails administrators is called by using an HTTP WebHook.<br/>**Health monitoring -**<br/>All web applications and services have health monitoring at the /health service endpoint.<br/>**Issues -**<br/>**Policy loss -**<br/>When you deploy Policy service, policies may not be applied if they were in the process of being applied during the deployment.<br/>**Performance issue -**<br/>When under heavy load, the anomaly detection service undergoes slowdowns and rejects connections.<br/>**Notification latency -**<br/>Users report that anomaly detection emails can sometimes arrive several minutes after an anomaly is detected.<br/>**App code -**<br/>EventGridController.cs -<br/>`public class EventGridController : EventGridController`<br/>`{`<br/>`	public static AsyncLocal<String> EventId = new AsyncLocal<string>();`<br/>`	public IactionResult Process([FromBody] string eventsJson)`<br/>`	{`<br/>`		var events = JArray.Parse(eventsJson);`<br/>` `<br/>`		foreach (var @event in events)`<br/>`		{`<br/>`			EventId.Value = @event["id"].ToString();`<br/>`			if (@event["topic"].ToString().Contains("providers/Microsoft.Storage"))`<br/>`			{`<br/>`				SendToAnomalyDetection Service(@event["data"]["url"].ToString());`<br/>`			}`<br/>`			{`<br/>`				EnsureLogging(@event["subject"].ToString());`<br/>`			}`<br/>`		}`<br/>`		return null;`<br/>`	}`<br/>`	private void EnsureLogging(string resource)`<br/>`	{`<br/>`		...`<br/>`	}`<br/>`	private async Task SendToAnomalyDetectionService(string uri)`<br/>`	{`<br/>`		var content = GetLogData(uri)`<br/>`		var scoreRequest = new`<br/>`		{`<br/>`			Inputs = new Dictionary<string, List<Dictionary<string, string>>>()`<br/>`			{`<br/>`				"input1",`<br/>`				new List<Dictionary<String, String>>()`<br/>`				{`<br/>`					new Dictionary<String, String>()`<br/>`					{`<br/>`						{`<br/>`							"logcontent", content`<br/>`						}`<br/>`					}`<br/>`				}`<br/>`			},`<br/>`		},`<br/>`	GlobalParameters = new Dictionary<String, String>()()`<br/>`	};`<br/>`	var result = await (new HttpClient()).PostAsJsonAsync("...", scoreRequest);`<br/>`	var rawModelResult = await result.Content.ReadAsStringAsync();`<br/>`	var modelResult = JObject.Parse(rawModelResult);`<br/>`if (modelResult ["notify"].HasValues)`<br/>`{`<br/>`...`<br/>`}`<br/>`private (String name, String resourceGroup) ParseResourceId(string resourceId)`<br/>`{`<br/>`...`<br/>`}`<br/>`private String GetLogData(String uri)`<br/>`{`<br/>`...`<br/>`}`<br/>`static string BlobStorageAccountSAS (String ContainerName)`<br/>`{`<br/>`...`<br/>`}`<br/>`}`<br/><br/>LoginEvent.cs â<br/>`public class LoginEvent`<br/>`{`<br/>` `<br/>`	public string subject { get ; set ; }`<br/>`public DateTime eventTime { get ; set ; }`<br/>`	public Dictionary<string, string> data { get; set; }`<br/>`	public string Serialize()`<br/>`	{`<br/>`		return JsonConvert.SerializeObject(this);`<br/>`	}`<br/>`}`<br/>**Question**<br/>You need to implement the Log policy.<br/>How should you complete the EnsureLogging method in EventGridController.cs?<br/>`var client = new WebSiteManagementClient(...);`<br/>`var id = ParseResourceID(resource);`<br/>`var appSettings = new StringDictionary(name: "properties",`<br/>`	properties: new StringDictionary<string, string> {`<br/>`		{"DIAGNOSTICS_AZUREBLOBCONTAINERSASURL", BlobStoreAccountSAS("<Code Snippet1")};`<br/>`		{"DIAGNOSTICS_AZUREBLOBRETENTIONINDAYS", "<Code Snippet2>"}`<br/>`	});`<br/>`	client.WebApps.<Code Snippet3>`<br/>`	id.resourceGroup,`<br/>`	id.name, appSettings);`<br/><br/>a. Code Snippet1:logs<br/>b. Code Snippet1:logdrop<br/>c. Code Snippet2:15<br/>d. Code Snippet2:30<br/>e. Code Snippet3:UploadLoggingSettings<br/>f. Code Snippet3:UpdateApplicationSetting|<details><summary>Answer</summary>b. Code Snippet1:logdrop<br/>c. Code Snippet2:15<br/>f. Code Snippet3:updateApplicationSetting<br/><br/>Scenario: All Azure App Service Web Apps must write logs to Azure Blob storage. All log files should be saved to a container named logdrop. Logs must remain in the container for 15 days.</details>|

---

## Results
|n|Data|Note|Revision|
|-|----|----|--------|
|1|07-08-2023|20/45 = 44%|<details><summary>Revision</summary>True</details>|
