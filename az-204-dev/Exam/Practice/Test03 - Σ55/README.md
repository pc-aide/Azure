# Test03 - Σ55

---

## Questions
|n|Question|Answer|
|-|--------|------|
|1|You have an Azure Storage account named StorageAccount1.<br/>You plan to store data that is rarely accessed in StorageAccount1 for several years.<br/>You must ensure that the data in Blob storage is always available for immediate access<br/>The solution must minimize storage costs.<br/>Which storage tier should you use ?<br/><br/>a. Cool<br/>b. Archive<br/>c. Hot|<details><summary>Answer</summary>a. Cool<br/><br/>The cool access tier has lower storage costs and higher access costs compared to hot storage. This tier is intended for data that will remain in the cool tier for at least 30 days. Example usage scenarios for the cool access tier include:<br/><br/>Short-term backup and disaster recovery datasets.<br/>Older media content not viewed frequently anymore but is expected to be available immediately when accessed.<br/>Large data sets that need to be stored cost effectively while more data is being gathered for future processing. (For example, long-term storage of scientific data, raw telemetry data from a manufacturing facility)<br/><br/>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-storage-tiers?tabs=azure-portal</details>|
|2|You are developing a web service that should prevent anonymous usage and use OpenID connect for authentication.<br/>You need to implement an API Management policy for the web service. Which policy should you use ?<br/><br/>a. Convert XML to JSON<br/>b. validate-client-certificate<br/>c. Check-header<br/>d. Validate-jwt|<details><summary>Answer</summary>d. validate-jwt<br/><br/>The requirement from the question to validate requests using API management policy. You can use the Validate JWT policy to pre-authorize requests in API Management, by validating the access tokens of each incoming request. If a request does not have a valid token, API Management blocks it.<br/>https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-protect-backend-with-aad#configure-a-jwt-validation-policy-to-pre-authorize-requests</details>|
|3|You are a developer for a company that publishes APIs using Azure API Management. You need to strip AspNet-Version from the response of the APIs.<br/>What should you implement ?<br/><br/>a. A new product<br/>b. A URL Scheme<br/>c. A new policy<br/>d. A new version|<details><summary>Answer</summary>c. A new policy<br/><br/>You need to transform your API so it does not reveal info about the private backend. To delete the following headers in the HTTP response, you need to set a transformation policy.<br/>X-Powered-By<br/>X-AspNet-Version<br/>https://docs.microsoft.com/en-us/azure/api-management/transform-api#transform-an-api-to-strip-response-headers</details>|
|4|You plan to migrate several web applications that uses a MongoDB database to Microsoft Azure. You must complete the migration with minimal changes to source code and configuration.<br/>You need to implement the Cosmos DB configuration. What should you use ?<br/><br/>a. Use SQL API<br/>b. Mongo DB API<br/>c. Cassandra API<br/>d. Gremlin API<br/>e. Azure Table API|<details><summary>Answer</summary>b. Mnogo DB API<br/><br>In this scenario, we are migrating applications which uses MongoDB database, so we must use Mongo DB API to minimize the code changes.<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/create-mongodb-dotnet</details>|
|5|You need to consume messages from a messaging component that is developed using Azure Service Bus publish-subscribe model. You have initialized a subscription client object using correct details to process messages. However, the subscription application is still not consuming the messages.<br/>Which of the below code segment should you use ?<br/><br/>a. await subscriptionClient.AddRuleAsync(newRuleDescription(RuleDescription.DefaultRuleName,New TrueFilter()));<br/>b. subscriptionClient = new SubscriptionCient(ServiceBusConnectionString,TopicName,SubscriptionName);<br/>c. await subscriptionClient.CloseAsync();<br/>d. subscriptionClient.RegisterMessageHandler(ProcessMessageAsync,messagehandlerOptions);|<details><summary>Answer</summary>d. subscriptionClient.RegisterMessagehandler(ProcessMessageAsync,messageHandlerOptions);<br/><br/>RegisterMessageHandler handles messages one by one and completes them in the end.<br/>https://docs.azure.cn/en-us/dotnet/api/microsoft.azure.servicebus.queueclient.registermessagehandler?view=azure-dotnet</details>|
|6|You are developer for a company named Company1<br/>Company1 has an application that uses Azure Cosmos DB configured with Azure Cosmos DB SQL API.<br/>The database contains millions of documents without distinct values for partitioning.<br/>You need to implement a scaling strategy for the database to scale individual containers<br/>The database must meet the performance requirements of the application by spreading the workload evenly across all partitions over time.<br/>You need to select a partition key.<br/><br/>Which two partition keys can you use ?<br/><br/>a. a concatenation of multiple property values with a random suffix appended<br/>b. a single property value that doest not appear frequently in the documents<br/>c. a hash suffix appended to a property value<br/>d. a value containing the collection name<br/>e. a single property value that appear frequently in the documents|<details><summary>Answer</summary>a. a concatenation of multiple property values with a random suffix appended<br/>c. a hash suffix appended to a property value<br/><br/>The goal is to distribute your data and workload evenly across the items associated with these partition key values. If such a property doesn’t exist in your data, you can construct a synthetic partition key.<br/>You can form a partition key by concatenating multiple property values into a single artificial partition Key property. These keys are referred to as synthetic keys.<br/>Another possible strategy to distribute the workload more evenly is to append a random number at the end of the partition key value. When you distribute items in this way, you can perform parallel write operations across partitions<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/synthetic-partition-keys</details>|
|7|You developing an application named Application1 that uses Azure Blob storage named Storage1.<br/>For audit purposes, Application1 must read the transaction logs of all changes that occur to the blobs and blob metadata in Storage1.<br/>The changes must be in the order in which they occurred.<br/>You need to process the logs asynchronously and should include only create, update, delete and copy operations.<br/>What should you do to implement audit requirement?<br/><br/>a. Process Blob storage events by using Azure Function app & scan the request body for successful blob events<br/>b. Enable the change feed on the storage account & process all changes for available events<br/>c. Process all Azure Storage logs for successful blob events<br/>d. Configure the Azure Monitor HTTP Data Collector API & scan the request body for successful blob events|<details><summary>Answer</summary>b. Enable the chage feed on the storage account & process all changes for available events<br/><br/>Change feed provides transaction logs of all the changes that occur to the blobs and the blob metadata in your storage account.<br/>The change feed provides ordered, guaranteed, durable, immutable, read-only log of these changes. Client applications can read these logs at any time, either in streaming or in batch mode<br/>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-change-feed?tabs=azure-portal</details>|
|8|You have created an Azure File Storage in an Azure storage account named StorageAccount1. You have generated a Shared access signature (SAS) token with read and write access to Azure File storage<br/><br/>Select the tool that can be used to access data in StorageAccount1 using SAS token ?<br/><br/>a. RoboCopy<br/>b. Microsoft Azure Storage Explorer<br/>c. Windows Explorer<br/>d. File Explorer|<details><summary>Answer</summary>b. Microsoft Azure Storage Explorer<br/><br/>Microsoft Azure Storage Explorer is a standalone app that makes it easy to work with Azure Storage data on Windows, macOS, and Linux.</details>|
|9|You have a service principal named ServicePrincipal1. You need to provide read access to ServicePrincipal1 to read the resources in a resource group named ResourceGroup1.<br/><br/>Select the actions that should you perform in the correct sequence ?<br/><br/>a. Navigate to ServicePrincipal1 in AAD - App registrations<br/>Select Access Control (IAM)<br/>Add role assignment with role as Reader<br/><br/>b. Navigate to ResourceGroup1<br/>Select Access Control (IAM)<br/>Add role assianment with role as Reader<br/><br/>c. Navigate to ResourceGroup1<br/>Select Access Control (IAM)<br/>Add role assignment with role as Contributor|<details><summary>Answer</summary>b. Navigate to ResourceGroup1<br/>Select Access Control (IAM)<br/>Add role assignment with role as Reader<br/><br/>To access resources in your subscription, you must assign a role to the application. Permissions are inherited to lower levels of scope. For example, adding an application to the Reader role for a resource group means it can read the resource group and any resources it contains.<br/>To assign a role at the resource group scope, search for and select “Resource Groups”, select the particular resource group, select Access Control (IAM), Select Add -> Add role assignment, Select the role you wish to add.<br/>https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal#assign-a-role-to-the-application</details>|
|10|You are developing an application that executes short lived processes on a schedule.<br/>You need to recommend a service that keeps costs and admin activities minimal.<br/>What should you recommend ?<br/><br/>a. Azure Web App<br/>b. Azure Function<br/>c. Azure VM<br/>d. Azure Logic Apps|<details><summary>Answer</summary>b. Azure Function<br/><br/>Azure Functions allows you to run small pieces of code (called "functions") without worrying about application infrastructure. A function is "triggered" by a specific type of event. Supported triggers include responding to changes in data, responding to messages, running on a schedule, or as the result of an HTTP request<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview</details>|
|11|Which Azure RBAC roles allows you to upload images to an Azure Container Registry ?<br/><br/>a. AcrPush<br/>b. AcrPull<br/>c. AcrImageSigner<br/>d. Contributor|<details><summary>Answer</summary>a. AcrPush<br/>d. Contributor<br/><br/>[<img src="https://i.imgur.com/DAHPaLx.png">](https://i.imgur.com/DAHPaLx.png)</details>|
|12|You define an API Policy object by using the below XML markup:<br/>[<img src="https://i.imgur.com/L1eIzuZ.png">](https://i.imgur.com/L1eIzuZ.png)<br/>Select Yes if the below statement is true. Otherwise, select No<br/>1. The XML Segment is part of the <inbound> section of the API policy.<br/>2. An error will be thrown is the body size is >265k<br/>3. The policy will retain the higher version is the request is http://preparationlabs.com/api/8.2/<br/><br/>a. Yes,Yes,Yess<br/>b. No,No,No<br/>c. Yes,No,No<br/>d. No,Yes,yes<br/>e. Yes,No,Yes|<details><summary>Answer</summary>c. Yes,No,No<br/><br/>1. The set-backend-service policy is used to redirect incoming requests. Therefore, this policy definition is part of inbound section<br/>Https://docs.microsoft.com/en-us/azure/api-management/api-management-advanced-policies#choose<br/>2. The condition on body size 400K. So, you will not get an error.<br/>3. There are conditions defined in the policy based on the body size. So, it will not retain the higher version always. The default/otherwise is version 8.1</details>|
|13|You have deployed several web applications into Azure App Service. You need to collect detailed resource logs for monitoring health and availability of Azure App Service.<br/><br/>Select the following options should you consider as destination ?<br/><br/>a. Log Analytics<br/>b. Storage Account<br/>c. Event Hub<br/>d. All of the above|<details><summary>Answer</summary>d. All of the above<br/><br/>[<img src="https://i.imgur.com/8NQyY3s.png">](https://i.imgur.com/8NQyY3s.png)<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/essentials/diagnostic-settings?tabs=CMD#destinations</details>|
|14|A software as a service (SaaS) company is developing a web service for several customers.<br/>The web service connects to a SQL database in an on-premise environment. You plan to deploy the web service to an Azure Web App.<br/>The web service also includes a WebJob that processes data and each instance of WebJob must process data for a single customer<br/>You need to configure Azure resources in an isolated network.<br/>Which pricing tier should you consider for the App Service plan keeping costs minimal ?<br/><br/>a. Standard<br/>b. Isolated<br/>c. Premium<br/>d. Consumption|<details><summary>Answer</summary>b. Isolated<br/><br/>The Isolated service plan is designed to run mission-critical workloads that are required to run in a virtual network. The Isolated plan allows customers to run their apps in a private, dedicated environment in an Azure data centre.<br/>https://azure.microsoft.com/en-au/pricing/details/app-service/windows/</details>|
|15|You have deployed an application in Azure and configured below rules in auto scaling<br/>a) If CPU < 30%, scale-in by 1<br/>b) If Memory < 50%, scale-in by 1<br/>c) If CPU > 75%, scale-out by 1<br/>d) If Memrory > 75%, scale-out by 1<br/>Then the follow occurs:<br/>If CPU is 76% and Memory is 50%<br/><br/>What happens to instance count ?<br/><br/>a. Scale out by 1<br/>b. Scale out by 2<br/>c. Scale in by 1<br/>c. Scale in by 1<br/>d. Scale in by 2|<details><summary>Answer</summary>a. Scale out by 1<br/><br/>The following autoscale rules are used by the autoscale engine when multiple rules are set<br/>On scale-out, autoscale runs if any rule is met. On scale-in, autoscale require all rules to be met<br/>So, in this scenario, CPU condition is met, it will scale out by 1 instance</details>|
|16|You have an application named Application1 in an Azure App Service named AppService1.<br/>Your application users are currently accessing Application1 using http://yourdomain.com.<br/>You need to enforce Application1 users to use https://yourdomain.com.<br/>What changes should you implement ?<br/><br/>a. Upload a certificate to AppService1<br/>b. Add a custom domain preparationlabs.com to AppService1<br/>c. Upgrade App Service Plan to Premium<br/>d. Set HTTPS Only to On|<details><summary>Answer</summary>a. Upload a certificate to AppService1<br/>d. Set HTTPS Only to On<br/><br/>By default, you can access your app using HTTP. You can redirect all HTTP requests to the HTTPS port.<br/>In your app page, in the left navigation, select SSL settings. Then, in HTTPS Only, select On.<br/>https://docs.microsoft.com/en-us/azure/app-service/configure-ssl-bindings#enforce-https</details>|
|17|You have uploaded a certificate to an Azure Web App named Application1.<br/>You need to access the certificate from the app code of Application1.<br/>What should you configure ?<br/><br/>a. Add a managed identity to Application1<br/>b. Add an app setting (WEBSITE_LOAD_CERTIFICATES) to the Application1 configuration<br/>c. Configure the TLS/SSL binding for Application1|<details><summary>Answer</summary>b. Add an app setting<br/>(WEBSITE_LOAD_CERTIFICATES) to the<br/>Application1 configuration<br/><br/>In your application code, you can access the public or private certificates you add to App Service. Your app code may act as a client and access an external service that requires certificate authentication, or it may need to perform cryptographic tasks.<br/>The WEBSITE_LOAD_CERTIFICATES app setting makes the specified certificates accessible to your Windows hosted app in the Windows certificate store,<br/>https://docs.microsoft.com/en-us/azure/app-service/configure-ssl-certificate-in-code</details>|
|18|You have an Azure Active Directory (Azure AD) tenant.<br/>You need to register an application with your Azure AD tenant.<br/>Which three actions should you perform in sequence ?<br/><br/>a. In App Registrations, select New registration<br/>Select the AAD Instance<br/>Create a new application & provide the name, account type & redirect URL<br/><br/>b. Select the AAD Instance<br/>In App Registrations, select New registration<br/>Create a new application & provide the name, account type & redirect URL<br/><br/>c. In App Registrations, select New Registration<br/>Select the AAD Instance<br/>Use an access token to access the secure resource|<details><summary>Answer</summary>b. Select the AAD Instance<br/>In App Registrations,select New registration<br/>Create a new application & provide the name,<br/>account type & redirect URL<br/><br/>https://docs.microsoft.com/en-us/azure/active-directory/develop/quickstart-register-app</details>|
|19|You are developing multiple ASP.NET applications that will be deployed to several Azure App Services.<br/>You need to save session state that can be shared across all ASP.NET applications.<br/>Session data can be accessed by multiple concurrent readers at a time, but will have a single writer.<br/><br/>You have enabled application request routing to save session state.<br/><br/>Did you achieve the requirement ?<br/><br/>a. Yes<br/>b. No|<details><summary>Answer</summary>b. No<br/><br/>ARR directs request to same instance of the application. Instead, you can use a caching solution like Azure Redis Cache.<br/>https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-overview</details>|
|20|You are developing multiple ASP.NET applications that will be deployed to several Azure App Services.<br/>You need to save session state that can be shared across all ASP.NET applications.<br/>Session data can be accessed by multiple concurrent readers at a time, but will have a single writer.<br/><br/>You have deployed Azure PostgreSQL to save session state.<br/>Did you achieve the requirement ?<br/><br/>a. Yes<br/>b. No|<details><summary>Answer</summary>b. No<br/><br/>Instead, you can use a caching solution like Azure Redis Cache.<br/>https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-overview</details>|
|21|You are developing multiple ASP.NET applications that will be deployed to several Azure App Services.<br/>You need to save session state that can be shared across all ASP.NET applications.<br/>Session data can be accessed by multiple concurrent readers at a time, but will have a single writer.<br/><br/>You have deployed Azure Cache for Redis to save session state.<br/>Did you achieve the requirement ?<br/><br/>a. Yes<br/>b. No|<details><summary>Answer</summary>a. Yes<br/><br/>Azure Cache for Redis provides an in-memory data store based on the open-source software Redis. Redis improves the performance and scalability of an application that uses on backend data stores heavily.<br/>Azure Cache for Redis can be used as a distributed data or content cache, a session store, a message broker.<br/>https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-overview</details>|
|22|You have a web application that is deployed to an Azure App Service.<br/>You need to implement an Azure monitoring service that can log requests and exceptions to a specific line of code within the application.<br/>Which service should you use ?<br/><br/>a. Azure Application Insights<br/>b. Azure Log Analytics<br/>c. Azure Activity Log|<details><summary>Answer</summary>a. Azure Application Insights<br/><br/>Application Insights is an extensible Application Performance Management (APM) service for developers and DevOps professionals. Use it to monitor your live applications. It will automatically detect performance anomalies, and includes powerful analytics tools to help you diagnose issues and to understand what users actually do with your app. It's designed to help you continuously improve performance and usability. It works for apps on a wide variety of platforms including .NET, Node.js, Java, and Python hosted on-premises, hybrid, or any public cloud. It integrates with your DevOps process, and has connection points to a variety of development tools. It can monitor and analyze telemetry from mobile apps by integrating with Visual Studio App Center.<br/></details>|
|23|You have a web application that is deployed to an Azure App Service.<br/>You need to implement an Azure monitoring service that can analyze how many users return to the application and how often they select a particular dropdown value.<br/>Which service should you use?<br/><br/>a. Azure Application Insights<br/>b. Auzre Log Analytics<br/>c. Azure Activity Log|<details><summary>Answer</summary>a. Azure Application Insights<br/><br/>Custom events and metrics in App insights allow you write yourself in the client or server code, to track business events such as items sold or games won.<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview</details>|
|24|You have a web application that is deployed to an Azure App Service.<br/>You need to implement an Azure monitoring service that can visualize the relationships between application components.<br/>Which service should you use ?<br/>a. Azure Application Insights<br/>b. Azure Log Analytics<br/>c. Azure Activity Log|<details><summary>Answer</summary>a. Azure Application Insights<br/><br/>Application Map helps you spot performance bottlenecks or failure hotspots across all components of your distributed application. You can see the full application topology across multiple levels of related application components. Components could be different Application Insights resources, or different roles in a single resource. The app map finds components by following HTTP dependency calls made between servers with the Application Insights SDK installed<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-map?tabs=net</details>|
|25|You have an application named Application1.<br/>Application1 generates log files that must be archived for seven years.<br/>The log files must be readable by Application1 but must not be modified.<br/>Which storage solution should you recommend ?<br/><br/>a. Azure Blob storage account with a time-based retention policy<br/>b. Azure Log Analytics workspace<br/>c. Azure Blob Storage account that is configured to use the Archive access tier|<details><summary>Answer</summary>a. Azure Blob storage account with a time-based retention policy<br/><br/>Time-based retention policy support allows Users can set policies to store data for a specified interval. When a time-based retention policy is set, blobs can be created and read, but not modified or deleted. After the retention period has expired, blobs can be deleted but not overwritten<br/>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-immutable-storage#time-based-retention-policies</details>|
|26|You are developing a solution that uses publish-subscribe model and eliminates the need for constant polling<br/>Select the two possible Azure messaging services to achieve the requirement.<br/><br/>a. Service Bus<br/>b Event Hub<br/>c. Event Grid<br/>d. Queue|<details><summary>Answer</summary>a. Service Bus<br/>c. Event Grid<br/><br/>Event Grid - Event Grid is an eventing backplane that enables event-driven, reactive programming. It uses a publish-subscribe model.<br/>Publishers emit events, but have no expectation about which events are handled. Subscribers decide which events they want to handle.<br/>Service Bus Topics and subscriptions enable relationships between publishers and subscribers.<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview<br/>https://docs.microsoft.com/en-us/azure/event-grid/compare-messaging-services#event-vs-message-services</details>|
|27|You have an Azure API Management service. You have deployed the API back end in an Azure App Service.<br/>What should you configure as target and gateway credential type for back-end authentication ?<br/><br/>a. Target - Azure Resourcce<br/>Gateway credential Type - Client cert<br/><br/>b. Target - Azure Resource Gateway credential Type - Basic<br/><br/>c. Target - Http(s) endpoint<br/>Gateway credential Type - Client cert|<details><summary>Answer</summary>c. Target - Http(s) endpoing<br/>Gateway credential Type - Client cert<br/><br/>API Management allows you to secure access to the back-end service of an API using client certificates.<br/>The target endpoint should be HTTP(s) as shown below.<br/>[<img src="https://i.imgur.com/KNeHorB.png">](https://i.imgur.com/KNeHorB.png)<br/>https://docs.microsoft.com/en-us/azure/api-management/api-management-howto-mutual-certificates</details>|
|28|You have a storage account named Storage1. You need to create a copy of Storage1 in another region and copy data to newly created storage account.<br/>Select the order in which should you perform the below actions ?<br/><br/>1. Use AZCopy to copy the data<br/>2. Deploy the template to create a new storage account in the target region.<br/>3. Export a Resource Manager template.<br/>4. Create a new template deployment.<br/>5. Modify the template by changing the storage account name & region.<br/><br/>a. 3,5,2,4,1<br/>b. 3,5,4,2,1<br/>c. 3,1,5,2,4|<details><summary>Answer</summary>b. 3,5,4,2,1<br/><br/>https://docs.microsoft.com/en-us/azure/storage/common/storage-account-move</details>|
|29|You are creating a CLI script that creates an Azure web app and related services in Azure App Service.<br/>You need to automatically deploy code from Git-Hub to the newly created web app.<br/>The web app uses the following variables:<br/><br/>$gitrepo=https://github.com/samples/app1<br/>$webappname=mywebapp<br/><br/>Select the correct script from below<br/><br/>a. az group create --location westeurope --name myResourceGroup<br/>az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname<br/>az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE<br/>az webapp deployment source config --name $webappname --resource-group myResourceGroup --repo-url $gitrepo --branch master --manual-integration<br/><br/>b. az group create --location weseurope --name myResourceGroup<br/>az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE<br/>az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname<br/>az webapp deployment source config --name $webappname --resource-group myResourceGroup --repo-url $gitrepo --branch master --manual-integration<br/><br/>c. az group create --location westeurope --name myResourceGroup<br/>az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE<br/>az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname<br/>az webapp create source config --name $webappname --resource-group myResourceGroup --repo-url $gitrepo --branch master --manual-integration<br/><br/>d. az group create --location westeurope --name myResourceGroup<br/>az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE<br/>az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname<br/>az webapp deployment source config --name $webappname --resource-group myResourceGroup git clone $gitrepo|<details><summary>Answer</summary>b. az group create --location westeurope --name myResourceGroup<br/>az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE<br/>az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname<br/>az webapp deployment source config --name<br/>$webappname --resource-group myResourceGroup --repo-url $gitrepo --branch master --manual-integration<br/><br/>The correct script is<br/>$gitrepo=https://github.com/samples/app1<br/>$webappname=mywebapp<br/># Create a resource group.<br/>az group create --location westeurope --name myResourceGroup<br/><br/># Create an App Service plan in `FREE` tier.<br/>az appservice plan create --name $webappname --resource-group myResourceGroup --sku FREE<br/><br/># Create a web app<br/>az webapp create --name $webappname --resource-group myResourceGroup --plan $webappname<br/><br/># Deploy code from a public GitHub repository<br/>az webapp deployment source config --name $webappname --resource-group myResourceGroup \ <br/>--repo-url $gitrepo --branch master --manual-integration<br/>https://docs.microsoft.com/en-us/azure/app-service/scripts/cli-deploy-github?toc=/cli/azure/toc.json</details>|
|30|You are deploying an ASP.NET Core web application to an Azure Web App.<br/>The source code of the web application is in a GitHub repository. The web application includes static content generated by a script.<br/>Azure Web App continuous deployment feature is planned to complete the deployment.<br/>Before website serves traffic, you must run the static generation scripts.<br/>Select the two possible ways to achieve this requirement ?<br/><br/>a. Create a file named .deployment in the root of the repository that calls a script which generates the static content & deploys the website.<br/>b. Add a PreBuild target in the websites csproj project file that runs the static content generation script<br/>c. Create a file name run.cmd in the folder /run that calls a script which generates the static content & deploys the website<br/>d. Add the path to static content generation tool to WEBSITE_RUN_FROM_PACKAGE setting in the host.json file|<details><summary>Answer</summary>a. Create a file named .deployment in the root of the<br/>repository that calls a script which generates the<br/>static content & deploys the website<br/><br/>If you want to customize the deployment process, for example you want to run your tests before deploying (or after) and cancel the deployment if they fail ?<br/>That's what the custom deployment feature is about, you just need to add a file to the root of your repository with the name .deployment and the content:<br>[config]<br/>command = YOUR COMMAND TO RUN FOR DEPLOYMENT<br/>this command can be just running a script (batch file) that has all that is required for your deployment, like copying files from the repository to the web root directory for example.<br/>https://github.com/projectkudu/kudu/wiki/Custom-Deployment-Script</details>|
|31|A user named User1 has access to multiple subscriptions. User1 must be able to store and retrieve a storage account key and secret from Azure Key Vault.<br/>Select the order in which should you arrange the below PowerShell commands to achieve the goal ?<br/><br/>1. Get-AzStorageAccountKey -ResourceGroupName $resGroup -Name $storAcct<br/>2. Get-AzKeyVaultSecret -VaultName $vaultName<br/>3. Get-AzSubscription<br/>4. $secretvalue = ConvertTo-SecureString $storAcctKey -AsPlainText -Force<br/>Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue<br/>5. Set-AzContext -SubscriptionId $subscriptionID<br/><br/>s. 1,2,3,4,5<br/>b. 3,5,1,4,2<br/>c. 3,2,1,4,5|<details><summary>Answer</summary>b. 3,5,1,4,2<br/><br/>1. 1.Get-AzSubscription<br/>2. 2.Set-AzContext -SubscriptionId $subscriptionID<br/>3.Get-AzStorageAccountKey -ResourceGroupName $resGroup -Name $storAcct<br/>4.$secretvalue = ConvertTo-SecureString $storAcctKey -AsPlainText -Force<br/>Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue<br/>5. .Get-AzKeyVaultSecret -VaultName $vaultName<br/>https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-powershell</details>|
|32|You are developing an ASP.NET Core Web API web service.<br/>The web service uses Azure Application Insights for all telemetry and dependency tracking.<br/>The web service reads and writes data to a third-party database other than Microsoft SQL Server.<br/>You need to ensure that dependency tracking works for requests to the third-party database<br/><br/>Which of the following dependency telemetry properties should you use? Choose 2 answers.<br/><br/>a. Telemetry.Context.Cloud.RoleInstance<br/>b. Telemetry.Id<br/>c. Telemetry.Name<br/>d. Telemetry.Context.Operation.Id<br/>e. Telemetry.Context.Session.Id|<details><summary>Answer</summary>b. Telemetry.Id<br/>Telemetry.Context.Operation.Id<br/><br/>The correlation identifiers are Telemetry.Id & Telemetry.Context.Operation.Id<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/custom-operations-tracking</details>|
|33|You are developing a web application using ASP.NET Core that is planned to deploy to Azure Web App for Containers.<br/>The application needs to store runtime diagnostic data that must be persisted across application restarts. You have the following code:<br/>[<img src="https://i.imgur.com/2bQuizz.png">](https://i.imgur.com/2bQuizz.png)<br/>You need to configure the application settings so that diagnostic data is stored as required.<br/>How should you configure the web app's settings ?<br/>a. LOCALAPPDATA = true<br/>DIAGDATA = /home<br/><br/>b. WEBSITES_ENABLE_APP_SERVICE_STORAGE = true<br/>DIAGDATA = /home<br/>c. WEBSITES_ENABLE_APP_SERVICE_STORAGE = false<br/>DIAGDATA = /local<br/><br/>d. WEBSITES_ENABLE_APP_SERVICE_STORAGE = false<br/>DIAGDATA = /home|<details><summary>Answer</summary>b. WEBSITES_ENABLE_APP_SERVICE_STORAGE = TRUE<br/>DIAGDATA = /HOME<br/><br/>If WEBSITES_ENABLE_APP_SERVICE_STORAGE setting is unspecified or set to true, the /home/ directory will be shared across scale instances, and files written will persist across restarts. Explicitly setting WEBSITES_ENABLE_APP_SERVICE_STORAGE to false will disable the mount<br/>https://docs.microsoft.com/en-us/azure/app-service/faq-app-service-linux</details>|
|34|You are developing an application that uses Azure Storage Queues.<br/>You have the following code:<br/>[<img src="https://i.imgur.com/jOcKXVn.png">](https://i.imgur.com/jOcKXVn.png)<br/>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br/>1. The code configures the lock duration for the queue<br/>2. The last message read remains in the queue after the code runs<br/>3. The storage queue remains in the storage account after the code runs<br/><br/>a. Yes,No,No<br/>b. No,No,Yes<br/>c. No,No,No<br/>d. No,Yes,Yes|<details><summary>Answer</summary>d. No,Yes,Yes<br/><br/>1. Code is not implementing any locks on the queue. So it is NO<br/>2. Messages are not deleted automatically from Azure Storage account queues and program is not deleting. So it is Yes<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted#comparing-storage-queues-and-service-bus-queues<br/>3. The queue remains in the storage account because the code is not deleting it.</details>|
|35|You are developing an application that uses Azure Cosmos DB resource and the Cassandra API in the application.<br/>You have an Azure Active Directory (Azure AD) group named DatabaseCreators to enable provisioning of Azure Cosmos accounts, databases, and containers.<br/>The DatabaseCreators group must not be able to access the keys that are required to access the data.<br/>Which role-based access control should you use for DatabaseCreators group ?<br/><br/>a. DocumentDB Accounts Contributor<br/>b. Cosmos Backup Operator<br/>c. Cosmos DB Operator<br/>d. Cosmos DB Account Reader|<details><summary>Answer</summary>c. Cosmos DB Operator<br/><br/>Cosmos DB Operator - Lets you manage Azure Cosmos DB accounts, but not access data in them. Prevents access to account keys and connection strings<br/>https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#cosmos-db-operator</details>|
|36|You are developing a web application that will be hosted in an Azure Web App<br/>The users for web application will be authenticated by using their Azure Active Directory (Azure AD).<br/>Users will be assigned with one of the following permission levels: admin, normal, and reader.<br/>A user's Azure AD group membership must be used to determine the permission level.<br/><br/>To achieve the above mentioned requirement, you have created a new Azure AD application and configured the value of the groupMembershipClaims option to All in the application's manifest. In the web application, you use the value of the groups claim from the JWT for the user to determine permissions.<br/><br/>Did you achieve the requirement ?<br/><br/>a. yes<br/>b. No|<details><summary>Answer</summary>a. yes<br/><br/>To configure group’s optional claims through the application manifest, use groupMembershipClaims.<br/>The valid values for groupMembershipClaims are:<br/>"All" (this option includes SecurityGroup, DirectoryRole, and DistributionList)<br/>"SecurityGroup"<br/>"DirectoryRole"<br/>"ApplicationGroup" (this option includes only groups that are assigned to the application)<br/>https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-optional-claims</details>|
|37|You are developing a web application that will be hosted in an Azure Web App<br/>The users for web application will be authenticated by using their Azure Active Directory (Azure AD).<br/>Users will be assigned with one of the following permission levels: admin, normal, and reader.<br/>A user's Azure AD group membership must be used to determine the permission level.<br/><br/>To achieve the above requirement, you have configured the Azure Web App for the website to allow only authenticated requests and require Azure AD log on<br/>Did you achieve the requirement?<br/><br/>a. Yes<br/>b. No|<details><summary>Answer</summary>b. No<br/><br/>You also need to configure app manifest file to get the user's groups.</details>|
|38|You are developing a web application that will be hosted in an Azure Web App.<br/>The users for web application will be authenticated by using their Azure Active Directory (Azure AD).<br/>Users will be assigned with one of the following permission levels: admin, normal, and reader.<br/>A user's Azure AD group membership must be used to determine the permission level.<br/><br/>To achieve the above requirement, you have assigned the appropriate Azure AD groups to each role. You have created a new Azure AD application and defined application roles that match the required permission levels for the application in the applications manifest. In the web application, you use the value of the groups claim from the JWT for the user to determine permissions.<br/>Did you achieve the requirement ?<br/><br/>a. Yes<br/>b. No|<details><summary>Answer</summary>a. Yes<br/><br/>ou define app roles by using the Azure portal. App roles are usually defined on an application registration representing a service, app or API. When a user signs in to the application, Azure AD emits a roles claim for each role that the user or service principal has been granted individually to the user and from their group membership. There are two ways to declare app roles by using the Azure portal:<br/>App roles UI \| Preview<br/>App manifest editor<br/>https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-add-app-roles-in-azure-ad-apps#app-manifest-editor</details>|
|39|You are developing a web application that will be hosted in an Azure Web App.<br/>The users for web application will be authenticated by using their Azure Active Directory (Azure AD).<br/>Users will be assigned with one of the following permission levels: admin, normal, and reader.<br/>A user's Azure AD group membership must be used to determine the permission level.<br/><br/>To achieve the requirement, you configure and use Integrated Windows Authentication in the website. In the website, query Microsoft Graph API to load the group to which the user is a member.<br/>Did you achieve the requirement ?<br/><br/>a. Yes<br/>b. No|<details><summary>Answer</summary>b. No<br/><br/>It is not possible to configure windows authentication in Azure web app. You can use Azure AD</details>|
|40|You are implementing authentication for an Azure API.<br/>All calls to the API must be secure and callers should not send credentials to the API.<br/>All callers to the API are hosted in Azure services.<br/>Which authentication mechanism should you implement ?<br/><br/>a. Basic<br/>b. Anonymous<br/>c. Managed Identity<br/>d. Client Certificate|<details><summary>Answer</summary>c. Managed Identity<br/><br/>The managed identity policy essentially uses the managed identity to obtain an access token from Azure Active Directory for accessing the specified resource. After successfully obtaining the token, the policy will set the value of the token in the Authorization header using the Bearer scheme.<br/>For managed identity, we no need to send any credentials.<br/>https://docs.microsoft.com/bs-cyrl-ba/azure/api-management/api-management-authentication-policies#ManagedIdentity</details>|
|41|You are developing a website that uses Azure Blob storage.<br/>You configure Azure Blob storage lifecycle to move all blobs to the archive tier after 30 days.<br/>You need to document the minimum service-level agreement (SLA) for data recovery that is older than 30 days.<br/>Select the SLA that you will document.<br/><br/>a. at least three days<br/>b. between one & 15 hours<br/>c. at least one day<br/>d. between zero & 60 minutes|<details><summary>Answer</summary>b. between one & 15 hours<br/><br/>To read data in archive storage, you must first change the tier of the blob to hot or cool. This process is known as rehydration and can take hours to complete. There are currently two rehydrate priorities, High and Standard<br/>Standard priority: The rehydration request will be processed in the order it was received and may take up to 15 hours.<br/>High priority: The rehydration request will be prioritized over Standard requests and may finish in under 1 hour for objects under ten GB in size.<br/>https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-rehydration?tabs=azure-portal</details>|
|42|You are developing an ASP.NET web app that will be deployed to an Azure App Service.<br/>You use Application Insights telemetry to monitor the app. You need to configure a test for the web app.<br/>You must test the app to ensure that the app is available and responsive from various points around the world and at regular intervals.<br/>If the app is not responding, you must send an alert to support staff.<br/><br/>Which two test types should you use ?<br/><br/>a. Integration<br/>b. multi-step web<br/>c. URL ping<br/>d. Unit<br/>e. load|<details><summary>Answer</summary>b. multi-step web<br/>c. URL ping<br/><br/>After you've deployed your web app/website, you can set up recurring tests to monitor availability and responsiveness. Azure Application Insights sends web requests to your application at regular intervals from points around the world. It can alert you if your application isn't responding, or if it responds too slowly.<br/>Types of availability tests:<br/>There are three types of availability tests:<br/>URL ping test: a simple test that you can create in the Azure portal.<br/>Multi-step web test: A recording of a sequence of web requests, which can be played back to test more complex scenarios. Multi-step web tests are created in Visual Studio Enterprise and uploaded to the portal for execution.<br/>Custom Track Availability Tests: If you decide to create a custom application to run availability tests, the TrackAvailability() method can be used to send the results to Application Insights.<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/app/monitor-web-app-availability</details>|
|43|You are developing an application that uses a micro service architecture.<br/>You need to design a communication service for communicating transactional messages between various parts of the solution.<br/>Messages must be communicated in first-in-first-out (FIFO) order.<br/>What service should you consider ?<br/><br/>a. Azure Storage Queue<br/>b. Azure Event Hub<br/>c. Azure Service Bus<br/>d. Azure Event Grid|<details><summary>Answer</summary>c. Azure Service Bus<br/><br/>Azure Service Bus queue provides a guaranteed first-in-first-out (FIFO) ordered delivery.<br/>https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted</details>|
|44|You are developing an application using Azure Function App and Azure Blob container.<br/>The images uploaded to the Azure Blob container will be processed by Azure Function App.<br/>Images must be processed as quickly as possible once they are uploaded.<br/>The solution must minimize latency.<br/>You need to configure the Function App. How should you configure ?<br/><br/>a. Use an App Service plan. Configure the Function App to use an Azure Blob Storage input trigger.<br/>b. Use a Consumption plan. Configure the Function App to use an Azure Blob Storage trigger.<br/>c. Use a Comsumption plan. Configure the Function App to use a Timer trigger.<br/>d. Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger.|<details><summary>Answer</summary>d. Use an App Service plan. Configure the Function App to use an Azure Blob Storage trigger<br/><br/>The requirement is to minimize the latency. If your function app is on the Consumption plan, there can be up to a 10-minute delay in processing new blobs if a function app has gone idle. To avoid this latency, you should use an App Service plan with Always On enabled.<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-blob-trigger?tabs=csharp</details>|
|45|You developing an application that connects to an Azure Cosmos DB database by using the .NET API.<br/>You need to create an object to configure and execute requests in the database.<br/>Select the code segment should you use ?<br/><br/>a. new Container(EndpointUri,PrimaryKey);<br/>b. new Database(EndpointUri,PrimaryKey);<br/>c. new CosmosClient(EndpointUri,PrimaryKey);|<details><summary>Answer</summary>c. new CosmosClient(EndpointUri, PrimaryKey);<br/><br/>To create a new instance of the Cosmos Client use<br/>new CosmosClient(EndpointUri, PrimaryKey);<br/>https://docs.microsoft.com/en-us/azure/cosmos-db/sql-api-get-started#Connect</details>|
|46|You have an application that use Azure API Management to publish APIs for external partners.<br/>You must change the behavior of the API to support alternative input parameters<br/><br/>Which type of policy should you implement to rewrite the request URL to match to the format expected by the web service ?<br/><br/>a. Inbound<br/>b. Outbound<br/>c. Backend|<details><summary>Answer</summary>a. Inbound<br/><br/>The rewrite-uri policy converts a request URL from its public form to the form expected by the web service. Rewrite URI is part of Inbound section.<br/>https://docs.microsoft.com/en-us/azure/api-management/api-management-transformation-policies#RewriteURL</details>|
|47|You have an application that use Azure API Management to publish APIs for external partners.<br/>You must change the behavior of the API to remove formatting text from responses<br/><br/>Which type of policy should you implement ?<br/><br/>a. Inbound<br/>b. Outbound<br/>c. Backend|<details><summary>Answer</summary>b. Outbound<br/><br/>As we need to remove the text from the response, it should be in outbound section.<br/>https://docs.microsoft.com/en-us/azure/api-management/policies/filter-response-conten</details>|
|48|You have an application that use Azure API Management to publish APIs for external partners.<br/>You must change the behavior of the API to provide additional context to back-end services<br/><br/>Which type of policy should you implement to forward the user ID that is associated with the subscription key for the original request to the back-end service ?<br/>a. Inbound<br/>b. Outbound<br/>c. Backend|<details><summary>Answer</summary>a. Inbound<br/><br/>Below is the sample snippet of the policy to send user context to backend service.<br/><policies><br/><inbound><br/><base /><br/>\<!-- Forward the name of the product associated with the subscription key in the request to the backend service. --\><br/><set-query-parameter name="x-product-name" exists-action="override"><br/><value>@(context.Product.Name)</value><br/></set-query-parameter><br/>\<!-- Forward the user id associated with the subscription key in the request as well as the region where the proxy processing the request is hosted. --\><br/><set-header name="x-request-context-data" exists-action="override"><br/><value>@(context.User.Id)</value><br/><value>@(context.Deployment.Region)</value><br/></set-header><br/></inbound><br/>The configuration is part of inbound section.<br/>https://docs.microsoft.com/en-us/azure/api-management/policies/send-request-context-info-to-backend-service</details>|
|49|You have several virtual machines in an Azure Subscription named Subscription1.<br/>You have noticed that a virtual machine was deleted three weeks ago.<br/>You need to find the details of the user who has deleted the virtual machine.<br/>What should you use in Azure Monitor ?<br/><br/>a. Logs<br/>b. Activity Logs<br/>c. Metrics<br/>d. Service Health|<details><summary>Answer</summary>b. Activity Logs<br/><br/>Provides insight into the operations on each Azure resource in the subscription from the outside (the management plane) in addition to updates on Service Health events. Use the Activity Log, to determine the what, who, and when for any write operations (PUT, POST, DELETE) taken on the resources in your subscription. There is a single Activity log for each Azure subscription.<br/>https://docs.microsoft.com/en-us/azure/azure-monitor/platform/platform-logs-overview</details>|
|50|**Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/><br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure.<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/BIlGzKu.png">](https://i.imgur.com/BIlGzKu.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations.<br/><br/>**Requirements for Shipping Function app -<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD).<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database -**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challenges -**<br/><br/>Windows Server 2016 VM -<br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/>**Question**<br/>You need to configure Azure CDN for the Shipping web site.<br/>Which profile and tier should you select ?<br/><br/>a. Profile - Akmai<br/>Tier - Premium<br/><br/>b. Profile - Microsoft<br/>Tier - Premium<br/><br/>c. Profile - Akmai<br/>Tier - Standar<br/><br/>d. Profile - Microsoft<br/>Tier - Standard|<details><summary>Answer</summary>c. Profile - Akmail<br/>Tier - Standard<br/><br/>Scenario: Shipping website -<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/>Dynamic site acceleration is supported in Akmai and to reduce costs, use standard tier<br/>https://docs.microsoft.com/en-us/azure/cdn/cdn-optimization-overview</details>|
|51|**Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/><br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure.<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/BIlGzKu.png">](https://i.imgur.com/BIlGzKu.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations.<br/><br/>**Requirements for Shipping Function app -**<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD).<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database -**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challeges -**<br/><br/>Windows Server 2016 VM -<br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/><br/>**Question**<br/>You need to configure Azure CDN for the Shipping web site. Which Optimization should you select ?<br/><br/>a. General Web Delivery<br/>b. Large file download<br/>c. Dynamic Site Acceleration<br/>d. Video-on-demand media streaming|<details><summary>Answer</summary>c. Dynamic Site Acceleration<br/><br/>Scenario: Shipping website -<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN)<br/>Therefore, Dynamic site acceleration is required.<br/>https://docs.microsoft.com/en-us/azure/cdn/cdn-optimization-overview</details>|
|52|**Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/><br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure.<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/BIlGzKu.png">](https://i.imgur.com/BIlGzKu.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations.<br/><br/>**Requirements for Shipping Function app -**<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD)<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challenges -**<br/><br/>Windows Server 2016 VM -<br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/><br/>**Question**<br/>You need to secure the Shipping Function app.<br/>How should you configure the app authorization level, User claims and trigger type ?<br/><br/>a. authorization level - Function<br/>User claims - JSON Web Token (JWT)<br/>trigger type - Queue<br/><br/>b. authorization level - Anonymous<br/>User claims - JSON Web Token (JWT)<br/>trigger type - Queue<br/><br/>c. authrorization - level - Function<br/>User claims - API Key<br/>trigger type - Queue<br/><br/>d. authorization level - Function<br/>User claims - JSON Web Token (JWT)<br/>trigger type - http<br/><br/>e. authroriztion level - Anonymous<br/>User claims - JSON Web Token (JWT)<br/>trigger type - http|<details><summary>Answer</summary>e. authorization level - Anymous<br/>User claims - JSON Web Token (JWT)<br/>trigger type - http<br/><br/>Scenario: Shipping Function app: Implement secure function endpoints by using app-level security and include Azure Active Directory (Azure AD).<br/>1. Authorization Level must be anonymous to use function app level security methods.<br/>2. User claims must be JWT tokens; API Key is not recommended due to security issue<br/>Function App is triggered from Logic App. So it must be http<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook-trigger?tabs=csharp#secure-an-http-endpoint-in-production</details>|
|53|**Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/><br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/BIlGzKu.png">](https://i.imgur.com/BIlGzKu.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations.<br/><br/>**Requirements for Shipping Function app -**<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD).<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database -**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challenges -**<br/><br/>Windows Server 2016 VM -<br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/><br/>**Question**<br/>You need to migrate on-premises shipping data to Azure. What should you use ?<br/><br/>a. Azure Cosmos DB Data Migration tool<br/>b. Azure Database Migration service<br/>c. AzCopy<br/>d. Azure Migrate|<details><summary>Answer</summary>b. Azure Database Migration service<br/><br/>Migrate from on-premises or cloud implementations of MongoDB to Azure Cosmos DB with minimal downtime by using Azure Database Migration Service. Perform resilient migrations of MongoDB data at scale and with high reliability. Provision an instance of Database Migration Service from the Azure portal or via Azure CLI and create a migration project.<br/><br/>https://azure.microsoft.com/en-us/updates/mongodb-to-azure-cosmos-db-online-and-offline-migrations-are-now-available/</details>|
|54|**Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure.<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/BIlGzKu.png">](https://i.imgur.com/BIlGzKu.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations.<br/><br/>**Requirements for Shipping Function app -**<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD).<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database -**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challenges -**<br/><br/>Windows Server 2016 VM -<br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/><br/>**Question**<br/>You need to correct the VM issues. Which tools should you use for backup and restore ?<br/><br/>a. Azure Site Recovery<br/>b. Azure Backup<br/>c. Azure Data Box<br/>d. Azure Migrate|<details><summary>Answer</summary>b. Azure Backup<br/><br/>Scenario: The VM is critical and has not been backed up in the past. The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>The Azure Backup service provides simple, secure, and cost-effective solutions to back up your data and recover it from the Microsoft Azure cloud.<br/>https://docs.microsoft.com/en-us/azure/backup/backup-overview</details>|
|55|**Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/><br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure.<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/BIlGzKu.png">](https://i.imgur.com/BIlGzKu.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations<br/><br/>**Requirements for Shipping Function app -**<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD).<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database -**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challenges -**<br/><br/>Windows Server 2016 VM <br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/><br/>**Question**<br/>You need to correct the VM issues. Which tools should you use for performance issues ?<br/><br/>a. Azure Network Watcher<br/>b. Azure Traffic Manager<br/>c. ExpressRoute<br/>d. Accelerated Networking|<details><summary>Answer</summary>d. Accelerated Networking<br/><br/>Scenario: The VM shows high network latency, jitter, and high CPU utilization.<br/>Accelerated networking enables single root I/O virtualization (SR-IOV) to a VM, greatly improving its networking performance. This high-performance path bypasses the host from the datapath, reducing latency, jitter, and CPU utilization, for use with the most demanding network workloads on supported VM types<br/><br/>https://azure.microsoft.com/en-au/blog/maximize-your-vm-s-performance-with-accelerated-networking-now-generally-available-for-both-windows-and-linux/</details>|

---

## Results
1. 13-07-2023 PM | 26/55 = 47%

|n|Date|Note|Revison|
|-|----|----|-------|
|2|16-07-2023 PM|50/55 = 90%|<details><summary>Revision</summary>Q3 You are a developer for a company that publishes APIs using Azure API Management. You need to strip AspNet-Version from the response of the APIs.<br/><br/>What should you implement ?<br/><br/>a. a new product<br/>b. a URL Scheme<br/>c. a new policy<br/>d. a new version<br/><br/>Q15 You are developing an application that uses Azure Storage Queues.<br/>You have the following code:<br/>[<img src="https://i.imgur.com/1OtKZft.png">](https://i.imgur.com/1OtKZft.png)<br/>For each of the following statements, select Yes if the statement is true. Otherwise, select No.<br/>1. The code configures the lock duration for the queue<br/>2. The last message read remains in the queue after the code runs<br/>3. The storage queue remains in the storage account after the code runs<br/><br/>a. Yes,No,No<br/>b. No,No,Yes<br/>c. No,No,No<br/>d. No,Yes,Yes<br/><br/>Q16 You are developing an application that uses Azure Cosmos DB resource and the Cassandra API in the application.<br/>You have an Azure Active Directory (Azure AD) group named DatabaseCreators to enable provisioning of Azure Cosmos accounts, databases, and containers.<br/>The DatabaseCreators group must not be able to access the keys that are required to access the data.<br/>Which role-based access control should you use for DatabaseCreators group ?<br/><br/>a. DocumentDB Accounts Contributor<br/>b. Cosmos Backup Operator<br/>c. Cosmos DB Operator<br/>d. Coscmos DB Account Reader<br/><br/>Q34 **Current environment -**<br/>You have an on-premise application that supports shipping and transport business.<br/>The application contains a virtual machine with Windows Server 2016 that runs BizTalk Server 2016.<br/>Two workflows has been deployed in to this BizTalk Server.<br/>Ocean Transport Workflow- This workflow gathers and validates shipping container information including container contents and arrival notices at various shipping ports.<br/>Inland Transport Workflow - This workflow gathers and validates trucking information including fuel usage, number of stops, and routes.<br/><br/>The virtual machine also contains three REST APIs:<br/>Container API - Provides container information including weight, contents, and other attributes.<br/>Location API - Provides location information regarding shipping ports of call and tracking stops.<br/>Shipping REST API - Provides shipping information for use and display on the shipping website.<br/><br/>Database -<br/>The application uses MongoDB JSON document storage database for all container and transport information.<br/><br/>Shipping Web Site -<br/>The site displays shipping container tracking information and container contents. The site is located at http://shipping.wwimporters.com/<br/><br/>**Proposed solution -**<br/>The on-premises shipping application must be migrated to Azure.<br/>The VM has been migrated to a new Standard_D16s_v3 Azure VM by using Azure Site Recovery and must remain running in Azure to complete the BizTalk component migrations.<br/>You create a Standard_D16s_v3 Azure VM to host BizTalk Server.<br/>The Azure architecture diagram for the proposed solution is shown below:<br/>[<img src="https://i.imgur.com/zi6l42y.png">](https://i.imgur.com/zi6l42y.png)<br/>**Requirements for Shipping Logic app -**<br/>Support the two existing workflows - ocean transport and inland transport workflows.<br/>Support industry-standard protocol X12 message format for various messages.<br/>Secure resources to the corporate VNet and use dedicated storage resources with a fixed costing model.<br/>Maintain on-premises connectivity to support legacy applications and final BizTalk migrations.<br/><br/>**Requirements for Shipping Function app -**<br/>Implement secure function endpoints by using app-level security and Azure Active Directory (Azure AD).<br/><br/>**Requirements for REST APIs -**<br/>Secure resources to the corporate VNet.<br/>Allow deployment to a testing location within Azure without incurring additional costs.<br/>Automatically scale to double capacity during peak shipping times while not causing application downtime.<br/>Minimize costs.<br/><br/>**Requirements for database -**<br/>Data migration from on-premises to Azure must minimize costs and downtime.<br/><br/>**Requirements for Shipping website -**<br/>Ensure maximum performance for dynamic content while minimizing latency and costs by using Azure Content Delivery Network (CDN).<br/><br/>**Challenges -**<br/><br/>Windows Server 2016 VM -<br/>The VM logs shows high network latency, jitter, and high CPU utilization.<br/>The VM is critical and has not been backed up in the past.<br/>The VM must enable a quick restore from a 7-day snapshot to include in-place restore of disks in case of failure.<br/><br/>Shipping website and REST APIs -<br/>While you test the website, you are getting below error message.<br/>Failed to load http://test-shippingapi.wideworldimporters.com/: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'http://test.wwimporters.com/' is therefore not allowed access.<br/><br/>**Question**<br/>You need to migrate on-premises shipping data to Azure. What should you use ?<br/><br/>a. Azure Cosmos DB Data Migration tool<br/>b. Azure Database Migration service<br/>c. AzCopy<br/>d. Azure Migrate<br/><br/>Q51 You have an Azure API Management service. You have deployed the API back end in an Azure App Service.<br/>What should you configure as target and gateway credential type for back-end authentication ?<br/><br/>a. Target - Azure Resource<br/>Gateway credential Type - Client cert<br/><br/>b. Target - Azure Resource<br/>Gateway credential Type - Basic<br/><br/>c. Target - Http(s) endpoint<br/>Gateway credential Type - Client cert</details>|
|3|24-08-2023 PM|38/55 = 69%|<details><summary>Revision</summary>Q02 You are developing a web service that should prevent anonymous usage and use OpenID connect for authentication.<br/>You need to implement an API Management policy for the web service. Which policy should you use?<br/><br/>a. Convert XML to JSON<br/>b. validate-client-certificate<br/>c. Check-header<br/>d. Validate-jwt<br/><br/>Q03 You are a developer for a company that publishes APIs using Azure API Management. You need to strip AspNet-Version from the response of the APIs.<br/>What should you implement?<br/><br/>a. A new product<br/>b. A URL Scheme<br/>c. A new policy<br/>d. A new version<br/><br/>Q05 You need to consume messages from a messaging component that is developed using Azure Service Bus publish-subscribe model. You have initialized a subscription client object using correct details to process messages. However, the subscription application is still not consuming the messages.<br/>Which of the below code segment should you use?<br/><br/>a. await subscriptionClient.AddRuleAsync(new RuleDescription(RuleDescription.DefaultRuleName, new TrueFilter()));<br/>b. subscriptionClient = new SubscriptionClient(ServiceBusConnectionString, TopicName, SubscriptionName);<br/>c. await subscriptionClient.CloseAsync();<br/>d. subscriptonClient.RegisterMessageHandler(ProcessMessageA sync, messageHandlerOptions);<br/><br/>Q11 Which Azure RBAC roles allows you to upload images to an Azure Container Registry?<br/><br/>a. AcrPush<br/>b. acrPull<br/>c. AcrImageSigner<br/>d. Contributor<br/><br/>Q12 You are developing a web application that will be hosted in an Azure Web App<br/>The users for web application will be authenticated by using their Azure Active Directory (Azure AD).<br/>Users will be assigned with one of the following permission levels: admin, normal, and reader.<br/>A user's Azure AD group membership must be used to determine the permission level.<br/><br/>To achieve the requirement, you configure and use Integrated Windows Authentication in the website. In the website, query Microsoft Graph API to load the group to which the user is a member.<br/>Did you achieve the requirement?<br/><br/>a. yes<br/>b. no<br/><br/>Q17 You are developing an application using Azure Function App and Azure Blob container.<br/>The images uploaded to the Azure Blob container will be processed by Azure Function App.<br/>Images must be processed as quickly as possible once they are uploaded.<br/>The solution must minimize latency.<br/>You need to configure the Function App. How should you configure?<br/>a. Use an App Service plan.Configure the Function App to use an Azure Blob Storage input trigger<br/>b. Use a Consumption plan.Configure the Function App to use an Azure Blob Storage trigger<br/>c. Use a Consumption plan.Configure the Function App to use a Timer trigger<br/>d. Use an App Service plan.Configure the Function App to use an Azure Blob Storage trigger<br/><br/>Q21 You have an application that use Azure API Management to publish APIs for external partners.<br/>You must change the behavior of the API to provide additional context to back-end services<br/><br/>Which type of policy should you implement to forward the user ID that is associated with the subscription key for the original request to the back-end service?<br/><br/>a. Inbound<br/>b. Outbound<br/>c. Backend<br/><br/>Q25 You define an API Policy object by using the below XML markup:<br/><set-variable name="bodySize" value="@(context.Request.Headers["Content-Length"][0])" /><br/><choose><br/><when condition="@(int.Parse(context.Variables.GetValueOrDefault<string>("bodySize"))<400000)"><br/></when><br/><otherwise><br/><rewrite-uri template="/put"/><br/><set-backend-service base-url="http://preparationlabs.com/api/8.1/"/><br/></otherwise><br/></choose><br/><br/>Select Yes if the below statement is true. Otherwise, select No<br/>1. The XML Segment is part of the <inbound> section of the API policy.<br/>2. An error will be thrown if the body size is >265K<br/>3. The policy will retain the higher version if the request is http://preparationlabs.com/api/8.2/<br/><br/>a. yes, yes, yes<br/>b. no, no, no<br/>c. yes, no,no<br/>d. no,yes,yes<br/>e. yes,no,yes<br/><br/>Q26 You have deployed several web applications into Azure App Service. You need to collect detailed resource logs for monitoring health and availability of Azure App Service.<br/>Select the following options should you consider as destination?<br/><br/>a. Log Analytics<br/>b. Storage Account<br/>c. Event Hub<br/>d. All of the above<br/><br/>Q36 You have a web application that is deployed to an Azure App Service<br/>You need to implement an Azure monitoring service that can analyze how many users return to the application and how often they select a particular dropdown value.<br/>Which service should you use?<br/>a. Azure Application Insights<br/>b. Azure Log Analytics<br/>c. Azure Activity Log<br/><br/>Q37 You have a web application that is deployed to an Azure App Service.<br/>You need to implement an Azure monitoring service that can visualize the relationships between application components.<br/>Which service should you use?<br/><br/>a. Azure Application Insights<br/>b. Azure Log Analytics<br/>c. Azure Activity Log<br/><br/>Q39 You are developing a solution that uses publish-subscribe model and eliminates the need for constant polling.<br/>Select the two possible Azure messaging services to achieve the requirement.<br/><br/>a. ServiceBus<br/>b. EventHub<br/>c. EventGrid<br/>d. Queue<br/><br/>Q40 You have an Azure API Management service. You have deployed the API back end in an Azure App Service.<br/>What should you configure as target and gateway credential type for back-end authentication?<br/><br/>a. Target - Azure Resource<br/>Gateway credential Type - Client cert<br/><br/>b. Target - Azure Resource<br/>Gateway credential Type - Basic<br/><br/>c. Target - Http(s) endpoint<br/>Gateway credential Type - Client cert<br/><br/>Q43 You are deploying an ASP.NET Core web application to an Azure Web App.<br/>The source code of the web application is in a GitHub repository. The web application includes static content generated by a script.<br/>Azure Web App continuous deployment feature is planned to complete the deployment<br/>Before website serves traffic, you must run the static generation scripts.<br/>Select the two possible ways to achieve this requirement?<br/><br/>a. Create a file named .deployment in the root of the repository that calls a script which generates the static content & deploys the website<br/>b. Add a PreBuild target in the websites csproj project file that runs the static content generation script<br/>c. Create a file named run.cmd in the folder /run that calls a script which generates the static content & deploys the website<br/>d. Add the path to the static content generation tool to WEBSITE_RUN_FRM_PACKAGE setting in the host.json file<br/><br/></details>|
