# Test09 - Î£30

---

## Questions
|n|Question|Answer|
|-|--------|------|
|1|What advantage does a Spot VM provide over a regularly-provisioned VM?<br/><br/>a. Spot instances have a high CPU-to-memory ratio<br/>b. Spot instances are specialized VMs available with single, multiple, or fractional GPUs<br/>c. Provides burstable performance, ideal for workloads that do not need the full performance of the CPU continuously<br/>d. Spot instances are significantly cheaper|<details><summary>Answer</summary>d. Spot instances are significantly cheaper<br/><br/>Using Azure Spot Virtual Machines allows you to take advantage of our unused capacity at a significant cost savings. At any point in time when Azure needs the capacity back, the Azure infrastructure will evict Azure Spot Virtual Machines. Therefore, Azure Spot Virtual Machines are great for workloads that can handle interruptions like batch processing jobs, dev/test environments, large compute workloads, and more. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/virtual-machines/spot-vms</details>|
|2|Which ASP.NET method outputs log messages to the application diagnostics log?<br/><br/>a. System.Diagnostics.Debug.WriteLine("message");<br/>b. EventLog.WriteEnty("EventSource","message");<br/>c. Console.WriteLine("message")<br/>d. System.Diagnostics.Trace.TraceError("message");|<details><summary>Answer</summary>d. System.Diagnostics.Trace.TraceError("message");<br/><br/>Logs messages generated by your application code. The messages can be generated by the web framework you choose, or from your application code directly using the standard logging pattern of your language. Each message is assigned one of the following categories: Critical, Error, Warning, Info, Debug, and Trace. You can select how verbose you want the logging to be by setting the severity level when you enable application logging. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/app-service/troubleshoot-diagnostic-logs</details>|
|3|You would like to receive an email every time a new Azure Container Registry is created. Which of the following steps would accomplish that goal?<br/><br/>a. Go into Azure Monitor. Go into Alerts.Select the Subscription scope.Select the Create or Update Container Registry signal.Add the action group that email you.Give it a name & click save<br/>b. Create an Azure Autmation Runbook that checks your Account every 15 minutes for new resources & alerts you as new ones are created<br/>c. Azure Sevice Health can monitor your Azure account & Alert you when new resources are created on your account<br/>d. Using Azure Event Grid, you can connect into the Azure subscription to receive alerts for resources created.The Event Grid can filter those events to only Azure Container Registry, & call a Function|<details><summary>Answer</summary>a. Go into Azure Monitor,Go into Alerts.Select the Subscription scope.Select the Create or Update Container Registry signal.Add the action group that emails you.Give it a name & click save<br/><br/>Azure Monitor can do this natively. You can create an Alert in Azure Monitor, based on the Create or Update Container Registry signal. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/container-registry/monitor-service</details>|
|4|Azure Functions store their configuration settings in which file?<br/><br/>a. web.config<br/>b. function.json<br/>c. default.js<br/>d. index.js|<details><summary>Answer</summary>b. function.json<br/><br/>The function.json file defines the function's trigger, bindings, and other configuration settings. Every function has one and only one trigger. The runtime uses this config file to determine the events to monitor and how to pass data into and return data from a function execution. The following is an example function.json file. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings?tabs=csharp<br/>eg<br/>`{`<br/>`  "bindings": [`<br/>`    {`<br/>`      "name": "req",`<br/>`      "name": "req",`<br/>`      "type": "httpTrigger",`<br/>`      "direction": "in",`<br/>`      "authLevel": "function"`<br/>`    },`<br/>`    {`<br/>`      "name": "res",`<br/>`      "type": "http",`<br/>`      "direction": "out"`<br/>`    }`<br/>`  ],`<br/>`  "scriptFile": "index.js"`<br/>`}`</details>|
|5|You have a Lifecycle Storage policy that moves blobs from hot storage to cool storage if they have not been modified in 30 days. You realize that there is a frequently accessed file that is in cool storage due to this policy, and you'd like to save money by moving it back to hot storage. So you manually move this file back to hot storage. Will this solve your problem?<br/><br/>a. No, the blob will be automatically moved back to cool storage the next day<br/>b. yes|<details><summary>Answer</summary>a. no, the blob will be automatically moved back to cool storage the next day<br/><br/>Moving the blob from cool to hot does not modify it's modification date, and so it will be moved back to cool storage the next time lifecycle management runs. You need to either modify the rule to be based on last access date, or modify the file when moving it back so that the modification date is updated. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-lifecycle-management-concepts?tabs=azure-portal</details>|
|6|Which of the following statements describes the type of data that can be retrieved using Microsoft Graph?<br/><br/>a. Columnar data, such as a spreadsheet or relational data table<br/>b. Document data, such as JSON or XML<br/>c. All of the data contained in Microsoft 365, including documents, calendar, email, Teams, & people<br/>d. All of your Azure resources & resource groups, including deployment history & activity logs|<details><summary>Answer</summary>c. All of the data contained in Microsoft 365, including documents, calendar, email,Teams, & people<br/><br/>Microsoft Graph is the gateway to data and intelligence in Microsoft 365. It provides a unified programmability model that you can use to access the tremendous amount of data in Microsoft 365, Windows 10, and Enterprise Mobility + Security. Microsoft Graph exposes REST APIs and client libraries to access data on the following Microsoft cloud services: (A) Microsoft 365 core services: Bookings, Calendar, Delve, Excel, Microsoft 365 compliance eDiscovery, Microsoft Search, OneDrive, OneNote, Outlook/Exchange, People (Outlook contacts), Planner, SharePoint, Teams, To Do, Workplace Analytics. (B) Enterprise Mobility and Security services: Advanced Threat Analytics, Advanced Threat Protection, Azure Active Directory, Identity Manager, and Intune. (C) Windows 10 services: activities, devices, notifications, Universal Print. (D) Dynamics 365 Business Central. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/graph/overview#whats-in-microsoft-graph</details>|
|7|Which CosmosDB API format works best with document (JSON) data?<br/><br/>a. Graph API<br/>b. Core SQL<br/>c. Cassandra API<br/>d. MongoDB API|<details><summary>Answer</summary>b. Core SQL<br/><br/>Core (SQL) API stores data in JSON document format. Cassandra API stores data in column-oriented schema. Gremlin API allows users to make graph queries and stores data as edges and vertices. MongoDB API also uses documents but is BSON format, which is a binary format and not text-based. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/cosmos-db/introduction</details>|
|8|Which type of data can most benefit from being stored in a caching system like Azure Redis Cache?<br/><br/>a. Data that is repeatedly read<br/>b. Data that is repeatedly written<br/>c. Data that is infrequently read but is static<br/>d. Data is repeatedly read, & can return a different value every time|<details><summary>Answer</summary>a. Data that is repeatedly read<br/><br/>Data that is static but read frequently benefits most from being cached, because you can use the cache to retrieve the data instead of having to go back to the original data source every time. Data that is written and never read does not need to be cached since caching only benefits reading. Data that is always changing (like a stock price) cannot be cached since you always have to go back to the original source to retrieve the latest. Data that is infrequently read but is static can benefit from caching, but it does not benefit the most of the four options. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/architecture/best-practices/caching?toc=%2fazure%2fredis-cache%2ftoc.json</details>|
|9|What is the Azure CLI command to download application log files to the local disk?<br/><br/>a. az webapp log download<br/>b. az webapp log<br/>c. az webapp log tail<br/>d. az log download|<details><summary>Answer</summary>a. az webapp log download<br/><br/>az webapp log download allows you to download the logs to your local disk. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/learn/modules/capture-application-logs-app-service/2-enable-and-configure-app-service-application-logging<br/>e.g\logFile:<br/>`2023-09-01 10:00:00 GET /api/products 200 100ms`<br/>`2023-09-01 10:01:00 POST /api/orders 201 50ms`<br/>`2023-09-01 10:02:00 GET /api/users 404 30ms`</details>|
|10|The API Management Gateway includes a powerful feature called Policies. What is the main function of policies?<br/>a. Policies allow you to modify the behavior of the API using configuration instead of code.A policy can change both the inbound request & the outbound response<br/>b. Increase the security of your account by rejecting traffic coming in to the API by IP address<br/>c. You can set rules as to who has access to an API & who does not<br/>d. Policies allow you to direct the incoming traffic to several back-end APIs to help balance the load of the request|<details><summary>Answer</summary>a. Policies allow you to modify the behavior of the API using configuration instead of code.A policy can change both the inbound request & the outbound response<br/><br/>Policies allow you to modify the inbound request as well as the outbound results without modifying the API code itself.</details>|
|11|For Windows App Services, where can you choose to have logging saved to?<br/><br/>a. File system, blob storage, & Windows Event Log<br/>b. File system only<br/>c. File system, blob storage, & SQL Database<br/>d. File system, & blob storage|<details><summary>Answer</summary>d. File system,& blob storage<br/><br/>To route messages to log files, Azure Web apps use the Web server (IIS process). Because Windows-based Web apps are a well-established Azure service, and messaging for ASP.NET apps is tightly integrated with the underlying IIS service, Windows apps benefit from a rich logging infrastructure. For other apps, logging options may be limited by the development platform, even when running on a Windows app service. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/learn/modules/capture-application-logs-app-service/2-enable-and-configure-app-service-application-logging</details>|
|12|Which Azure service allows you to extend Azure File Shares from the cloud to on-premises by creating a local cache of the files?<br/><br/>a. azCopy<br/>b. azure service bus<br/>c. azure AD Connect<br/>d. Azure File Sync|<details><summary>Answer</summary>d. Azure File Sync<br/><br/>Azure File Sync service allows you to keep a local copy of files that are stored in the Azure File Shares in the cloud. While some users may opt to keep a full copy of their data locally, Azure File Sync additionally has the ability to transform Windows Server into a quick cache of your Azure file share. You can use any protocol that's available on Windows Server to access your data locally, including SMB, NFS, and FTPS. You can have as many caches as you need across the world. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/storage/file-sync/file-sync-introductio</details>|
|13|Which Durable Functions application pattern would you use for an Azure Function that only needs to run whenever an external API returns a status change?<br/><br/>a. Monitor pattern<br/>b. Fan-out/fan-in<br/>c. Async HTTP API<br/>d. Function chaining|<details><summary>Answer</summary>a. Monitor pattern<br/><br/>The monitor pattern refers to a flexible, recurring process in a workflow. An example is polling until specific conditions are met. You can use a regular timer trigger to address a basic scenario, such as a periodic cleanup job, but its interval is static and managing instance lifetimes becomes complex. You can use Durable Functions to create flexible recurrence intervals, manage task lifetimes, and create multiple monitor processes from a single orchestration. An example of the monitor pattern is to reverse the earlier async HTTP API scenario. Instead of exposing an endpoint for an external client to monitor a long-running operation, the long-running monitor consumes an external endpoint, and then waits for a state change. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp#monitoring</details>|
|14|In ASP.NET Core, using the logger factory class, how do you write a message to the application diagnostics log that only shows up with the user has enabled error level messages?<br/><br/>a. logger.LogCritical("message");<br/>b. logger.LogDebug("Message");<br/>c. logger.LogWarning("Message");<br/>d. logger.LogTrace("Message")'|<details><summary>Answer</summary>a. logger.LogCritical("message");<br/><br/>logger.LogCritical("Message") writes a critical message at log level 5. Levels 4 and 5 are "error" messages. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/learn/modules/capture-application-logs-app-service/2-enable-and-configure-app-service-application-logging<br/><br/>The **LogCritical** method is used to log messages at the **highest error level**, which typically represents critical failures that require immediate attention. These messages are usually enabled when a user or the application specifically configures the logging to capture critical-level events.<br/>The other options (LogDebug, LogWarning, and LogTrace) represent lower levels of log verbosity, and messages logged at those levels may not be visible when only error-level messages are enabled in the logging configuration.</details>|
|15|When deploying an Azure Storage account, and you choose Zone Redundant Storage (ZRS), how many copies of your data does Azure keep?<br/><br/>a. 6<br/>b. 1<br/>c. 3<br/>d. 3 copies in each Availability Zone|<details><summary>Answer</summary>c. 3<br/><br/>Azure Storage always stores multiple copies of your data so that it is protected from planned and unplanned events, including transient hardware failures, network or power outages, and massive natural disasters. Redundancy ensures that your storage account meets its availability and durability targets even in the face of failures. Zone-redundant storage (ZRS) copies your data synchronously across three Azure availability zones in the primary region. For applications requiring high availability, Microsoft recommends using ZRS in the primary region, and also replicating to a secondary region. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy</details>|
|16|What option do you have to grant someone access to a single container in your Azure storage account without having to give them your storage account keys?<br/><br/>a. Recycle the storage account keys after giving one to them<br/>b. Change the permission settings for the container to public<br/>c. Create for them a SAS<br/>d. Grand their user contributor access to your storage account within your subscription|<details><summary>Answer</summary>c. Create for them a SAS<br/><br/>Storage accounts are access by keys. Using SAS will let them have very granular access without exposing any other part of your storage account.</details>|
|17|If your Azure solution relies on third-party public images, some risks are added to your process. Microsoft recommends keeping a private copy of public images and deploying from there, instead of deploying directly from public image locations like DockerHub. Which CLI command is able to copy a public image into Azure Container Registry?<br/><br/>a. az acr copy<br/>b. az acr import<br/>c. docker compose<br/>d. git clone|<details><summary>Answer</summary>b. az acr import<br/><br/>As a recommended one-time step, import base images and other public content to your Azure container registry. The az acr import command in the Azure CLI supports image import from public registries such as Docker Hub and Microsoft Container Registry and from other private container registries. Refer to Microsoft Doc: https://docs.microsoft.com/en-ca/azure/container-registry/buffer-gate-public-content#import-images-to-an-azure-container-registry</details>|
|18|You have a docker image in your local repository that you'd like to share with the Azure Container Register. Your local repository image is named myimage, and your ACR is named myacr.azurecr.io. What is the command to get the image from your local into ACR?<br/><br/>a. docker save myimage<br/>b. docker push azurecr.io/myacr/myimage<br/>c. docker build myacr.azurecr.io/myimage<br/>d. docker push myacr.azurecr.io/myimage|<details><summary>Answer</summary>d. docker push myacr.azurecr.io/myimage<br/><br/>Use docker image push to share your images to the Docker Hub registry or a self-hosted one. You pass the URL of your ACR, which is in the format youruniquename.azurecr.io, plus the image name.<br/>Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-docker-cli?tabs=azure-cli#push-the-image-to-your-registry</details>|
|19|You have a Timer Trigger Function that uses "0 15,30,45 0 * * *" as it's timer setting. How often will the function run?<br/><br/>a. Every 15 minutes, every hour of the day<br/>b. At 15 minutes, 30 minutes, & 45 minutes past every hour of the day<br/>c. Every 15 seconds, every minute of the day<br/>d. At 00:15, 00:30, & 00:45 (12:15am, 12:30am, & 12:45am); three times per day only|<details><summary>Answer</summary>d. At 00:15,00:30, & 0045 (12:15am,12:30am, & 12:45am);three times per day only<br/><br/>CRON uses a "{second} {minute} {hour} {day} {month} {day-of-week}" format for expressions. The first "0" means that it runs when the second equals 0. The second "15,30,45" means when the minutes equal 15, 30 and 45. The third "0" means at midnight. So the answer is at 12:15, 12:30, and 12:45 every day. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-timer?tabs=csharp#ncrontab-expressions</details>|
|20|What does the CLI command 'az acr build --registry $ACR_NAME --image helloacrtasks:v1 .' do?<br/><br/>a. Performs a docker build & keeps the image on the local machine<br/>b. Creates a new ACR resource if one doesn't exist under that name, otherwise does nothing<br/>c. Performs a docker build & immediately pushes the result image into an ACR<br/>d. Creates a new ACR resource if one doesn't exist under that name, or deletes the images from the existing resource|<details><summary>Answer</summary>c. Performs a docker build & immediately pushes the result image into an ACR<br/><br/>ACR Tasks is a suite of features within Azure Container Registry that provides streamlined and efficient Docker container image builds in Azure. az acr build is an ACR Task which queues a quick build, providing streaming logs for an Azure Container Registry. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-tutorial-quick-task</details>|
|21|You are a developer for Acme Inc. You have implemented Redis as a caching service, and it's going great. You are running on a premium plan and using the top 120 GB of memory cache. You'd like to increase the memory limit to 500 GB, but Redis does not support that. How can you get more memory when using Azure Redis? Choose the best answer.<br/><br/>a. Implement the Redis auto-scaling feature to automatically add & remove Redis nodes when demand exceeds 120 GB<br/>b. If you attempt to store more than 120 of data in the memory cache, you're probably doing something wrong.Best to use an Azure SQL DAtabase for that<br/>c. Create a second Redis server & modify your application to shard your storage between the two locations<br/>d. Implement the Redis Cluster feature, & add a second shard to double the memory available|<details><summary>Answer</summary>d. Implement the Redis Cluster feature, & add a second shard to double the memory available<br/><br/>Redis Cluster supports up to 10 shards to create 1.2 TB of memory.</details>|
|22|You have an Azure Container Registry named 'contoso.azurecr.io'. There are several departments in your company that need to push images to the registry, and you want to keep them organized. You decide to use repository namespaces to separate out 'sales', 'marketing', 'technology' and 'customerservice'. How do you pull down the container image for the 'website' project located in the marketing namespace?<br/><br/>a. docker pull contoso.azurecr.io -path marketing -project website<br/>b. docker pull marketing.contoso.azurecr.io/website<br/>c. docker pull contoso.azurecr.io/marketing/website<br/>d. docker pull contoso.azurecr.io -location marketing/website|<details><summary>Answer</summary>c. docker pull contoso.azurecr.io/marketing/website<br/><br/>By using repository namespaces, you can allow sharing a single registry across multiple groups within your organization. Registries can be shared across deployments and teams. Azure Container Registry supports nested namespaces, enabling group isolation. However, the registry manages all repositories independently, not as a hierarchy. The syntax is contoso.azurecr.io/marketing/website<br/>Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/container-registry/container-registry-best-practices#repository-namespaces</details>|
|23|ARM templates are said to have a declarative syntax. Why is a declarative syntax better than a programmatic approach?<br/><br/>a. Declarative syntax compiles into a binary form & is quicker to deploy<br/>b. You don't have to check if the resource exists, you simply declare that it should exist<br/>c. Programmatic approach does not support advanced techniques such as loops, variables, parameters, & random resource names<br/>d. Delcarative syntax only requires minor changesto the code before each deployment to ensure uniqueness|<details><summary>Answer</summary>b. You don't have to check if the recource exists, you simply declare that it should exist<br/><br/>ARM templates allow you to create and deploy an entire Azure infrastructure declaratively. For example, you can deploy not only virtual machines but also the network infrastructure, storage systems, and any other resources you may need.<br/>Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview</details>|
|24|How many input bindings is an Azure Function allowed to have?<br/><br/>a. 0 or 1<br/>b. Any number or zero<br/>c. 1<br/>d. 1 or more|<details><summary>Answer</summary>b. any number or zero<br/><br/>You can mix and match different bindings to suit your needs. Bindings are optional and a function might have one or multiple input and/or output bindings. Refer to Microsoft Doc:<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings?tabs=csharp</details>|
|25|You are a developer for Acme Inc. Your company's flagship application is the Wind Monitoring software that Wind Energy farms use to monitor their equipment. At the end of each day, the Wind Collector sends a message that contains all of the days statistics in JSON format which needs to be read, processed, and posted to the database. Which Azure Service is best for processing this type of data?<br/><br/>a. Event Hub<br/>b. Storage Queues<br/>c. IoT Hub<br/>d. Service Bus|<details><summary>Answer</summary>d. service bus<br/><br/>Service Bus Queue is enterprise-grade message queue.</details>|
|26|Your company has several applications running on Azure App Services - App1, App2, App3 and App4. Each application is configured to use a system-managed identity to access resources. Your applications all store their secrets in a KeyVault named KV1. You are finding it difficult to manage the permissions for all these applications, and would like to move to a single managed identity for all applications instead of each application having their own. What action do you take to implement that?<br/><br/>a. Change the applications to the same user-managed identity<br/>b. Create one user in AAD for all applications, & have the applications use that<br/>c. Change the applications to the sam esystem-managed identity<br/>d. Create one user in AAD for each application, & have the applications use that|<details><summary>Answer</summary>a. change the applications to the same user-managed identity<br/><br/>Managed identities eliminate the need for developers to manage credentials. Managed identities provide an identity for applications to use when connecting to resources that support Azure Active Directory (Azure AD) authentication. Applications may use the managed identity to obtain Azure AD tokens. For example, an application may use a managed identity to access resources like Azure Key Vault where developers can store credentials in a secure manner or to access storage accounts. You cannot configure multiple applications to use the same system-assigned identity. You must use a user-assigned identity for this purpose. Refer to Microsoft Doc:<br/>https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview</details>|
|27|The speed of an Azure Event Hub is determined by the number of Throughput units you reserve for it. You can set between 1 and 20 throughput units for the Event Hub. How fast does 1 throughput unit represent for data coming in to an Event Hub?<br/><br/>a. 1GB per second<br/>b. 1000 events per second<br/>c. 1 throughput unit is one event per second<br/>d. 1MB per second or 1000 events per second (whichever come first)|<details><summary>Answer</summary>d. 1MB per second or 1k events per second (whichever comes first)<br/><br/>Each throughput unit for an Azure Event Hub provides a capacity of either 1 MB per second or 1000 events per second, depending on which limit is reached first. This means that if you send data into the Event Hub at a rate of 1 MB per second, you'll fully utilize the throughput unit. If you send smaller events that take up less space, you can achieve a rate of 1000 events per second before reaching the 1 MB per second limit.</details>|
|28|Which feature of Azure functions allow you to use a runtime not currently supported natively by Azure?<br/><br/>a. Serverless Funcstions<br/>b. SignalR<br/>c. Durable Functions<br/>d. Custom Handlers|<details><summary>Answer</summary>d. Custom handlers<br/<br/>Every Functions app is executed by a language-specific handler. While Azure Functions features many language handlers by default, there are cases where you may want to use other languages or runtimes. Custom handlers are lightweight web servers that receive events from the Functions host. Any language that supports HTTP primitives can implement a custom handler. Refer to Microsoft Doc:<br/>https://docs.microsoft.com/en-us/azure/azure-functions/functions-custom-handlers</details>|
|29|You need to modify an ARM template. You would like the location of the Azure resources to be in the same region as the resource group itself. Which ARM template function meets the criteria?<br/><br/>a. [resourceGroup().location]<br/>b. [parameters('location')]<br/>c. [environment()]<br/>d. [subscription().location]|<details><summary>Answer</summary>a. [resourceGroup()/location]<br/><br/>[resourceGroup().location] is the best answer because it accesses the resource group, and looks at the location parameter. The other answers do not do that. We don't know if the location is passed in as a parameter, and the requirement said the resource group location. Refer to Microsoft Doc: https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-functions-resource#resourcegroup</details>|
|30|Which Azure service provides the ability to store and manage your private Docker container images?<br/><br/>a. ACR<br/>b. ACI<br/>c. Azure Kubernetes Service<br/>d. Azure Web Apps for Containers|<details><summary>Answer</summary>a. ACR<br/><br/>You can send your container images to Azure Container Registry (ACR) to store them before deployment</details>|

---

## Scores
|n|Date|Resultat|Revison|
|-|----|--------|-------|
|1|02-09-2023 PM|13/30 = 43%|<details><summary>Revision</summary>True</details>|
|2|
